{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00aa64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import glob, os\n",
    "import requests, urllib\n",
    "import json, random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "from typing import List, Any, List, Dict\n",
    "from textblob import TextBlob\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as wn\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "from rdflib import URIRef, BNode, Literal, Namespace, Graph\n",
    "from rdflib.namespace import XSD, RDF, RDFS, SKOS, NamespaceManager\n",
    "\n",
    "import utils as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11663171",
   "metadata": {},
   "source": [
    "We would like to express the following features/relations:\n",
    "* Dictionary definition terms, which are always concepts\n",
    "  * We'll use the source as namespace, and corresponding concept identifier if it exists\n",
    "  * SKOS is used to establish a mapping (e.g., skos:exactMatch) and add the definition (skos:definition)\n",
    "* Special properties that we want to capture between words, which may help identify concepts:\n",
    "  * Word is part of MWE\n",
    "  * Morphologically similar words; stemming & Levenshtein distance\n",
    "  * Semantically similar words; distributed similarity (NNs)\n",
    "  * Acronyms\n",
    "  * Related, this is a generic relation, e.g., a `ampere` is related to `electric current`\n",
    "  * Domain-specificity; foreground or background term following our filtering procedure\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b0616",
   "metadata": {},
   "source": [
    "### Prepare namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4602c",
   "metadata": {},
   "source": [
    "* Note: that UNICLASS is not a namespace (yet) only has identifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b60e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Namespace(\"http://example.org/top_concept_for_visulisation/#\")\n",
    "WIKI = Namespace(\"http://www.wikidata.org/entity/#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098e92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "IREC_ontology_URL = \"http://example.org/irec-schema/#\"\n",
    "IREC_instances_URL = \"http://example.org/irec-spans/#\"\n",
    "IREC_concepts_URL = \"http://example.org/irec-concepts/#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e6b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our custom namespace for the schema to store spans\n",
    "IREC = Namespace(IREC_ontology_URL)\n",
    "\n",
    "# create a custom namespace to store spans and concepts\n",
    "SPANS = Namespace(IREC_instances_URL)\n",
    "CONCEPTS = Namespace(IREC_concepts_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef6e56",
   "metadata": {},
   "source": [
    "### graph creation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e8ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UID_assigner:\n",
    "    def __init__(self):\n",
    "        self.UIDs = {}\n",
    "        self.UID = 0\n",
    "        \n",
    "    def assign_UID(self, text, namespace: Namespace):\n",
    "        \"\"\"\n",
    "        Determines which type of UID to assign, based on the namespace.\n",
    "        \"\"\"\n",
    "        if namespace == SPANS:\n",
    "            return self.span_UID(text)\n",
    "        elif namespace == CONCEPTS:\n",
    "            return self.concept_UID(text)\n",
    "        else:\n",
    "            print(\"Currently no function implemented for assigning UIDs for this namespace\")\n",
    "    \n",
    "    def span_UID(self, text):\n",
    "        \"\"\"\n",
    "        NOTE: each text span is a unique identifier in and of itself. We'll simply convert the text span to \n",
    "        a URL friendly representation.\n",
    "        \"\"\"\n",
    "        n_space = SPANS.placeholder.defrag().__reduce__()[1][0]\n",
    "        if n_space not in self.UIDs:\n",
    "            self.UIDs[n_space] = {}\n",
    "        \n",
    "        urltext = urllib.parse.quote(text)\n",
    "        if text in self.UIDs[n_space]:\n",
    "            return self.UIDs[n_space][text], False\n",
    "        else:\n",
    "            self.UIDs[n_space][text] = urltext\n",
    "            return self.UIDs[n_space][text], True\n",
    "        \n",
    "    def concept_UID(self, text):\n",
    "        \"\"\"\n",
    "        For now I'll create my own dumb interger-based UIDs for nodes as a simple shortcut, split per namespace\n",
    "        \"\"\"\n",
    "        n_space = CONCEPTS.placeholder.defrag().__reduce__()[1][0]\n",
    "        \n",
    "        if n_space not in self.UIDs:\n",
    "            self.UIDs[n_space] = {}\n",
    "        \n",
    "        if text in self.UIDs[n_space]:\n",
    "            return self.UIDs[n_space][text], False\n",
    "        else:\n",
    "            self.UID += 1\n",
    "            self.UIDs[n_space][text] = str(self.UID)\n",
    "            return self.UIDs[n_space][text], True\n",
    "    \n",
    "    def count_nodes_in_namespace(self, namespace: Namespace = SPANS):\n",
    "        n_space = namespace.placeholder.defrag().__reduce__()[1][0]\n",
    "        print(f\"Number of nodes in '{n_space}': {len(self.UIDs[n_space])}\")\n",
    "        \n",
    "    def print_node_by_id(self, graph, node_id, namespace: Namespace = SPANS):\n",
    "        for s, p, o in graph.triples((namespace[str(node_id)],  None, None)):\n",
    "            print(f\"{s.split('#')[-1]} ; {p.split('#')[-1]} ; {o.split('#')[-1]}\")\n",
    "        \n",
    "    def print_node_by_text(self, graph, node_text, namespace: Namespace = SPANS):\n",
    "        n_space = namespace.placeholder.defrag().__reduce__()[1][0]\n",
    "        node_id = self.UIDs[n_space][node_text]\n",
    "        # find all triples with subject\n",
    "        for s, p, o in graph.triples((namespace[node_id],  None, None)):\n",
    "            print(f\"{s.split('#')[-1]} ; {p.split('#')[-1]} ; {o.split('#')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772b6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These wrappers only exist to help me quickly and consistently add nodes to the graph\n",
    "\n",
    "\n",
    "def add_top_concept(graph, node_uid, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" In some cases we'd like the concept to be linked to the ROOT of the graph, for visualisation. \"\"\"\n",
    "    graph.add((namespace[node_uid], SKOS.hasTopConcept, ROOT[top_concept_uid]))\n",
    "    return graph\n",
    "\n",
    "# IREC functions and REFERENCE\n",
    "IREC.Span # A span is a sequence of characters that occurs verbatim in a text, either contiguous or discontiguos as extracted by SPaR.txt (Kruiper et al., 2021).   \n",
    "IREC.constitutes  # Indicates that a span constitutes another span, e.g., the Multi-Word Expression (MWE) Span `hot water storage system` the Span `storage`.\n",
    "IREC.isMorphologicallySimilarTo # Indicates that a Span is morphologically similar to another Span, e.g., they may have the same stem or a small Levenshtein distance.\n",
    "IREC.isSemanticallySimilarTo # Indicates that a Span is semantically similar to another Span, following a cosine similarity between their  embeddings.\n",
    "IREC.related # General way to indicate some relation between two spans, e.g., `ampere` is related to `electric current`\n",
    "IREC.hasAcronym # A Span can have an acronym, e.g., `British Standards Institute` has the acronym `BSI`.\n",
    "IREC.isAcronymOf # A Span can have an acronym, e.g., `BSI` is the acronym for `British Standards Institute`.\n",
    "IREC.hasAntonym # Property that relates a Span to another Span, each being each other's antonyms.\n",
    "\n",
    "def irec_span(graph, node_uid, text, namespace: Namespace=SPANS):\n",
    "    \"\"\" Add a span node in the SPANS namespace, of type IREC.Span and the span text set as its RDF.label \"\"\"\n",
    "    # is preflabel a property? I would assume so\n",
    "    graph.add((namespace[node_uid], RDF.type, IREC.Span))\n",
    "    graph.add((namespace[node_uid], RDFS.label,  Literal(text, lang='en')))\n",
    "    return graph\n",
    "\n",
    "def irec_constitutes(graph, subject_node_uid, object_node_uid,\n",
    "                     subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that somewhere in the label of the first SPAN node, you can find the second span's label \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.constitutes, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_morp_sim(graph, subject_node_uid, object_node_uid,\n",
    "                  subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the labels of two SPAN nodes are morphologically similar \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.isMorphologicallySimilarTo, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_sem_sim(graph, subject_node_uid, object_node_uid,\n",
    "                 subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the labels of two SPAN nodes are semantically similar, following the distributed semantics hypothesis \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.isSemanticallySimilarTo, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_related(graph, subject_node_uid, object_node_uid,\n",
    "                 subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the labels of two SPAN nodes are semantically similar, following the distributed semantics hypothesis \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.related, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_has_acronym(graph, subject_node_uid, object_node_uid,\n",
    "                     subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the label of the subject node has an acronym, ergo the label of the object node  \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.hasAcronym, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_is_acronym_of(graph, subject_node_uid, object_node_uid,\n",
    "                       subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the label of the subject node is an acronym of the label of the object node  \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.isAcronymOf, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "def irec_antonym(graph, subject_node_uid, object_node_uid,\n",
    "                 subject_namespace: Namespace=SPANS, object_namespace: Namespace=SPANS):\n",
    "    \"\"\" Indicates that the label of the subject node is an antonym of the label of the object node  \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], IREC.hasAntonym, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "\n",
    "\n",
    "# SKOS \n",
    "def skos_node(graph, node_uid, text, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" Add a concept to the graph in the CONCEPTS namespace, of type SKOS.Concept \"\"\"\n",
    "    graph.add((namespace[node_uid], RDF.type, SKOS.Concept))\n",
    "    graph = skos_prefLabel(graph, node_uid, text, namespace)\n",
    "    return graph\n",
    "\n",
    "def skos_prefLabel(graph, node_uid, text, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" Add the text label for a node \"\"\"\n",
    "    graph.add((namespace[node_uid], SKOS.prefLabel, Literal(text, lang='en')))\n",
    "    return graph\n",
    "\n",
    "def skos_altLabel(graph, node_uid, alt_label_uid, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" Add an alternative text label for a concept node \"\"\"\n",
    "    graph.add((namespace[node_uid], SKOS.altLabel, namespace[alt_label_uid]))\n",
    "    graph.add((namespace[alt_label_uid], SKOS.altLabel, namespace[node_uid]))\n",
    "    return graph\n",
    "\n",
    "def skos_related(subject_node_uid, object_node_uid,\n",
    "                subject_namespace: Namespace=SPANS, object_namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" Denotes a relation between two nodes, would expect the nodes to be in different vocabularies \"\"\"\n",
    "    graph.add((subject_namespace[subject_node_uid], SKOS.related, object_namespace[object_node_uid]))\n",
    "    return graph\n",
    "    \n",
    "def skos_broader(graph, narrower_node_uid, broader_node_uid,\n",
    "                 narrower_namespace: Namespace=CONCEPTS, broader_namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" Assuming narrower/broader is always reflexive, would expect the nodes to be in different vocabularies \"\"\"\n",
    "    graph.add((broader_namespace[narrower_node_uid], SKOS.narrower, narrower_namespace[broader_node_uid]))\n",
    "    graph.add((narrower_namespace[broader_node_uid], SKOS.broader, broader_namespace[narrower_node_uid]))\n",
    "    return graph\n",
    "    \n",
    "def skos_note(graph, node_uid, note_text, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" I don't think this is used right now; not sure if there is a use-case at any point \"\"\"\n",
    "    graph.add((namespace[node_uid], SKOS.note, Literal(note_text, lang='en')))\n",
    "    return graph\n",
    "\n",
    "def skos_definition(graph, node_uid, definition_text, namespace: Namespace=CONCEPTS):\n",
    "    \"\"\" The namespace indidcates the source of the definition? \"\"\"\n",
    "    graph.add((namespace[node_uid], SKOS.definition, Literal(definition_text, lang='en')))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdc557",
   "metadata": {},
   "source": [
    "### Prepare namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a1e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "irec_graph = Graph()\n",
    "\n",
    "irec_graph.bind(\"root\", ROOT)\n",
    "irec_graph.bind(\"wikipedia\", WIKI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56acbeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N26ed2f0a3129443c8229f1f8cbc59f6d (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import our vocabulary\n",
    "irec_graph.parse(\"IREC.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb5024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UID_assigner()\n",
    "top_concept_uid = 'ROOT'\n",
    "\n",
    "irec_graph = skos_prefLabel(irec_graph, top_concept_uid, \"NUU_graph_root\", namespace = ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fceef5",
   "metadata": {},
   "source": [
    "### Add base antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fe6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to capture antonyms: dichotomy in meaning of words, \n",
    "# For this we'll use NLTK's version of WordNet, which mainly captures antonyms for adjectives and adverbs.\n",
    "wordnet_antonyms = {}\n",
    "for i in wn.all_synsets():\n",
    "    if i.pos() in ['a', 's']:    # If synset is adj or satelite-adj.\n",
    "        for j in i.lemmas():     # Iterating through lemmas for each synset.\n",
    "            if j.antonyms():     # If adj has antonym.\n",
    "                wordnet_antonyms[str(j.name()).strip()] = [x.name() for x in j.antonyms()]\n",
    "\n",
    "# Example of a useful antonym for us\n",
    "wordnet_antonyms['hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3d0ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hot']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_antonyms['cold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd035fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for span in wordnet_antonyms.keys():\n",
    "    span_uid, new_uid_bool = ua.assign_UID(span, SPANS)\n",
    "    \n",
    "    if new_uid_bool: # equals if (SPANS[uid], None, None) not in graph: \n",
    "        # need to add the span to the graph\n",
    "        irec_graph = irec_span(irec_graph, span_uid, span)\n",
    "        \n",
    "    antonyms = wordnet_antonyms[span]\n",
    "    for antonym in antonyms:\n",
    "        antonym_uid, new_uid_bool = ua.assign_UID(antonym, SPANS)\n",
    "        \n",
    "        if new_uid_bool:\n",
    "            irec_graph = irec_span(irec_graph, antonym_uid, antonym)\n",
    "            \n",
    "        # add the antonym relation\n",
    "        irec_graph = irec_antonym(irec_graph, span_uid, antonym_uid)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f63e5",
   "metadata": {},
   "source": [
    "### Add domain terms extracted from the Approved documents as Spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8178ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_terms = pickle.load(open('data/domain_terms.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f4b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expansion water',\n",
       " 'the hot water system',\n",
       " 'the hot water',\n",
       " 'a hot water system',\n",
       " 'the hot tap',\n",
       " 'the water supply',\n",
       " 'PLY',\n",
       " 'Water Fittings',\n",
       " 'Fittings',\n",
       " 'the storage vessel',\n",
       " 'the Gas Safety Installation',\n",
       " 'the Gas Safety Installation Use',\n",
       " 'Gas Safety Installation',\n",
       " 'Regulations 1996',\n",
       " 'Regulations 1992',\n",
       " 'Regulations 1994',\n",
       " 'ductwork',\n",
       " 'ductwork serving',\n",
       " 'pipework',\n",
       " 'Electrical safety Dwellings',\n",
       " 'industrial processes',\n",
       " 'the stored water',\n",
       " 'a sanitary conveniences',\n",
       " 'sanitary conveniences',\n",
       " 'sanitary fittings',\n",
       " 'a sanitary convenience',\n",
       " 'a temperature relief valve',\n",
       " 'cistern lids',\n",
       " 'cylinders',\n",
       " 'ignition',\n",
       " 'cylinder',\n",
       " 'steam',\n",
       " 'engine',\n",
       " 'thermoplastic material',\n",
       " 'thermoplastics',\n",
       " 'thermoplastic product',\n",
       " 'thermoplastic',\n",
       " 'thermoplastic core',\n",
       " 'thermoplastic materials a )',\n",
       " 'thermoplastic panels',\n",
       " 'thermoplastic substrate',\n",
       " 'cistern',\n",
       " 'cisterns',\n",
       " 'the cistern',\n",
       " 'washing facilities',\n",
       " 'shower facilities',\n",
       " 'changing facilities',\n",
       " 'internal facilities',\n",
       " 'turning facilities',\n",
       " 'hand washing facilities',\n",
       " 'Water supply',\n",
       " 'the Water Supply',\n",
       " 'water heater',\n",
       " 'water heaters',\n",
       " 'storage water heaters',\n",
       " 'a space heater',\n",
       " 'BS 853 - 1 : 1996 Specification',\n",
       " 'Unvented',\n",
       " 'Calorifiers',\n",
       " 'a hot water storage system',\n",
       " 'hot water storage system',\n",
       " 'hot water storage systems',\n",
       " 'a solar hot water system',\n",
       " 'Open vented copper cylinders',\n",
       " 'ecification',\n",
       " 'pressure relief valve',\n",
       " 'heat source',\n",
       " 'heat sources',\n",
       " 'heat input',\n",
       " 'heat supplied',\n",
       " 'PLY AND',\n",
       " 'the operating pressure',\n",
       " 'a boiler',\n",
       " 'the boiler',\n",
       " 'curtilages',\n",
       " 'curtilage',\n",
       " 'WARNING',\n",
       " 'the pipe floor',\n",
       " 'the source rooms',\n",
       " 'the supply air',\n",
       " 'the water main',\n",
       " 'the source room measurements',\n",
       " 'the discharge pipe',\n",
       " 'the storage layer',\n",
       " 'The ventilation areas',\n",
       " 'the independent ceiling',\n",
       " 'the pipework',\n",
       " 'the heat panel form',\n",
       " 'the fan unit',\n",
       " 'the distribution pipes',\n",
       " 'the worktop',\n",
       " 'litres per',\n",
       " 'litres',\n",
       " 'litres /',\n",
       " 'litres capacity',\n",
       " 'paragraph 3 15',\n",
       " 'paragraph 3 13',\n",
       " 'paragraph 3 22',\n",
       " 'paragraph 3 25',\n",
       " 'paragraph 3 35',\n",
       " 'paragraph 3 21',\n",
       " 'paragraph 3 10',\n",
       " 'paragraph 3 30',\n",
       " 'paragraph 3 5',\n",
       " 'paragraph 3 60',\n",
       " 'paragraph 3 32',\n",
       " 'paragraph 3 68',\n",
       " 'paragraph 4 14',\n",
       " 'an energy cut - out',\n",
       " 'energy cut - out',\n",
       " 'BS EN 1155 Building hardware',\n",
       " 'BS EN 1125 Building hardware',\n",
       " 'BS EN 1490 : 2000 Building valves',\n",
       " 'thermostats',\n",
       " 'The BCB',\n",
       " 'the BCB',\n",
       " 'Discharge',\n",
       " 'a manifold',\n",
       " 'fixed immersion heaters',\n",
       " 'tundish',\n",
       " 'storage system',\n",
       " 'transfer space',\n",
       " 'sound absorption',\n",
       " 'bin storage',\n",
       " 'the tundish',\n",
       " 'air gap',\n",
       " 'air gaps',\n",
       " 'Factory made systems',\n",
       " 'solar water heating systems',\n",
       " 'bends',\n",
       " 'combustion installations',\n",
       " 'combustion installation',\n",
       " 'heating installations',\n",
       " 'lift installations',\n",
       " 'pipe sizes',\n",
       " 'pipe size',\n",
       " 'trap sizes',\n",
       " 'discharge pipes',\n",
       " 'circulation pipes',\n",
       " 'gas pipes',\n",
       " 'rainfall pipes',\n",
       " 'discharge pipe',\n",
       " 'a straight length',\n",
       " 'copper discharge pipe',\n",
       " 'copper discharge pipe  D2',\n",
       " 'a G temperature relief',\n",
       " 'Symbols',\n",
       " 'Basic polymers',\n",
       " 'discharge stack',\n",
       " 'discharge stacks',\n",
       " 'a discharge stack',\n",
       " 'a clear space',\n",
       " 'clear space',\n",
       " 'a safe place',\n",
       " 'branch pipe',\n",
       " 'branch pipes',\n",
       " 'wall',\n",
       " 'floor',\n",
       " 'floor a',\n",
       " 'walls',\n",
       " 'roof',\n",
       " 'outside',\n",
       " 'door a',\n",
       " 'Wall',\n",
       " 'residential',\n",
       " 'enclosure',\n",
       " 'drain',\n",
       " 'panel',\n",
       " 'plane',\n",
       " 'walkway',\n",
       " 'thatch',\n",
       " 'wall R',\n",
       " 'the water level',\n",
       " 'the water table',\n",
       " 'the water seal',\n",
       " 'BB',\n",
       " 'PB',\n",
       " 'Class F',\n",
       " 'Class B',\n",
       " 'Class S',\n",
       " 'a wire cage',\n",
       " 'hot water',\n",
       " 'cold water',\n",
       " 'domestic hot water',\n",
       " 'the fixed building service',\n",
       " 'the fixed building services',\n",
       " 'a fixed building service',\n",
       " 'fixed building service',\n",
       " 'fixed building services',\n",
       " 'fixed building',\n",
       " 'the fixed services',\n",
       " 'fixed building services i )',\n",
       " 'static completion',\n",
       " 'working order',\n",
       " 'PN 10 )',\n",
       " 'PE )',\n",
       " 'Low pressure',\n",
       " 'thermostatic mixing valves',\n",
       " 'existing dwellings',\n",
       " 'blending valves',\n",
       " 'the bathroom',\n",
       " 'the shower',\n",
       " 'a bathroom',\n",
       " 'the bath',\n",
       " 'The bathroom',\n",
       " 'the bedrooms',\n",
       " 'TMVs',\n",
       " 'full plans',\n",
       " 'a person registered',\n",
       " 'NVENIENCES',\n",
       " 'Sanitary conveniences',\n",
       " 'hand washing',\n",
       " 'the sanitary appliances',\n",
       " 'the sanitary',\n",
       " 'sanitary appliances',\n",
       " 'WC suites',\n",
       " 'vehicles',\n",
       " 'vehicle',\n",
       " 'businesses',\n",
       " 'BS 6465 - 2 : 1996 Sanitary installations',\n",
       " 'cold taps',\n",
       " 'sanitary appliance',\n",
       " 'a sanitary appliance',\n",
       " 'food preparation area',\n",
       " 'food preparation areas',\n",
       " 'a cubicle',\n",
       " 'WC cubicles',\n",
       " 'WC cubicle',\n",
       " 'sanitary facilities',\n",
       " 'sanitary accommodation',\n",
       " 'traps',\n",
       " 'trap',\n",
       " 'a branch discharge pipe',\n",
       " 'branch discharge pipes',\n",
       " 'a branch pipe',\n",
       " 'sewers',\n",
       " 'sewerage',\n",
       " 'sewer systems',\n",
       " 'cleaners',\n",
       " 'foul drains',\n",
       " 'a grating',\n",
       " 'a macerator',\n",
       " 'the macerator',\n",
       " 'Lifting plants',\n",
       " 'greywater recycling',\n",
       " 'the sewer',\n",
       " 'the drain',\n",
       " 'the basin',\n",
       " 'The sewer',\n",
       " 'the pool',\n",
       " 'the drain sewer',\n",
       " 'the sanitation',\n",
       " 'the trench',\n",
       " 'the wastewater',\n",
       " 'a washbasin',\n",
       " 'Part F',\n",
       " 'Part P',\n",
       " 'Part M',\n",
       " 'Part R',\n",
       " 'Part L',\n",
       " 'Part G H',\n",
       " 'Approved Document E',\n",
       " 'Approved Document C',\n",
       " 'Approved Document P',\n",
       " 'Approved Document G',\n",
       " 'Approved Document F',\n",
       " 'Approved Document K',\n",
       " 'Approved Document M',\n",
       " 'Approved Document B',\n",
       " 'Approved Document N',\n",
       " 'Approved Document J',\n",
       " 'Approved Document 7',\n",
       " 'Approved Document M : Access',\n",
       " 'See Approved Document B',\n",
       " 'Approved Document H How',\n",
       " 'Approved Docume',\n",
       " 'Scale of provision',\n",
       " 'faecal - free wastewater',\n",
       " 'a dishwasher',\n",
       " 'a kitchen',\n",
       " 'the kitchen',\n",
       " 'a garage',\n",
       " 'a chimney',\n",
       " 'a shower',\n",
       " 'the oven',\n",
       " 'In kitchens',\n",
       " 'an sink',\n",
       " 'a kitchen bathroom',\n",
       " 'appendix',\n",
       " 'ducts',\n",
       " 'linings',\n",
       " 'ducting',\n",
       " 'enclosures',\n",
       " 'ducted',\n",
       " 'panels',\n",
       " 'flue',\n",
       " 'sheeting',\n",
       " 'taps',\n",
       " 'duct provided',\n",
       " 'undulations',\n",
       " 'paragraphs A8 A10',\n",
       " 'paragraphs H2 J7',\n",
       " 'Taps',\n",
       " 'bath',\n",
       " 'baths',\n",
       " 'bathing',\n",
       " 'shower',\n",
       " 'the water efficiency',\n",
       " 'the water consumption',\n",
       " 'the water volume',\n",
       " 'the energy efficiency',\n",
       " 'the total water consumption',\n",
       " 'water consumption figures',\n",
       " 'overflow',\n",
       " 'dishwasher',\n",
       " 'Flow rate',\n",
       " 'Flow rates',\n",
       " 'litres per minute',\n",
       " 'dry load',\n",
       " 'ER EFFICIENCY',\n",
       " 'washing machine',\n",
       " 'washing machines',\n",
       " 'Shower outlets',\n",
       " 'BS 8519',\n",
       " 'BS 8515',\n",
       " 'BS 8519 Selection',\n",
       " 'water supply systems 1',\n",
       " 'water supply pipes',\n",
       " 'Rainfall',\n",
       " 'Percentage',\n",
       " 'total capacity',\n",
       " 'the regeneration cycle',\n",
       " 'regeneration cycle',\n",
       " 'Average number',\n",
       " 'a bedroom',\n",
       " 'the bedroom',\n",
       " 'a bedroom wall',\n",
       " 'the first bedroom',\n",
       " 'water softeners',\n",
       " 'a water softener',\n",
       " 'Table A3',\n",
       " 'Table B3',\n",
       " 'Table A below',\n",
       " 'gas fittings',\n",
       " 'pipe fittings',\n",
       " 'light fittings',\n",
       " 'water fittings',\n",
       " 'access fittings',\n",
       " 'terminal fittings',\n",
       " 'low fittings',\n",
       " 'gaskets',\n",
       " 'column a )',\n",
       " 'column b )',\n",
       " 'the average flow rate / volume',\n",
       " 'flow rate / volume',\n",
       " 'CALCULATOR FOR',\n",
       " 'litres / min )',\n",
       " 'litres / min',\n",
       " 'flow rate',\n",
       " 'flow rates',\n",
       " 'fitting type',\n",
       " 'litres per kilogram',\n",
       " 'per cent',\n",
       " 'the calculator',\n",
       " 'a U - value calculator',\n",
       " 'regeneration cycles per day',\n",
       " 'the total capacity',\n",
       " 'The total capacity',\n",
       " 'the installed capacity',\n",
       " 'column 2',\n",
       " 'column 1',\n",
       " 'column 4',\n",
       " 'Table A5 3',\n",
       " 'Table A5 2',\n",
       " 'Table A5 5',\n",
       " 'Table A5 1',\n",
       " 'Table A4 6',\n",
       " 'the greywater savings',\n",
       " 'the greywater supply',\n",
       " 'fittings',\n",
       " 'Constructions',\n",
       " 'fabrics',\n",
       " 'Controls',\n",
       " 'fittings WC',\n",
       " 'Fires assembly',\n",
       " 'plasters',\n",
       " 'workmanship',\n",
       " 'Litres per Number Quantity Greywater minute',\n",
       " 'the WC',\n",
       " 'The WC',\n",
       " 'a WC',\n",
       " 'hydraulic filter efficiency',\n",
       " 'Daily rainwater per',\n",
       " 'yield coefficient',\n",
       " 'the rainwater savings',\n",
       " 'the rainwater',\n",
       " 'mg / l',\n",
       " 'nitrite',\n",
       " 'Water Quality',\n",
       " 'Water supplied',\n",
       " 'water supplied',\n",
       " 'Regulations 2010',\n",
       " 'Regulations 2004',\n",
       " 'Regulations 2006',\n",
       " 'Regulations 2001',\n",
       " 'Regulations 2007',\n",
       " 'Regulations 1998',\n",
       " 'Regulations 2000',\n",
       " 'Regulations 1999',\n",
       " 'Regulations 2012',\n",
       " 'the Regulations 2010',\n",
       " 'the Regulations 2011',\n",
       " 'coli parameter',\n",
       " 'a parameter',\n",
       " 'Schedule I',\n",
       " 'parasite',\n",
       " 'any substance',\n",
       " 'Any substance',\n",
       " 'nitrate',\n",
       " 'Building Approved Inspectors',\n",
       " 'the Approved Inspectors',\n",
       " 'the Building Approved Inspectors',\n",
       " 'The Building Approved Inspectors',\n",
       " 'Approved Inspectors',\n",
       " 'an Approved Inspector',\n",
       " 'The Food Hygiene',\n",
       " 'the Food Hygiene Wales',\n",
       " 'water use',\n",
       " 'energy use',\n",
       " 'water consumption',\n",
       " 'water systems',\n",
       " 'domestic use',\n",
       " 'hmso',\n",
       " 'solid fuel - burning appliances',\n",
       " 'gas - burning appliances',\n",
       " 'Sanitary tapware',\n",
       " 'a type 1',\n",
       " 'a type 2 lift',\n",
       " 'type 2',\n",
       " 'the Type C requirements',\n",
       " 'wras',\n",
       " 'www wras co uk',\n",
       " 'BS EN 1634 - 1 Fire resistance test door and',\n",
       " 'Point smoke BS EN 1634 - 3 Smoke control test door',\n",
       " 'BS EN 54 - 7 Smoke detectors',\n",
       " 'BS EN 12050 - 1 : 2001 Wastewater lifting plants',\n",
       " 'Market Transformation Programme',\n",
       " 'economic feasibility',\n",
       " 'cibse',\n",
       " 'page 18',\n",
       " 'iti ed 15 20',\n",
       " 'underground drains',\n",
       " 'underground drainage',\n",
       " 'a sewerage undertaker',\n",
       " 'the sewerage undertaker',\n",
       " 'sewerage undertaker',\n",
       " 'The sewerage undertaker',\n",
       " 'sewerage undertakers',\n",
       " 'surface water sewers',\n",
       " 'private sewers',\n",
       " 'a surface water sewer',\n",
       " 'Pumping installations',\n",
       " 'Siting',\n",
       " 'siting',\n",
       " 'The siting',\n",
       " 'Drainage fields',\n",
       " 'Traps',\n",
       " 'Trap doors',\n",
       " 'Section 2 : Drainage',\n",
       " 'Cesspools',\n",
       " 'Combined systems',\n",
       " 'rainfall intensities',\n",
       " 'overflowing',\n",
       " 'the cesspool',\n",
       " 'a cesspool',\n",
       " 'cesspools',\n",
       " 'septic tanks',\n",
       " 'septic tank',\n",
       " 'Contaminated',\n",
       " 'seats',\n",
       " 'runoff',\n",
       " 'seated',\n",
       " 'cars',\n",
       " 'chair',\n",
       " 'Disused',\n",
       " 'gutters',\n",
       " 'gutter',\n",
       " 'rainwater pipes',\n",
       " 'rainwater drains',\n",
       " 'litres per second per square metre',\n",
       " 'paved areas',\n",
       " 'underground rainwater drainage',\n",
       " 'unventilated',\n",
       " 'nominal ring stiffness SN4',\n",
       " 'a shared drain / sewer',\n",
       " 'Bedding',\n",
       " 'Code of Practice L24',\n",
       " 'HSE Books 1992',\n",
       " 'HSE Books',\n",
       " 'ISBN 0 7176 0413 6',\n",
       " 'confined spaces',\n",
       " 'Relev',\n",
       " 'the Health and',\n",
       " 'Health and',\n",
       " 'the Health Work',\n",
       " 'March 2004',\n",
       " 'March 1998',\n",
       " 'March 1996',\n",
       " 'April 2002',\n",
       " 'March 2012',\n",
       " 'March 1983',\n",
       " 'foul water',\n",
       " 'a foul sewer',\n",
       " 'the foul water',\n",
       " 'foul air',\n",
       " 'foul water drainage',\n",
       " 'surface water drainage systems',\n",
       " 'a foul water drainage system',\n",
       " 'reclaimed water systems',\n",
       " 'blockage',\n",
       " 'blockages',\n",
       " 'a drainage system',\n",
       " 'the drainage system',\n",
       " 'drainage system',\n",
       " 'drainage systems',\n",
       " 'separate drainage systems',\n",
       " 'The foul drainage system',\n",
       " 'clearing blockages',\n",
       " 'seal depths',\n",
       " 'paragraph 2 11',\n",
       " 'paragraph 2 10',\n",
       " 'paragraph 2 7',\n",
       " 'paragraph 2 8',\n",
       " 'paragraph 1 11',\n",
       " 'paragraph 1 42',\n",
       " 'paragraph 2 29',\n",
       " 'paragraph 2 24',\n",
       " 'paragraph 1 39',\n",
       " 'paragraph 11 2',\n",
       " 'Gullies',\n",
       " 'a stub stack',\n",
       " 'sanitary pipework',\n",
       " 'sanitary',\n",
       " 'the tail',\n",
       " 'the bend',\n",
       " 'the stack',\n",
       " 'the pile',\n",
       " 'individual dwellings',\n",
       " 'single dwellings',\n",
       " 'private dwellings',\n",
       " 'the leaf',\n",
       " 'the leaves',\n",
       " 'the branch',\n",
       " 'the external leaf',\n",
       " 'water seals',\n",
       " 'slope',\n",
       " 'slopes',\n",
       " 'Air admittance valves',\n",
       " 'an air admittance valve',\n",
       " 'Stacks',\n",
       " 'Stack',\n",
       " 'the higher',\n",
       " 'the less',\n",
       " 'the highest',\n",
       " 'litres / sec )',\n",
       " 'litres / sec',\n",
       " 'surcharging',\n",
       " 'paragraph 2 15',\n",
       " 'paragraph 2 14',\n",
       " 'paragraph 2 13',\n",
       " 'paragraph 2 25',\n",
       " 'paragraph 2 17',\n",
       " 'paragraph 2 21',\n",
       " 'paragraph 2 5',\n",
       " 'paragraph 1 17',\n",
       " 'paragraph 2 44',\n",
       " 'paragraph 1 28',\n",
       " 'paragraph 1 31',\n",
       " 'paragraphs 2 35',\n",
       " 'Rodding points',\n",
       " 'lengths',\n",
       " 'corrosion',\n",
       " 'rodent control',\n",
       " 'PP )',\n",
       " 'PP',\n",
       " 'Polyethylene',\n",
       " 'PE',\n",
       " 'the effluent',\n",
       " 'The effluent',\n",
       " 'effluent',\n",
       " 'condensate',\n",
       " 'condensates',\n",
       " 'positive pressure',\n",
       " 'smoke testing',\n",
       " 'smoke tests',\n",
       " 'Smoke testing',\n",
       " 'pressure testing',\n",
       " 'a smoke test',\n",
       " 'smoke production',\n",
       " 'a pressure test',\n",
       " 'the pressure test',\n",
       " 'a water test',\n",
       " 'National Annexes NA',\n",
       " 'pipe',\n",
       " 'pipes',\n",
       " 'shafts',\n",
       " 'sewer',\n",
       " 'shaft',\n",
       " 'mortar',\n",
       " 'hand',\n",
       " 'the curtilage',\n",
       " 'the curtilages',\n",
       " 'the private curtilage',\n",
       " 'Appendix B : Standards',\n",
       " 'Appendix B : Performance of materials',\n",
       " 'Appendix F : Standards Fire resistance',\n",
       " 'Appendix C : Fire doorsets C1',\n",
       " 'Appendix H1 - B',\n",
       " 'Appendix A : Key terms Appendix B : Performance of',\n",
       " 'key terms Appendix B',\n",
       " 'the sewer system',\n",
       " 'the public sewer system',\n",
       " 'the sewerage',\n",
       " 'public sewers',\n",
       " 'low - lying sites',\n",
       " 'gully',\n",
       " 'the floor above',\n",
       " 'the floor below',\n",
       " 'the floor level',\n",
       " 'the floor roof above',\n",
       " 'the room below',\n",
       " 'the storey above',\n",
       " 'a floor level',\n",
       " 'the landing floor level',\n",
       " 'the ground below',\n",
       " 'The lowest floor of',\n",
       " 'private land',\n",
       " 'a public sewer',\n",
       " 'the public sewer',\n",
       " 'a public sewer )',\n",
       " 'a combined sewer',\n",
       " 'the developer',\n",
       " 'The developer',\n",
       " 'private sewer',\n",
       " 'wastewater treatment system',\n",
       " 'wastewater treatment systems',\n",
       " 'a wastewater treatment system',\n",
       " 'cesspool',\n",
       " 'prefabricated components',\n",
       " 'surcharge',\n",
       " 'one property',\n",
       " 'gullies',\n",
       " 'Vent',\n",
       " 'the gradient',\n",
       " 'a gradient',\n",
       " 'The gradient',\n",
       " 'gradients',\n",
       " 'the maximum gradients',\n",
       " 'straight lines',\n",
       " 'granular',\n",
       " 'inspection chambers',\n",
       " 'inspection chamber',\n",
       " 'manholes',\n",
       " 'the crown',\n",
       " 'the Crown',\n",
       " 'manhole',\n",
       " 'flexible joints',\n",
       " 'Special measures',\n",
       " 'an open channel',\n",
       " 'an openable',\n",
       " 'personnel entry',\n",
       " 'the local authority',\n",
       " 'a local authority',\n",
       " 'The local authority',\n",
       " 'Pipe gradients',\n",
       " 'paragraphs 0 10 3',\n",
       " 'paragraphs 0 20 0 25',\n",
       " 'premises 0 6',\n",
       " 'Sewers',\n",
       " 'watertight',\n",
       " 'flexible filler',\n",
       " 'fields Laid',\n",
       " 'light roads Laid',\n",
       " 'BS EN 295',\n",
       " 'BS EN 520',\n",
       " 'bedding factor',\n",
       " 'bedding types',\n",
       " 'Alternative designs',\n",
       " 'pipe strengths',\n",
       " 'pipe strength',\n",
       " 'economic options',\n",
       " 'BS EN 1295',\n",
       " 'BS EN 12845',\n",
       " 'Mini depth',\n",
       " 'roads',\n",
       " 'traffic',\n",
       " 'BS 5911',\n",
       " 'm deep',\n",
       " 'mm x mm',\n",
       " 'Drains',\n",
       " 'highways',\n",
       " 'public open space',\n",
       " 'basements',\n",
       " 'driveways',\n",
       " 'porches',\n",
       " 'sheds',\n",
       " 'construction traffic',\n",
       " 'piling works',\n",
       " 'covers',\n",
       " 'cover',\n",
       " 'the piling',\n",
       " 'trial holes',\n",
       " 'Piling',\n",
       " 'Manholes',\n",
       " 'fixed ladders',\n",
       " 'BS EN 1610',\n",
       " 'BS EN 13141',\n",
       " 'the depth',\n",
       " 'The depth',\n",
       " 'a depth of',\n",
       " 'test lengths',\n",
       " 'BS EN 752 - 4',\n",
       " 'BS EN 752',\n",
       " 'BS EN 845 - 1',\n",
       " 'BS EN 12056',\n",
       " 'gas appliances',\n",
       " 'fire appliances',\n",
       " 'combustion appliances',\n",
       " 'fixed appliances',\n",
       " 'oil appliances',\n",
       " 'Fire appliances',\n",
       " 'ground floor appliances',\n",
       " 'heating stoves',\n",
       " 'a stairway ground',\n",
       " 'a stairway shaft',\n",
       " 'a stairway b',\n",
       " 'a ladder',\n",
       " 'fire stairway b ) resistance',\n",
       " 'a flight steps',\n",
       " 'a gully drain',\n",
       " 'Pipework',\n",
       " 'Reclaimed',\n",
       " 'Approved Document L2A',\n",
       " 'Approved Document L1A',\n",
       " 'Approved Document L1B',\n",
       " 'Approved Document L2B',\n",
       " 'Approved Document H2',\n",
       " 'Approved Document L1A c',\n",
       " 'Approved Document H1',\n",
       " 'existing dwellings Approved Document L2A',\n",
       " 'the Water Regulations Advisory Scheme',\n",
       " 'leaflet No',\n",
       " 'Section 48',\n",
       " 'Repair',\n",
       " 'a nuisance',\n",
       " 'Drainage of',\n",
       " 'water tight',\n",
       " 'gas - tight',\n",
       " 'grout filled',\n",
       " 'Section 102',\n",
       " 'Section 104',\n",
       " 'Section 106',\n",
       " 'Agreements',\n",
       " 'Right',\n",
       " 'Requisition',\n",
       " 'Adoption',\n",
       " 'construction works',\n",
       " 'renovation works',\n",
       " 'disposal works',\n",
       " 'the exit',\n",
       " 'the storey exit',\n",
       " 'The exit',\n",
       " 'the side access',\n",
       " 'the exits',\n",
       " 'the accessible',\n",
       " 'the return wall',\n",
       " 'the guidance 5 14',\n",
       " 'the aspects 1 13',\n",
       " '- 2 25',\n",
       " 'foundation',\n",
       " 'man entry',\n",
       " 'a power failure',\n",
       " 'a septic tank',\n",
       " 'the septic tank',\n",
       " 'drainage fields',\n",
       " 'the soakage capacity',\n",
       " 'soakage capacity',\n",
       " 'drainage mounds',\n",
       " 'a drainage field',\n",
       " 'a drainage field /',\n",
       " 'waterlogged',\n",
       " 'mains drainage',\n",
       " 'watercourse',\n",
       " 'BS 8297 : 2000 Code of practice',\n",
       " 'BS 6297 : 1983 Code of practice',\n",
       " 'BS 5628 - 3 : 2001 Code of practice',\n",
       " 'a watercourse',\n",
       " 'Septic tanks',\n",
       " 'Access covers',\n",
       " 'corrosive nature',\n",
       " 'downslope',\n",
       " 'a vehicle access',\n",
       " 'free - flowing',\n",
       " 'BS EN 12566 - 1',\n",
       " 'The mortar',\n",
       " 'the mortar',\n",
       " 'cementsand ratio',\n",
       " 'BS 5328',\n",
       " 'soakaways',\n",
       " 'underground',\n",
       " 'the 300mm',\n",
       " 'the shaft',\n",
       " 'The shaft',\n",
       " 'the shafts',\n",
       " 'The shaft structure',\n",
       " 'the shaft corridor c',\n",
       " 'the hole',\n",
       " 'subsoils',\n",
       " 'soil',\n",
       " 'soils',\n",
       " 'land',\n",
       " 'mineral',\n",
       " 'groundwater',\n",
       " 'organic',\n",
       " 'smooth',\n",
       " 'sand',\n",
       " 'sediments',\n",
       " 'earth',\n",
       " 'percolation characteristics',\n",
       " 'a soakaway',\n",
       " 'shingle',\n",
       " 'vents',\n",
       " 'venting',\n",
       " 'vent',\n",
       " 'seepage',\n",
       " 'm long',\n",
       " 'm wide',\n",
       " 'ammonia',\n",
       " 'the gravel bed',\n",
       " 'Horizontal flow systems',\n",
       " 'reed beds',\n",
       " 'plant',\n",
       " 'leaves',\n",
       " 'plants',\n",
       " 'roots',\n",
       " 'leaf',\n",
       " 'BRE Good Building Guide No',\n",
       " 'Marking',\n",
       " 'building owners',\n",
       " 'building owner',\n",
       " 'building occupants',\n",
       " 'flushing',\n",
       " 'wetting',\n",
       " 'emptying',\n",
       " 'a licensed contractor',\n",
       " 'fortnightly',\n",
       " 'small sewage treatment works',\n",
       " 'Offences',\n",
       " 'polluting',\n",
       " 'the Water Resources Act',\n",
       " 'lake',\n",
       " 'the Public Health Act 1936',\n",
       " 'settlement tank',\n",
       " 'the inflow',\n",
       " 'the overflow',\n",
       " 'inflow',\n",
       " 'the pores',\n",
       " 'a monthly basis',\n",
       " 'the occupier',\n",
       " 'the occupiers',\n",
       " 'the first occupier',\n",
       " 'principal entrance',\n",
       " 'Principal entrance',\n",
       " 'rainfall intensity',\n",
       " 'a gutter',\n",
       " 'the gutter',\n",
       " 'parapet gutters',\n",
       " 'flat roof',\n",
       " 'Flat roof',\n",
       " 'flat roofs',\n",
       " 'sheet roof',\n",
       " 'a rainwater pipe',\n",
       " 'Information about',\n",
       " 'rainwater drainage systems',\n",
       " 'catchments',\n",
       " 'channels',\n",
       " 'a detention tank',\n",
       " 'paragraph 3 18',\n",
       " 'paragraph 3 6',\n",
       " 'paragraph 3 24',\n",
       " 'paragraph 3 11',\n",
       " 'paragraph 3 29',\n",
       " 'paragraph 3 28',\n",
       " 'paragraph 3 34',\n",
       " 'paragraph 3 36',\n",
       " 'paragraph 3 2',\n",
       " 'paragraph 3 1',\n",
       " 'larger areas',\n",
       " 'oil separators',\n",
       " 'Safety Executive',\n",
       " 'disposal main',\n",
       " 'the owner',\n",
       " 'The owner',\n",
       " 'the owners',\n",
       " 'vesting',\n",
       " 'appendix H1 - C paragraph C 7',\n",
       " 'the consent',\n",
       " 'the waste collection authority',\n",
       " 'Section 46',\n",
       " 'Section 47',\n",
       " 'Section 45',\n",
       " 'industrial waste',\n",
       " 'commercial waste',\n",
       " 'household waste',\n",
       " 'waste containers',\n",
       " 'shelter',\n",
       " 'rail',\n",
       " 'rails',\n",
       " 'railway',\n",
       " 'Rails',\n",
       " 'pedestrian',\n",
       " 'amenity',\n",
       " 'an wall',\n",
       " 'an floor',\n",
       " 'a surface',\n",
       " 'a wall common',\n",
       " 'an layer',\n",
       " 'a ceiling',\n",
       " 'an enclosure',\n",
       " 'An wall',\n",
       " 'These walls',\n",
       " 'Enclosures',\n",
       " 'recyclable',\n",
       " 'a polluted',\n",
       " 'disuse',\n",
       " 'secure containers',\n",
       " 'the top bottom',\n",
       " 'a top bottom',\n",
       " 'Drain and',\n",
       " 'amd 14640 2003',\n",
       " 'amd 15040 2004',\n",
       " 'amd 10440 1999',\n",
       " 'amd 14639 2003',\n",
       " 'Vitrified clay pipes',\n",
       " 'pipe joints',\n",
       " 'joints',\n",
       " 'movement joints',\n",
       " 'copper tubes',\n",
       " 'Plumbing fittings',\n",
       " 'compression ends',\n",
       " 'cast iron spigot',\n",
       " 'Generalities',\n",
       " 'buried pipelines',\n",
       " 'Plastics piping systems',\n",
       " 'AMD 10984 2000',\n",
       " 'AMD 13189 2001',\n",
       " 'Unplasticized',\n",
       " 'PVC - U )',\n",
       " 'Hydraulic design',\n",
       " 'amd 15442 2005',\n",
       " 'high temperature',\n",
       " 'Polypropylene',\n",
       " 'building structure',\n",
       " 'building design',\n",
       " 'building construction',\n",
       " 'building sites',\n",
       " 'internal structure',\n",
       " 'vinyl chloride',\n",
       " 'poly',\n",
       " 'amd 13815 2002',\n",
       " 'amd 13018 2000',\n",
       " 'amd 7114 1992',\n",
       " 'unreinforced',\n",
       " 'BS EN 1917 : 2002 Concrete manholes',\n",
       " 'amd 15359 2004',\n",
       " 'amd 15289 2004',\n",
       " 'amd 15406 2004',\n",
       " 'amd 14857 2004',\n",
       " 'amd 13189 2001',\n",
       " 'amd 15333 2004',\n",
       " 'jacking pipes',\n",
       " 'steel fibre',\n",
       " 'Glass fibre',\n",
       " 'Gravity drainage systems',\n",
       " 'Layout',\n",
       " 'Lifting',\n",
       " 'Other publications',\n",
       " 'WRAS',\n",
       " 'www netregs gov uk',\n",
       " 'carbon monoxide alarms',\n",
       " 'solid fuel appliances',\n",
       " 'older houses',\n",
       " 'liquid biofuel',\n",
       " 'solid biofuel',\n",
       " 'liquid biofuel conform',\n",
       " 'mineral oil',\n",
       " 'heating oil',\n",
       " 'secondary containment',\n",
       " 'informative',\n",
       " 'relining',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c506907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply adding the extracted spans\n",
    "for span in domain_terms:\n",
    "    span_uid, new_uid_bool = ua.assign_UID(span, SPANS)\n",
    "    \n",
    "    if new_uid_bool:\n",
    "        irec_graph = irec_span(irec_graph, span_uid, span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c4c91",
   "metadata": {},
   "source": [
    "### Add Acronyms that were grabbed from the text\n",
    "\n",
    "These can help:\n",
    "* remove terms where the boundary detection is off\n",
    "* avoid suggesting similar acronyms, e.g., suggest that EPC and EPS are similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434b8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = {'PAS': ['ecification', 'Specification'],  'GSIUR': ['Regulations 1998'],  'HSE': ['Regulations 2000',   'water systems',   'Safety Executive',   'Health and Safety Executive'],  'PE': ['Polyethylene', 'polyethylene'],  'DN': ['pipe'],  'DCLG': ['land', 'Local Government', 'England', 'ment'],  'PP': ['Polypropylene'],  'BCB': ['Control Body',   'the building control body',   'Building control body',   'building control body',   'Building Control Body'],  'SRHRV': ['ventilator',   'single room heat recovery ventilator',   'a single room heat recovery ventilator'],  'MVHR': ['blocks', 'heat recovery'],  'WC': ['sets'],  'TFA': ['the total floor area'],  'LRV': ['Light reflectance value'],  'BER': ['Building CO2 Emission Rate', 'CO2 Emission Rate'],  'TER': ['CO2 Emission Rate',   'the Target CO2 Emission Rate',   'Target CO2 Emission Rate'],  'DER': ['CO2 Emission Rate', 'the Dwelling CO2 Emission Rate'],  'EPC': ['energy performance certificate'],  'TFEE': ['Target Fabric Energy Efficiency',   'Fixed building services',   'Energy Efficiency'],  'DHF': ['the Door and Hardware Federation', 'Door and Hardware Federation'],  'REI': ['fire resistance', 'bility'],  'PHE': ['horizontal evacuation'],  'W': ['the final exit', 'final exit'],  'DWELLINGS': ['RESIDENTIAL'],  'OTHER': ['RESIDENTIAL'],  'TSO': ['Office', 'The Stationery Office'],  'FPA': ['the Fire Protection Association', 'Association'],  'A': ['absorption area'],  'AT': ['absorption area'],  'DECC': ['Climate Change'],  'NCM': ['the National Calculation Methodology'],  'ADCAS': ['Allied Services'],  'DFEE': ['Energy Efficiency'],  'LPA': ['the local planning authority', 'planning authority'],  'UKAS': ['the United Kingdom Accreditation Service'],  'BSI': ['the British Standards Institution'],  'EA': ['Accreditation'],  'BGS': ['British Geological Survey'],  'HBN': ['Notes'],  'GGF': ['Glazing Federation'],  'E': ['terms of integrity'],  'TRADA': ['the Timber Research and Development Association', 'Association'],  'ACOP': ['Code of Practice'],  'ATTMA': ['Association'],  'RVA': ['Association', 'the Residential Ventilation Association'],  'TEHVA': ['Association'],  'DSA': ['Association'],  'CIRIA': ['Association'],  'MCRMA': ['Association'],  'DSMA': ['Association'],  'OFTEC': ['Association'],  'WHO': ['Organisation'],  'GAI': ['Architectural Ironmongers'],  'MEV': ['mechanical extract', 'extract ventilation'],  'VST': ['Vicat softening temperature'],  'SCI': ['Guild Steel Construction Institute'],  'FBE': ['the Built Environment', 'ment'],  'DSER': ['Rating'],  'WER': ['Rating'],  'CIWM': ['ment', 'Wastes Management'],  'EOTA': ['ment'],  'GQRA': ['ment'],  'BRE': ['ment', 'the Building Research Establishment'],  'PPS': ['ment'],  'PSV': ['Passive stack ventilation'],  'EST': ['the Energy Saving Trust'],  'CIBSE': ['Ventilation hygiene toolkit', 'Building Services Engineers'],  'AGS': ['Geoenvironmental Specialists'],  'SPAB': ['Ancient Buildings'],  'UF': ['urea formaldehyde'],  'ODPM': ['the Deputy Prime Minister']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf33be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for acronym, spans in acronyms.items():\n",
    "    \n",
    "    acronym_uid, new_uid_bool = ua.assign_UID(acronym, SPANS)\n",
    "    if new_uid_bool:\n",
    "        # many of these will be in the graph already\n",
    "        irec_graph = irec_span(irec_graph, acronym_uid, acronym)\n",
    "    \n",
    "    for span in spans:\n",
    "        # these are all part of the graph already\n",
    "        span_uid, _ = ua.assign_UID(span, SPANS) \n",
    "        \n",
    "        # todo; \n",
    "        #  could do some filtering here of the clearly erroneous span-acronym combinations\n",
    "        #  or leave this until later, using the graph...\n",
    "    \n",
    "        if (SPANS[acronym_uid], IREC.isAcronymOf, SPANS[span_uid]) not in irec_graph:\n",
    "            irec_graph = irec_is_acronym_of(irec_graph, acronym_uid, span_uid)\n",
    "            irec_graph = irec_has_acronym(irec_graph, span_uid, acronym_uid)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c8e57",
   "metadata": {},
   "source": [
    "### Add CONCEPTS: defined terms from the Approved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af2368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "definitions = pd.read_excel(\"data/Approved Documents and derived terms.xlsx\", sheet_name=\"Definitions\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77530dc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Alternative labels</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absorption</td>\n",
       "      <td>Conversion of sound energy to heat, often by t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Absorption coefficient</td>\n",
       "      <td>A quantity characterising the effectiveness of...</td>\n",
       "      <td></td>\n",
       "      <td>See BS EN 20354:1993.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absorptive material</td>\n",
       "      <td>Material that absorbs sound energy.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Term                                         Definition  \\\n",
       "0              Absorption  Conversion of sound energy to heat, often by t...   \n",
       "1  Absorption coefficient  A quantity characterising the effectiveness of...   \n",
       "2     Absorptive material                Material that absorbs sound energy.   \n",
       "\n",
       "  Alternative labels                   Note  \n",
       "0                                            \n",
       "1                     See BS EN 20354:1993.  \n",
       "2                                            "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cbdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_terms = pd.read_excel(\"data/Approved Documents and derived terms.xlsx\", sheet_name=\"Index terms\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355c9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo; below, perhaps check existince of relations to avoid duplication, e.g.;\n",
    "# if (SPANS[acronym_uid], IREC.isAcronymOf, SPANS[span_uid]) not in irec_graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d066368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph from definitions first\n",
    "for i, row in definitions.iloc[1:].iterrows():\n",
    "    term = row['Term'] if row['Term'].isupper() else row['Term'].lower()\n",
    "    alternative_labels = row['Alternative labels']\n",
    "    definition = row['Definition']\n",
    "    note = row['Note']\n",
    "    \n",
    "    # add the term \n",
    "    concept_uid, new_uid = ua.assign_UID(term, CONCEPTS)\n",
    "    if new_uid:\n",
    "        irec_graph = skos_node(irec_graph, concept_uid, term)\n",
    "    \n",
    "    if note: \n",
    "        irec_graph = skos_note(irec_graph, concept_uid, note) \n",
    "    \n",
    "    # always expecting a definition\n",
    "    irec_graph = skos_definition(irec_graph, concept_uid, definition) \n",
    "    \n",
    "    if alternative_labels:\n",
    "        # lowercase if not an abbreviation\n",
    "        alt_labels = [x.strip() if x.isupper() else x.lower().strip() for x in alternative_labels.split(\", \")]  \n",
    "        \n",
    "        for alt_label in alt_labels:\n",
    "            # treated like a span, that refers to the same concept <-- this is a deviation from previously\n",
    "            alt_label_uid, new_uid = ua.assign_UID(alt_label, SPANS)\n",
    "            if new_uid:\n",
    "                irec_graph = irec_span(irec_graph, alt_label_uid, alt_label)\n",
    "        \n",
    "            irec_graph = skos_altLabel(irec_graph, concept_uid, alt_label_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ddb6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>AltLabel(s)</th>\n",
       "      <th>Related terms</th>\n",
       "      <th>Broader term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbreviated eaves</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>eaves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Access floors</td>\n",
       "      <td>access floor</td>\n",
       "      <td>Platform floors</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access for fire service</td>\n",
       "      <td>fire access</td>\n",
       "      <td></td>\n",
       "      <td>Fire service facilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term   AltLabel(s)    Related terms  \\\n",
       "0        abbreviated eaves                                  \n",
       "1            Access floors  access floor  Platform floors   \n",
       "2  Access for fire service   fire access                    \n",
       "\n",
       "              Broader term  \n",
       "0                    eaves  \n",
       "1                           \n",
       "2  Fire service facilities  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_terms[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f1358bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add triples from index terms / glossaries\n",
    "# we will treat glossary terms like concepts, relations between their labels occur between the spans \n",
    "for i, row in index_terms.iloc[1:].iterrows():\n",
    "    term = row['Term'].strip() if row['Term'].isupper() else row['Term'].lower().strip()\n",
    "    alternative_labels = row['AltLabel(s)']\n",
    "    related_terms = row['Related terms']\n",
    "    broader_term = row['Broader term']\n",
    "    \n",
    "    # add the term \n",
    "    concept_uid, new_uid = ua.assign_UID(term, CONCEPTS)\n",
    "    if new_uid:\n",
    "        irec_graph = skos_node(irec_graph, concept_uid, term)\n",
    "        # hacky visualisation solution; connect all terms to the graph root -> need to find a better solution\n",
    "        # hacky visualisation solution; connect all terms to the graph root\n",
    "        # hacky visualisation solution; connect all terms to the graph root\n",
    "        irec_graph = add_top_concept(irec_graph, concept_uid)\n",
    "\n",
    "    if alternative_labels:\n",
    "        # lowercase if not an abbreviation\n",
    "        alt_labels = [x.strip() if x.isupper() else x.lower().strip() for x in alternative_labels.split(\", \")]  \n",
    "        \n",
    "        for alt_label in alt_labels:\n",
    "            # treated like a span, that refers to the same concept <-- this is a deviation from previously\n",
    "            alt_label_uid, new_uid = ua.assign_UID(alt_label, SPANS)\n",
    "            if new_uid:\n",
    "                irec_graph = irec_span(irec_graph, alt_label_uid, alt_label)\n",
    "                \n",
    "            irec_graph = skos_altLabel(irec_graph, concept_uid, alt_label_uid)\n",
    "\n",
    "    if related_terms:\n",
    "        rel_terms = [x.strip() if x.isupper() else x.lower().strip() for x in related_terms.split(\", \")]\n",
    "        for rel_term in rel_terms:\n",
    "            related_uid, new_uid = ua.assign_UID(rel_term, SPANS)\n",
    "            if new_uid:\n",
    "                irec_graph = irec_span(irec_graph, related_uid, rel_term)\n",
    "                \n",
    "            irec_graph = irec_related(irec_graph, concept_uid, related_uid)\n",
    "    \n",
    "    if broader_term:\n",
    "        # We expect 1 broader term at most currently, assuming we'd like a tree structure (DAG with 1 parent at most)\n",
    "        b_term = broader_term.strip().lower() if not broader_term.isupper() else broader_term.strip()\n",
    "        b_term_uid, new_uid = ua.assign_UID(b_term, SPANS)\n",
    "        if new_uid:\n",
    "            irec_graph = irec_span(irec_graph, b_term_uid, b_term)\n",
    "\n",
    "        # We do not expect that the broader term is necessarily a concept, although this is a feature we may rely on later\n",
    "        irec_graph = skos_broader(irec_graph, concept_uid, b_term_uid, CONCEPTS, SPANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d8b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40952822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irec_graph.serialize(destination=\"graph/approved_doc_terms_only.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80038a",
   "metadata": {},
   "source": [
    "### Print some insight in the graph so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14daa5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in 'http://example.org/irec-spans/': 12264\n"
     ]
    }
   ],
   "source": [
    "ua.count_nodes_in_namespace(SPANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "204cfd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in 'http://example.org/irec-concepts/': 849\n"
     ]
    }
   ],
   "source": [
    "ua.count_nodes_in_namespace(CONCEPTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41733c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 ; type ; Concept\n",
      "291 ; prefLabel ; wet room\n",
      "291 ; note ; For the purposes of Part F, sanitary accommodation is also regarded as a wet room.\n",
      "291 ; definition ; A room used for domestic activities (such as cooking, clothes washing and bathing) which give rise to significant production of airborne moisture, e.g. a kitchen, utility room or bathroom. \n",
      "291 ; definition ; WC or bathroom compartment with tanking and drainage laid to fall to a connected gulley capable of draining the floor area when used as a shower.\n"
     ]
    }
   ],
   "source": [
    "ua.print_node_by_id(irec_graph, 291, CONCEPTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91b677bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanitary%20accommodation ; type ; Span\n",
      "sanitary%20accommodation ; label ; sanitary accommodation\n"
     ]
    }
   ],
   "source": [
    "ua.print_node_by_id(irec_graph, urllib.parse.quote('sanitary accommodation'), SPANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "492a5fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanitary%20accommodation ; type ; Span\n",
      "sanitary%20accommodation ; label ; sanitary accommodation\n"
     ]
    }
   ],
   "source": [
    "ua.print_node_by_text(irec_graph, 'sanitary accommodation', SPANS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407358e6",
   "metadata": {},
   "source": [
    "### Grab wikipedia definitions for Concept nodes, and store locally for re-use\n",
    "* We have previously annotated the relevance of all WikiData classes returned for the defined terms and index terms in the Approved Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5003abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_wikidata_classes_df = pd.read_csv(\"data/wiki_classes_annotated.csv\", index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b22d3027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiData class</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Example spans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WikiData UIDs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['Q107715']</th>\n",
       "      <td>physical quantity</td>\n",
       "      <td>y</td>\n",
       "      <td>['sound pressure level', 'density', 'area', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Q82799']</th>\n",
       "      <td>name</td>\n",
       "      <td>n</td>\n",
       "      <td>['access point']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Q180160']</th>\n",
       "      <td>metadata</td>\n",
       "      <td>n</td>\n",
       "      <td>['access point']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  WikiData class Annotation  \\\n",
       "WikiData UIDs                                 \n",
       "['Q107715']    physical quantity          y   \n",
       "['Q82799']                  name          n   \n",
       "['Q180160']             metadata          n   \n",
       "\n",
       "                                                   Example spans  \n",
       "WikiData UIDs                                                     \n",
       "['Q107715']    ['sound pressure level', 'density', 'area', 's...  \n",
       "['Q82799']                                      ['access point']  \n",
       "['Q180160']                                     ['access point']  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_wikidata_classes_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a327b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiclass_dict = {}\n",
    "for row in annotated_wikidata_classes_df.iterrows():\n",
    "    uid_list_string, class_annotations_examples = row\n",
    "    uid_list = uid_list_string[2:-2].split(',')\n",
    "    for uid in uid_list:\n",
    "        wikiclass_dict[uid] = {\n",
    "            'Class': class_annotations_examples['WikiData class'],\n",
    "            'Annotation': class_annotations_examples['Annotation'],\n",
    "            'Example spans': class_annotations_examples['Example spans']\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83da4c",
   "metadata": {},
   "source": [
    "* First, we try to grab all wiki definitions for all spans and concepts that are in the graph (so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2e41964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the SPARQL endpoint for wikidata\n",
    "\n",
    "sparql_wrapper = SPARQLWrapper(\"https://query.wikidata.org/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12e9e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_matches(graph_sparql_endpoint: SPARQLWrapper,\n",
    "                     jargon_term_and_uids: List):\n",
    "\n",
    "    all_wiki_definitions = {}\n",
    "    # we want to grab the term (subject), any definition (subjectDescription) and the class (subjectClass)\n",
    "    sparql_q = \"\"\"\n",
    "               SELECT ?subject ?subjectDescription ?classUID ?className WHERE {\n",
    "                  ?subject rdfs:label \"$QUERY\"@en.\n",
    "                  ?subject wdt:P31|wdt:P279 ?classUID.\n",
    "                  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\".}\n",
    "                  ?classUID  rdfs:label ?className  FILTER(LANG(?className) = \"en\").\n",
    "                }\n",
    "               \"\"\"\n",
    "    \n",
    "    for term, uid in tqdm(jargon_term_and_uids):\n",
    "        # make the call to \n",
    "        temp_q = sparql_q.replace(\"$QUERY\", term)\n",
    "        graph_sparql_endpoint.setQuery(temp_q)\n",
    "        graph_sparql_endpoint.setReturnFormat(JSON)\n",
    "        try:\n",
    "            json_output = graph_sparql_endpoint.query().convert()\n",
    "        except:\n",
    "            # If no result, wait 2s; One client is allowed 30 error queries per minute\n",
    "            print(f\"Error for query, you should what's wrong with the term: {term}\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "        # sometimes multiple Wiki UIDs for a single term, we grab them all here\n",
    "        bindings = [v for v in json_output['results']['bindings']]\n",
    "            \n",
    "\n",
    "        for v in bindings:\n",
    "            class_uid = v['classUID']['value'] if 'classUID' in v else \"\"\n",
    "            class_label = v['className']['value'] if 'className' in v else \"\"\n",
    "            \n",
    "            if 'subjectDescription' in v:\n",
    "                if uid not in all_wiki_definitions:\n",
    "                    all_wiki_definitions[uid] = [{'prefLabel': term,\n",
    "                                                  'class_uid': class_uid,\n",
    "                                                  'class_label': class_label,\n",
    "                                                  'WikiUID': v['subject']['value'],\n",
    "                                                  'WikiDefinition': v['subjectDescription']['value']}]\n",
    "                else:\n",
    "                    all_wiki_definitions[uid].append({'prefLabel': term,\n",
    "                                                      'class_uid': class_uid,\n",
    "                                                      'class_label': class_label,\n",
    "                                                      'WikiUID': v['subject']['value'],\n",
    "                                                      'WikiDefinition': v['subjectDescription']['value']})\n",
    "            elif 'subject' in v:\n",
    "                # no description found, simply adding wiki UID if that exists\n",
    "                if uid not in all_wiki_definitions:\n",
    "                    all_wiki_definitions[uid] = [{'prefLabel': term,\n",
    "                                                  'class_uid': class_uid,\n",
    "                                                  'class_label': class_label,\n",
    "                                                  'WikiUID': v['subject']['value']}]\n",
    "                else:\n",
    "                    all_wiki_definitions[uid].append({'prefLabel': term,\n",
    "                                                      'class_uid': class_uid,\n",
    "                                                      'class_label': class_label,\n",
    "                                                      'WikiUID': v['subject']['value']})\n",
    "    return all_wiki_definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4522bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_and_uids = [(k, v) for k, v in ua.UIDs[CONCEPTS.placeholder.defrag().__reduce__()[1][0]].items()]\n",
    "spans_and_uids = [(k, v) for k, v in ua.UIDs[SPANS.placeholder.defrag().__reduce__()[1][0]].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07f55352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run for the Concepts\n",
    "if not os.path.exists(\"data/concept_wiki_dict.json\"):\n",
    "    wiki_dict = get_wiki_matches(sparql_wrapper, concepts_and_uids)#{'test': 1, 'conductor':2})\n",
    "    with open(\"data/concept_wiki_dict.json\", 'w') as f:\n",
    "        json.dump(wiki_dict, f, indent=2)\n",
    "else:\n",
    "    with open(\"data/concept_wiki_dict.json\", 'r') as f:\n",
    "        wiki_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b368865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▍                                                                                                                                                    | 950/12264 [03:19<56:50,  3.32it/s]"
     ]
    }
   ],
   "source": [
    "# Now run for the spans\n",
    "if not os.path.exists(\"data/span_wiki_dict.json\"):\n",
    "    wiki_dict = get_wiki_matches(sparql_wrapper, spans_and_uids)#{'test': 1, 'conductor':2})\n",
    "    with open(\"data/span_wiki_dict.json\", 'w') as f:\n",
    "        json.dump(wiki_dict, f, indent=2)\n",
    "else:\n",
    "    with open(\"data/span_wiki_dict.json\", 'r') as f:\n",
    "        wiki_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b98fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7f6d951",
   "metadata": {},
   "source": [
    "TODO\n",
    "* parse WikiData definitions and add spans!\n",
    "* link definitions to spans (if span occurs, link),\n",
    "* create concepts for the 500ish spans that occur in Uniclass\n",
    "* compute span properties \n",
    "  * constitutes; x occurs in y, thus y might be an extended phrase for x and perhaps a subclass, or x may be a material property, and so on\n",
    "  * morphological similarity, x may be an inflection of y\n",
    "  * semantic similarity, x and y might be alternative labels or have the same superclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2866f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - create a new node for the wikipedia term, with prefLabel the term\n",
    "for uid, wiki_def_dict_list in expanded_dict.items():\n",
    "    \n",
    "    # we will only take into account the 1st definition for now!\n",
    "    # we will only take into account the 1st definition for now!\n",
    "    # we will only take into account the 1st definition for now!\n",
    "    idx = 0\n",
    "    d = wiki_def_dict_list[idx]\n",
    "    \n",
    "    term = d['prefLabel']\n",
    "    wiki_uid = d['WikiUID'].rsplit('/',1)[1]\n",
    "    if 'WikiDefinition' in d:\n",
    "        if wiki_definition == \"Wikimedia disambiguation page\":\n",
    "            # skip disambiguation pages in general\n",
    "            continue\n",
    "        \n",
    "        definition = d['WikiDefinition']\n",
    "        spar_objects = d['WikiDef_terms']\n",
    "        mygraph = add_wiki_exact_match(mygraph, term, uid, wiki_uid, definition, spar_objects)\n",
    "    else:\n",
    "        print(f\"Term with wiki exact match, but without definition: {term}\")\n",
    "        mygraph = add_wiki_exact_match(mygraph, term, uid, wiki_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_wiki_exact_match(graph, term, mygraph_uid, wiki_uid, wiki_definition=None, spar_objects=None):\n",
    "#     graph.add((EX[mygraph_uid], SKOS.exactMatch, WIKI[wiki_uid]))\n",
    "#     graph.add((WIKI[wiki_uid], SKOS.prefLabel, Literal(term, lang='en')))\n",
    "#     if wiki_definition:\n",
    "#         graph.add((WIKI[wiki_uid], SKOS.definition, Literal(wiki_definition, lang='en')))\n",
    "#     if spar_objects:\n",
    "#         for obj in spar_objects:\n",
    "#             # UIDs for these terms are assigned within our EXAMPLE namespace\n",
    "#             def_term_uid, new_uid_bool = ua.assign_UID(def_term)\n",
    "#             if new_uid_bool:\n",
    "#                 mygraph = add_prefLabel(mygraph, def_term_uid, def_term)\n",
    "            \n",
    "#             graph.add((WIKI[wiki_uid], SKOS.related, EX[def_term_uid]))\n",
    "#             graph.add((EX[def_term_uid], SKOS.related, WIKI[wiki_uid]))\n",
    "            \n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03886a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdeed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ecbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49fc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b5c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "732800f8",
   "metadata": {},
   "source": [
    "### Step 1: create a graph from the approved documents terms file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e978d7",
   "metadata": {},
   "source": [
    "### Step 3: parse all definitions, in order to identify new nodes and links between nodes\n",
    "* we won't re-define the new nodes (again), because we assume that this would cause too much drift?\n",
    "* should check to make sure that that's the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83372d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo; change to a local parser, see term extraction notebook\n",
    "\n",
    "def parse_definition(full_definition):\n",
    "    definition_sentences = [str(sent) for sent in TextBlob(full_definition).sentences]\n",
    "    identified_objects = []\n",
    "    for definition_sent in definition_sentences:\n",
    "        encoded_def = urllib.parse.quote(definition_sent)\n",
    "        spar_output = requests.get(f\"http://localhost:8000/predict_objects/{encoded_def}\").json()\n",
    "        try:\n",
    "            spar_objects = spar_output[\"prediction\"]['obj']\n",
    "            identified_objects += util.custom_cleaning_rules(spar_objects)\n",
    "        except:\n",
    "            continue\n",
    "    return identified_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98cba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in complete_dict.items():\n",
    "    # run spar.txt on definition\n",
    "    full_definition = v['definition']\n",
    "    # should break up into sentences\n",
    "    definition_sentences = [str(sent) for sent in TextBlob(full_definition).sentences]\n",
    "    complete_dict[k]['def_terms'] = []\n",
    "    \n",
    "    for definition_sent in definition_sentences:\n",
    "        encoded_def = urllib.parse.quote(definition_sent)\n",
    "        spar_output = requests.get(f\"http://localhost:8000/predict_objects/{encoded_def}\").json()\n",
    "        try:\n",
    "            spar_objects = spar_output[\"prediction\"]['obj']\n",
    "            cleaned_objs = util.custom_cleaning_rules(spar_objects)\n",
    "            for obj in cleaned_objs:\n",
    "                complete_dict[k]['def_terms'] += cleaned_objs\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd5b3b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lp/l_mzhpjs6bg95plfkl_n_vsc0000gn/T/ipykernel_6026/1466942311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mobject_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lp/l_mzhpjs6bg95plfkl_n_vsc0000gn/T/ipykernel_6026/1054273634.py\u001b[0m in \u001b[0;36mparse_definition\u001b[0;34m(full_definition)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdefinition_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefinition_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mencoded_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mspar_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"http://localhost:8000/predict_objects/{encoded_def}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mspar_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspar_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/haystack/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# approved_documents\n",
    "object_dict = {}\n",
    "for row in definitions.iterrows():\n",
    "    idx, (term, definition, alt_labels, note) = row\n",
    "    objects = parse_definition(definition)\n",
    "    \n",
    "    object_dict[term] = objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "739d3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Conversion of sound energy to heat, often by t...\n",
       "1    A quantity characterising the effectiveness of...\n",
       "2                  Material that absorbs sound energy.\n",
       "Name: Definition, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#     term = term if term.isupper() else term\n",
    "    \n",
    "#     for obj in objects:\n",
    "#         obj = obj if obj.isupper() else obj\n",
    "#         # add the object to the graph \n",
    "#         obj_uid, new_uid = ua.assign_UID(obj)\n",
    "#         if new_uid:\n",
    "#             mygraph = add_prefLabel(mygraph, obj_uid, obj)\n",
    "        \n",
    "#         # add relation between term and mygraph\n",
    "            \n",
    "      # ====      \n",
    "#     def add_related(graph, jargon_uid, other_term_uid, jargon_namespace: Namespace=JARGON, related_namespace: Namespace=JARGON):\n",
    "#     graph.add((jargon_namespace[jargon_uid], SKOS.related, related_namespace[other_term_uid]))\n",
    "#     graph.add((related_namespace[other_term_uid], SKOS.related, jargon_namespace[jargon_uid]))\n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22864cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6d627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da428b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff71a8d7",
   "metadata": {},
   "source": [
    "### Step 4: Add relevant wikipedia nodes and to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f79113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO merge same defintion, us rdfs:a \n",
    "# TODO merge same defintion, us rdfs:a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ec590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da37ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600fd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d33d1178",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9290c9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
