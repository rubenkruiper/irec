{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788a8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM cuda not found, defaulting to sklearn CPU version of kmeans\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, List, Any, Optional, Dict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import urllib\n",
    "import requests\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from threading import current_thread\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "try:\n",
    "    from libKMCUDA import kmeans_cuda\n",
    "except:\n",
    "    print(\"KM cuda not found, defaulting to sklearn CPU version of kmeans\")\n",
    "    kmeans_cuda = None\n",
    "\n",
    "from utils import cleaning_utils\n",
    "from utils import cluster_utils\n",
    "from utils import IDF_computation\n",
    "from utils import embedding_utils as embedding\n",
    "from utils.customdocument import CustomDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081bf43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "We will run our term extraction on the Merged Approved Documents, the .pdf file can be found in the `data/` directory. For filtering of out-of-domain terms we will also process a set of EU regulations for medical device design, the .html files for these can be found in the same directory.\n",
    "</div>\n",
    "\n",
    "1. Preprocessing will consist only of removing headers/footers from PDF files. \n",
    "\n",
    "2. Candidate terms are identified using SPaR.txt (Kruiper et al., 2021), sentence splitting is done with the PunkSentTokenizer (Strunk, 2006).\n",
    "\n",
    "3. Filtering of term candidates consists of:\n",
    "  * a set of regular expressions found in utils.py\n",
    "  * clustering of terms found in (1) the Approved Documents, and (2) a set of EU regulations for medical device design; any clusters containing terms from (2) will be designated as terms that are irrelevant to the AEC domain.\n",
    "  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a98d0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1 Preprocessing: get text from PDF and HTML\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Here, we grab the text from our foreground and background corpora.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f74d6fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved Documents: data/input/The Merged Approved Documents.pdf\n",
      "Reference corpus: ['data/input/EUR-Lex - 31993L0042 - EN.html', 'data/input/CELEX 32017R0746 EN TXT.html', 'data/input/CELEX 32017R0745 EN TXT.html', 'data/input/EUR-Lex - 31998L0079 - EN.html', 'data/input/EUR-Lex - 31990L0385 - EN.html']\n"
     ]
    }
   ],
   "source": [
    "merged_approved_pdf_file = glob.glob(\"data/input/*.pdf\")[0]\n",
    "eu_html_files = glob.glob(\"data/input/*.html\")\n",
    "print(f\"Approved Documents: {merged_approved_pdf_file}\")\n",
    "print(f\"Reference corpus: {eu_html_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bdc02",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "First we grab the text from the Merged Approved Documents pdf file. Our implementation on based on the pdf conversion pipeline in Haystack.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0d20e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path: Path, layout: bool = True, encoding: Optional[str] = \"Latin1\") -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract pages from the pdf file at file_path; based on Haystack.\n",
    "\n",
    "        :param file_path: path of the pdf file\n",
    "        :param layout: whether to retain the original physical layout for a page. If disabled, PDF pages are read in\n",
    "                       the content stream order.\n",
    "        \"\"\"\n",
    "        if layout:\n",
    "            command = [\"pdftotext\", \"-enc\", encoding, \"-layout\", str(file_path), \"-\"]\n",
    "        else:\n",
    "            command = [\"pdftotext\", \"-enc\", encoding, str(file_path), \"-\"]\n",
    "        output = subprocess.run(command, stdout=subprocess.PIPE, shell=False)  # type: ignore\n",
    "        document = output.stdout.decode(errors=\"ignore\")\n",
    "        pages = document.split(\"\\f\")\n",
    "        pages = pages[:-1]  # the last page in the split is always empty.\n",
    "        return pages\n",
    "\n",
    "def convert_pdf_to_mydoc(source_file_path: Path, \n",
    "                         output_file_path: Path, \n",
    "                         meta: Optional[Dict[str, str]] = None,\n",
    "                         remove_header_and_footer: Optional[bool] = True,\n",
    "                         clean_whitespace: Optional[bool] = True,\n",
    "                         clean_empty_lines: Optional[bool] = True,\n",
    "                         encoding: Optional[str] = \"Latin1\") -> CustomDocument:\n",
    "        \"\"\"\n",
    "        Extract pages from the pdf file at file_path; based on Haystack.\n",
    "\n",
    "        :param output_file_path:    Path to the .json file to store the converted file.\n",
    "        :param source_file_path:    Path to the .pdf file you want to convert\n",
    "        :param meta: Optional dictionary with metadata that shall be attached to all resulting documents.\n",
    "                     Can be any custom keys and values.\n",
    "        :param encoding: Encoding that will be passed as -enc parameter to pdftotext. \"Latin 1\" is the default encoding\n",
    "                         of pdftotext. While this works well on many PDFs, it might be needed to switch to \"UTF-8\" or\n",
    "                         others if your doc contains special characters (e.g. German Umlauts, Cyrillic characters ...).\n",
    "                         Note: With \"UTF-8\" we experienced cases, where a simple \"fi\" gets wrongly parsed as\n",
    "                         \"xef\\xac\\x81c\" (see test cases). That's why we keep \"Latin 1\" as default here.\n",
    "                         (See list of available encodings by running `pdftotext -listenc` in the terminal)\n",
    "        \"\"\"\n",
    "        pages = read_pdf(source_file_path, layout=True, encoding=encoding)\n",
    "\n",
    "        if not pages:\n",
    "            # empty input file\n",
    "            return None\n",
    "        \n",
    "        pages = [\"\\n\".join(p.splitlines()) for p in pages]\n",
    "\n",
    "        # splitting text happens during preprocessing, so no split_size passed here;\n",
    "        # split_size will be set to -1 during conversion.\n",
    "        document = CustomDocument(output_file_path, source_file_path, split_size=-1)\n",
    "        \n",
    "        print(\"Converted PDF file to pages of text, combining to a single CustomDocument to keep track of page nrs.\")\n",
    "        for page_idx, page in tqdm(enumerate(pages)):\n",
    "            \n",
    "            # some simple cleaning -- roughly based on haystack.\n",
    "            lines = page.splitlines()\n",
    "            if remove_header_and_footer:\n",
    "                # simplest way for removing header and footer \n",
    "                lines = lines[1:-2]\n",
    "\n",
    "            if clean_whitespace:\n",
    "                cleaned_lines = []\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    cleaned_lines.append(line)\n",
    "                text = \" \".join(cleaned_lines)\n",
    "\n",
    "            if clean_empty_lines:\n",
    "                text = re.sub(r\"\\n\\n+\", \"\\n\\n\", text)\n",
    "                text = re.sub(r\"[\\s]+\", \" \", text)\n",
    "            \n",
    "            # no splitting here yet, so simply using page_nr as a place holder and split_id is left blank\n",
    "            page_nr = str(page_idx + 1)\n",
    "            document.add_content(text=text, \n",
    "                                 page_nr=page_nr, \n",
    "                                 doc_title=source_file_path.rsplit('/',1)[1])   # we're using the pdf file name for simplicity\n",
    "\n",
    "        return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71184fcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted PDF file to pages of text, combining to a single CustomDocument to keep track of page nrs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1274it [00:00, 7683.26it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_approved_document = convert_pdf_to_mydoc(merged_approved_pdf_file, \"data/converted_documents/merged_approved.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1473ee8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum character length for a single block of text: 5537\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum character length for a single block of text: {max([len(c.text) for c in merged_approved_document.all_contents])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203400ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84117041",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Second, we grab the text from the EU regulation HTML files. Because the text in HTML files isn't split into pages, the blocks of text are much longer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bb53f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def grab_HTML_text_simple(file):\n",
    "    \"\"\"\n",
    "    All text in the EU htmls seems to be captured neatly in <p> tags, we don't care about structure currently.\n",
    "    We do remove all unicode characters, see `utils.remove_unicode_chars()`.\n",
    "    \"\"\" \n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return [cleaning_utils.remove_unicode_chars(x.text) for x in soup.body.find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6630e6ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_html_to_mydoc(source_file_path: Path, \n",
    "                          output_file_path: Path) -> CustomDocument:\n",
    "    \n",
    "    document = CustomDocument(output_file_path, source_file_path, split_size=-1)\n",
    "    document_paragraphs = []\n",
    "    list_of_paragraphs = grab_HTML_text_simple(html_file)\n",
    "    for paragraph in list_of_paragraphs:\n",
    "        if paragraph.strip() != '':\n",
    "            document_paragraphs.append(paragraph)\n",
    "    \n",
    "    for paragraph_idx, paragraph in tqdm(enumerate(document_paragraphs)):\n",
    "            # no splitting here yet, so simply using page_nr as a place holder and split_id is left blank\n",
    "            paragraph_nr = str(paragraph_idx + 1)\n",
    "            document.add_content(text=paragraph, \n",
    "                                 page_nr=paragraph_nr, \n",
    "                                 doc_title=source_file_path) # we're using the html file name for simplicity\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b68b58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/5 [00:00<?, ?it/s]\n",
      "826it [00:00, 372766.85it/s]\n",
      "\n",
      "4344it [00:00, 370371.52it/s]\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 2/5 [00:00<00:01,  2.31it/s]\n",
      "4799it [00:00, 399747.08it/s]\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3/5 [00:01<00:01,  1.71it/s]\n",
      "623it [00:00, 265905.30it/s]\n",
      "\n",
      "511it [00:00, 250355.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "eu_regulation_documents = []\n",
    "for html_file in tqdm(eu_html_files):\n",
    "    outfile = f\"data/converted_documents/{html_file.rsplit('/',1)[1]}.json\"\n",
    "    eu_regulation_documents.append(convert_html_to_mydoc(html_file, outfile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033634ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum character length for a single paragraph: 143428\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum character length for a single paragraph: {max([len(c.text) for d in eu_regulation_documents for c in d.all_contents])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77347abc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Third, if the output document doesn't exist (yet), we save the ConvertedDocument.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24237e3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "foreground_corpus = [merged_approved_document]\n",
    "background_corpus = eu_regulation_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a00ed81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in foreground_corpus + background_corpus:\n",
    "    if not os.path.exists(d.output_fp):\n",
    "        d.write_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6e56a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2 Term extraction: identify object spans with SPaR.txt\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "For each of the sentences in our corpora, we run SPaR.txt for object identification.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf22a14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# download SPaR.txt if required\n",
    "if not os.path.exists(\"SPaR.txt/README.md\"):\n",
    "    !git clone https://github.com/rubenkruiper/SPaR.txt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19aa4ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "with open('SPaR.txt/spar_predictor.py', 'rb') as fp:\n",
    "    spar_predictor = imp.load_module(\n",
    "        'spar_predictor', fp, 'SPaR.txt.spar_predictor.py',\n",
    "        ('.py', 'rb', imp.PY_SOURCE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9daef1de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# trains a model if needed, otherwise loads from archive; \n",
    "# - best F1 on dev/validation in the paper is 80,96 trained on a GPU, CPU will be a bit lower ~77.x I think\n",
    "sp = spar_predictor.SparPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a0206ea8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input: An example sentence to show how ACC terminology will be extracted from the British Standards.\n",
      "{'obj': ['An example sentence', 'ACC terminology', 'the British Standards']}\n",
      "Parsing took 1.0985469818115234\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "example = \"An example sentence to show how ACC terminology will be extracted from the British Standards.\"\n",
    "start_time = time.time()\n",
    "# prepare instance and run model on single instance\n",
    "docid = ''                  # ToDo - add doc_id during pre_processing?\n",
    "token_list = sp.predictor._dataset_reader.tokenizer.tokenize(example)\n",
    "instance = sp.predictor._dataset_reader.text_to_instance(docid,\n",
    "                                                      example,\n",
    "                                                      token_list,\n",
    "                                                      sp.predictor._dataset_reader._token_indexer)\n",
    "result = sp.predictor.predict_instance(instance)\n",
    "printable_result = sp.parse_output(result, ['obj'])\n",
    "print(f\"Example input: {example}\")\n",
    "print(printable_result)\n",
    "print(\"Parsing took {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270daa7c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* To run SPaR.txt, we split the text in our corpora into sentences. We set up multiple instances of SPaR.txt predictors to speed up the processing a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f7c27f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# These should automatically run on your Nvidia GPU if available\n",
    "class SparInstance:\n",
    "    def __init__(self):\n",
    "        self.sp = spar_predictor.SparPredictor()\n",
    "    \n",
    "    def call(self, input_str:str=''):\n",
    "        if input_str:\n",
    "            # prepare instance and run model on single instance\n",
    "            docid = ''  # ToDo - add doc_id during pre_processing?\n",
    "            token_list = self.sp.predictor._dataset_reader.tokenizer.tokenize(input_str)\n",
    "\n",
    "            # truncating the input to SPaR.txt to maximum 512 tokens\n",
    "            token_length = len(token_list)\n",
    "            if token_length > 512:\n",
    "                token_list = token_list[:511] + [token_list[-1]]\n",
    "                token_length = 512\n",
    "\n",
    "            instance = self.sp.predictor._dataset_reader.text_to_instance(docid, input_str, token_list,\n",
    "                                                              self.sp.predictor._dataset_reader._token_indexer)\n",
    "            result = self.sp.predictor.predict_instance(instance)\n",
    "            printable_result = self.sp.parse_output(result, ['obj'])\n",
    "            return {\n",
    "                    \"prediction\": printable_result,\n",
    "                    \"num_input_tokens\": token_length,\n",
    "            }\n",
    "            \n",
    "        # If the input is None, or too long, return an empty list of objects\n",
    "        return {\n",
    "                \"prediction\": {'obj': []},\n",
    "                \"num_input_tokens\": 0\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb733c61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TermExtractor:\n",
    "    \n",
    "    def __init__(self, split_length=300, max_num_cpu_threads=4):\n",
    "        \"\"\"\n",
    "        Initialise SPaR.txt predictors `max_num_cpu_threads` \n",
    "        \"\"\"\n",
    "        self.split_length = split_length   # in number of tokens\n",
    "        self.max_num_cpu_threads = max_num_cpu_threads\n",
    "        self.PREDICTORS = []\n",
    "        for i in range(max_num_cpu_threads + 1):\n",
    "            self.PREDICTORS.append(SparInstance())\n",
    "    \n",
    "    \n",
    "    def process_sentence(self, sentence: str = ''):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        predictor_to_use = int(current_thread().name.rsplit('_', 1)[1])\n",
    "        spartxt = self.PREDICTORS[predictor_to_use]\n",
    "\n",
    "        # SPaR doesn't handle ALL uppercase sentences well, which the OCR system sometimes outputs    \n",
    "        sentence = sentence.lower() if sentence.isupper() else sentence\n",
    "        prediction_dict =  spartxt.call(sentence)\n",
    "        if not prediction_dict:\n",
    "            return []\n",
    "\n",
    "        pred_labels = prediction_dict[\"prediction\"]\n",
    "        return pred_labels['obj']\n",
    "        \n",
    "\n",
    "    def split_into_sentences_and_run_spar(self, input_document):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        print(f\"Working on: {input_document.source_fp}\")\n",
    "        content_as_list_of_dicts = input_document.to_list_of_dicts()\n",
    "        total_number_of_sentences_found = 0\n",
    "        content_idx = 0\n",
    "        for content_dict in tqdm(content_as_list_of_dicts):\n",
    "\n",
    "            text = ' '.join([x for x in content_dict[\"content\"].split(' ') if x != ''])\n",
    "            # some really long paragraphs in the EU regulations are summations that should be split at ';'\n",
    "            if len(text) > 3000:\n",
    "                text = text.replace(\";\", \".\\n\")\n",
    "\n",
    "            # We'll split into sentences even if this has been done before, it doesn't take long\n",
    "            sentences = []\n",
    "            for part in text.split('\\n'):\n",
    "                # split into sentences using PunktSentTokenizer (TextBlob implements NLTK's version under the hood) \n",
    "                sentences += [str(s) for s in TextBlob(part).sentences if len(str(s)) > 10]\n",
    "\n",
    "            content_dict[\"meta\"][\"sentences\"] = '###'.join(sentences)\n",
    "                \n",
    "            total_number_of_sentences_found += len(sentences)\n",
    "\n",
    "            # process sentences in the content and add SPaR.txt object tags to the content dict.        \n",
    "            if not content_dict[\"meta\"][\"SPaR_labels\"]:\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_num_cpu_threads) as executor:\n",
    "                    futures = [executor.submit(self.process_sentence, sentences[idx]) for idx in range(len(sentences))]\n",
    "\n",
    "                content_spar_objects = [f.result() for f in futures]\n",
    "                content_dict[\"meta\"][\"SPaR_labels\"] = ', '.join([tag for tags in content_spar_objects for tag in tags])\n",
    "                \n",
    "            # immediately update the list of content_dicts and every X iterations we save the file \n",
    "            content_as_list_of_dicts[content_idx] = content_dict\n",
    "            if content_idx // 5 == 0:\n",
    "                converted_document.replace_contents(content_as_list_of_dicts)\n",
    "                converted_document.write_document()\n",
    "            \n",
    "            content_idx += 1\n",
    "\n",
    "        print(f\"Number of sentences found: {total_number_of_sentences_found}\")\n",
    "        converted_document.replace_contents(content_as_list_of_dicts)\n",
    "        converted_document.write_document()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7dc2f46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te = TermExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d086b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: data/input/The Merged Approved Documents.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1274/1274 [00:01<00:00, 812.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 17745\n",
      "Working on: data/input/EUR-Lex - 31993L0042 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 826/826 [00:00<00:00, 4072.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 1679\n",
      "Working on: data/input/CELEX 32017R0746 EN TXT.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4344/4344 [00:01<00:00, 2775.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 3405\n",
      "Working on: data/input/CELEX 32017R0745 EN TXT.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4799/4799 [00:01<00:00, 3439.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 3838\n",
      "Working on: data/input/EUR-Lex - 31998L0079 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 623/623 [00:00<00:00, 2892.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 1255\n",
      "Working on: data/input/EUR-Lex - 31990L0385 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [00:00<00:00, 4963.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run SPaR.txt on all documents and write to file\n",
    "for converted_document in foreground_corpus + background_corpus:\n",
    "    # re-load the document from file, to make sure we don't overwrite existing SPaR.txt labels\n",
    "    converted_document = converted_document.load_document(converted_document.output_fp)\n",
    "    te.split_into_sentences_and_run_spar(converted_document)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835185f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Number of sentences (longer than 10 characters) found in: <ul>\n",
    "    <li>Merged Approved documents: 17745</li>\n",
    "    <li>Background corpus (1679+3405+3838+1255+771): 10948</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b15878",
   "metadata": {},
   "source": [
    "### 3 Filtering\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The objects identified by SPaR.txt contain a lot of noise. Here, we clean and filter them; based on our background corpus we try to identify which terms belong to the AEC domain. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511762d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "First, load all terms from the processed files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fb5373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of foreground terms: 114333\n",
      "Total number of UNIQUE foreground terms: 42657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 2130),\n",
       " ('a', 930),\n",
       " ('the building', 864),\n",
       " ('buildings', 839),\n",
       " ('guidance', 522),\n",
       " ('a building', 455),\n",
       " ('the Building Regulations', 434),\n",
       " ('document', 303),\n",
       " ('people', 301),\n",
       " ('the requirements', 297)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreground_terms_lists = [c.NER_labels for d in foreground_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "foreground_terms = [t for t_list in foreground_terms_lists for t in t_list if t]\n",
    "foreground_terms_c = Counter(foreground_terms)\n",
    "print(f\"Total number of foreground terms: {len(foreground_terms)}\")\n",
    "print(f\"Total number of UNIQUE foreground terms: {len(foreground_terms_c)}\")\n",
    "foreground_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8006f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of background terms: 73124\n",
      "Total number of UNIQUE background terms: 10245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 2651),\n",
       " ('devices', 1641),\n",
       " ('the manufacturer', 1243),\n",
       " ('the device', 1187),\n",
       " ('Regulation', 624),\n",
       " ('the notified body', 595),\n",
       " ('information', 550),\n",
       " ('Member States', 489),\n",
       " ('a', 451),\n",
       " ('the market', 447)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_terms_lists = [c.NER_labels for d in background_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "background_terms = [t for t_list in background_terms_lists for t in t_list if t]\n",
    "background_terms_c = Counter(background_terms)\n",
    "print(f\"Total number of background terms: {len(background_terms)}\")\n",
    "print(f\"Total number of UNIQUE background terms: {len(background_terms_c)}\")\n",
    "background_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e79727a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique spans identified by SPaR.txt:51296\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of unique spans identified by SPaR.txt:{len(foreground_terms_c+background_terms_c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464451e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Second, clean the terms with the regular expressions we've defined in utils.py\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2503708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_filter = cleaning_utils.RegexFilter()\n",
    "def run_filters(input_counter):\n",
    "    cleaned_counter = Counter()\n",
    "    for k, v in input_counter.items():\n",
    "        # terms should occur twice at least\n",
    "        if v < 2:\n",
    "            continue\n",
    "\n",
    "        # todo; clean up these util functions and how to call them|\n",
    "        _, k = regex_filter.run_filter(k)\n",
    "        if k:\n",
    "            cleaned_k = cleaning_utils.custom_cleaning_rules(k)\n",
    "            if cleaned_k:\n",
    "                cleaned_counter[cleaned_k[0]] = v\n",
    "    return cleaned_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e42c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('guidance', 522),\n",
       " ('a building', 455),\n",
       " ('document', 303),\n",
       " ('the requirements', 297),\n",
       " ('requirements', 266),\n",
       " ('work', 242),\n",
       " ('the guidance', 240),\n",
       " ('the work', 232),\n",
       " ('Schedule 1', 226),\n",
       " ('the dwelling', 215)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_foreground_terms_c = run_filters(foreground_terms_c)\n",
    "print(len(cleaned_foreground_terms_c))\n",
    "cleaned_foreground_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "899b1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('devices', 1641),\n",
       " ('the device', 1187),\n",
       " ('the notified body', 595),\n",
       " ('Member States', 489),\n",
       " ('accordance', 429),\n",
       " ('a device', 405),\n",
       " ('conformity', 357),\n",
       " ('the requirements', 350),\n",
       " ('The notified body', 328),\n",
       " ('notified bodies', 324)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_background_terms_c = run_filters(background_terms_c)\n",
    "print(len(cleaned_background_terms_c))\n",
    "cleaned_background_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d6ca8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Third, we compute the embeddings for both foreground and background terms.\n",
    "</div>\n",
    "\n",
    "\n",
    "* Note: embeddings will be IDF weighted (IDF weights over both foreground and background corpora)\n",
    "  * Could add more sentences to the computation of IDF weights, e.g., definitions from vocabularies/WikiData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b177bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which tokenizer to use for IDF computation and Embedding;\n",
    "bert_model_name = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10278f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms_c = cleaned_foreground_terms_c + cleaned_background_terms_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f403d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16441"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_terms_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1000a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('devices', 1665),\n",
       " ('the device', 1195),\n",
       " ('the requirements', 647),\n",
       " ('accordance', 631),\n",
       " ('the notified body', 595),\n",
       " ('guidance', 539),\n",
       " ('Member States', 491),\n",
       " ('requirements', 457),\n",
       " ('a building', 455),\n",
       " ('a device', 412)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac5654c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MWEs: 10833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['m centres',\n",
       " 'perlite mixes',\n",
       " 'registered trade mark',\n",
       " 'amd 14857 2004',\n",
       " 'respiration activity',\n",
       " 'the medical device',\n",
       " 'OJ No C 159',\n",
       " 'The maximum whole dwelling extract ventilation rate',\n",
       " 'All people',\n",
       " 'Alternatively access',\n",
       " 'the field safety corrective action',\n",
       " 'oil separators',\n",
       " 'Conformity assessment procedures',\n",
       " 'a smoke alarm',\n",
       " 'masonry structures',\n",
       " 'building situations',\n",
       " 'firefighting lift shaft',\n",
       " 'the basement storey',\n",
       " 'a standard of provision',\n",
       " 'the performance study report',\n",
       " 'the product labelling',\n",
       " 'firefighting side shaft',\n",
       " 'pipe size',\n",
       " 'requirement K5 2',\n",
       " 'independent offices above',\n",
       " 'first sentence',\n",
       " 'Fire stopping',\n",
       " 'Regulations 2007',\n",
       " 'class B',\n",
       " 'timber / metal frame',\n",
       " 'exposed edges line',\n",
       " 'the Equality Act',\n",
       " 'independence principles',\n",
       " 'procedure packs',\n",
       " 'cover moulds',\n",
       " 'the common areas stairs',\n",
       " 'class A1 rating',\n",
       " 'Point g ) ii )',\n",
       " 'minimum EI 30',\n",
       " 'BS EN ISO',\n",
       " 'a gravity system',\n",
       " 'Paragraphs H2 J7',\n",
       " 'exits ceiling',\n",
       " 'Alternative supply',\n",
       " 'OJ No L 126',\n",
       " 'a medical prescription',\n",
       " 'Table K1',\n",
       " 'and ii',\n",
       " 'they classification',\n",
       " 'June 1998',\n",
       " 'minimum REI 30',\n",
       " 'organisation structure',\n",
       " 'loft space',\n",
       " 'accordance 4 3',\n",
       " 'min NOTES',\n",
       " 'product quality',\n",
       " 'storage room',\n",
       " 'fire safety engineering principles',\n",
       " 'the waste collection authority',\n",
       " 'floor materials',\n",
       " 'the external leaf',\n",
       " 'sub - paragraph b',\n",
       " 'below ground drainage',\n",
       " 'air vents',\n",
       " 'quality manuals',\n",
       " 'condensing appliances',\n",
       " 'UT UP TO',\n",
       " 'Table B2 Roof covering classifications',\n",
       " 'structures Introduction B1 Much',\n",
       " 'patients  organisations',\n",
       " 'escape routes',\n",
       " 'a test report',\n",
       " 'medical specialist',\n",
       " 'mm / minute',\n",
       " 'Class I IIa',\n",
       " 'regulation 20 Inspectors',\n",
       " 'a competent person scheme',\n",
       " 'a Member State laboratory',\n",
       " 'sources of',\n",
       " 'a hall of residence',\n",
       " 'paper faced',\n",
       " 'tch roof ii',\n",
       " 'Guidance 1',\n",
       " 'a stepped change level',\n",
       " 'informed consent',\n",
       " 'BS 9251 b',\n",
       " 'vehicle barriers',\n",
       " 'vena cava superior',\n",
       " 'alarm systems',\n",
       " 'November 2017',\n",
       " 'a single storey end product',\n",
       " 'a visual check',\n",
       " 'cavity barrier',\n",
       " 'the type of integrated report',\n",
       " 'blocks of flats',\n",
       " 'splash screen',\n",
       " 'absorption coefficients',\n",
       " 'averaging periods',\n",
       " 'biological safety testing',\n",
       " 'contact 3']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some insight in number of MWEs\n",
    "mwes = []\n",
    "for t in all_terms_c.keys():\n",
    "    words = t.split(' ')\n",
    "    if words[0] in ['the', 'a', 'The', 'A', 'an', 'An', 'any', 'Any', 'this', 'This']:\n",
    "        words = words[1:]\n",
    "    if len(words) > 1:\n",
    "        mwes.append(t)\n",
    "\n",
    "print(f\"Number of MWEs: {len(mwes)}\")\n",
    "random.sample(mwes, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8d0d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF weights\n",
    "sentence_lists = [c.sentences for d in foreground_corpus + background_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "all_sentences = [s for sent_list in sentence_lists for s in sent_list if s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bf4a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Merged Approved Documents',\n",
       " 'How to use the Merged Approved Documents This document combines the approved documents into a single PDF.',\n",
       " 'Each approved document is self-contained and has its own introduction.',\n",
       " 'Each introduction relates only to the corresponding approved document.',\n",
       " \"Each introduction also contains information on when the document's guidance came into effect (or will come into effect).\",\n",
       " 'It is important to check that the version of each approved document you are using remains current and is the correct version for your project.',\n",
       " 'Please refer to the Ministry of Housing, Communities and Local Government website to check, and confirm with your building control body if in doubt.',\n",
       " 'Key features The Merged Approved Documents enable the user to: undertake a word search across all of the approved documents cut and paste text and diagrams into other documents add notes to a saved copy use an index to access individual sections of the guidance Correction to Approved Document K The heading in section 1.18 of the online version of Approved Document K have been corrected to match the print version.',\n",
       " \"Forthcoming changes Please check the Ministry of Housing, Communities and Local Government's website to ensure that each approved document you are using is current for your project.\",\n",
       " 'This is particularly important in relation to Approved Document B as this has been subject to frequent update.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_sentences))\n",
    "all_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c09c984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing IDF weights.\n",
      "Printing some IDF values, should be subword units!\n",
      "['cluster']\n",
      "['##of']\n",
      "['deposits']\n",
      "['ultimate']\n",
      "['horizontal']\n",
      "['proximity']\n",
      "['estates']\n",
      "['exploration']\n",
      "['##most']\n",
      "['rendered']\n"
     ]
    }
   ],
   "source": [
    "IDF_c = IDF_computation.IdfComputer(\"data/IDF_weights.json\", bert_model_name=bert_model_name)\n",
    "IDF_path = IDF_c.compute_or_load_IDF_weights(all_sentences, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "411b8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each of the terms identified by SPaR.txt, applies IDF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b1959bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique terms: 16441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the Merged Approved Documents',\n",
       " 'document',\n",
       " 'documents',\n",
       " 'Each introduction',\n",
       " 'approved',\n",
       " 'information',\n",
       " 'guidance',\n",
       " 'the version',\n",
       " 'project',\n",
       " 'the Ministry']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_terms = [k for k in all_terms_c.keys()] # counter keys, so already unique\n",
    "print(f\"Number of unique terms: {len(all_terms)}\")\n",
    "all_terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26f20d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a669a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedding.Embedder(tokenizer, bert_model, \n",
    "                              IDF_dict=json.load(open(IDF_path)), \n",
    "                              embedding_fp=\"output/\",\n",
    "                              layers_to_use = [12],         # we'll use the output of the last layer\n",
    "                              layer_combination = \"avg\",    # how to combine layers if multiple are used\n",
    "                              idf_threshold = 1.5,          # minimum IDF value for a token to contribute\n",
    "                              idf_weight_factor = 1.0,      # modify how strong the influence of IDF weighting is\n",
    "                              not_found_idf_value = 0.5)    # IDF value for tokens that weren't seen during IDF computation (doesn't apply here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce59ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embeddings, this is split into subsets so we don't overload your memory (adjust these values if needed)\n",
    "max_num_cpu_threads = 4\n",
    "subset_size = 1000\n",
    "\n",
    "# Checks which of the embeddings for the clustering cluster_data already exist, so they can be re-used\n",
    "term_subsets = cleaning_utils.split_list(all_terms, subset_size)\n",
    "embedding_files = glob.glob(embedder.embedding_fp + 'embeddings*.pkl')\n",
    "span_and_embedding_pairs = []\n",
    "if len(embedding_files) == len(term_subsets):\n",
    "    for e in embedding_files:\n",
    "        span_and_embedding_pairs += pickle.load(open(e, 'rb'))\n",
    "else:\n",
    "    print(f\"Preparing embeddings for {len(all_terms)} spans, in groups of: {subset_size}\")\n",
    "    subset_idx = 0            # iterator index outside of tqdm \n",
    "    for subset in tqdm(term_subsets):\n",
    "        subset_embeddings = []\n",
    "        subset_file_name = embedder.embedding_fp + \"embeddings_part_\" + '{}.pkl'.format(subset_idx)\n",
    "        subset_idx += 1\n",
    "        if os.path.exists(subset_file_name):\n",
    "            # already computed previously\n",
    "            continue\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_num_cpu_threads) as executor:\n",
    "            futures = [executor.submit(embedder.embed_a_span, subset[idx]) for idx in range(len(subset))]\n",
    "\n",
    "        subset_embeddings += [f.result() for f in futures if f.result()]\n",
    "\n",
    "        with open(subset_file_name, 'wb') as f:\n",
    "            pickle.dump(subset_embeddings, f)\n",
    "\n",
    "    # Once all embeddings are created; combine them in span_and_embedding_pairs\n",
    "    embedding_files = glob.glob(embedder.embedding_fp + \"embeddings_part_\" + '*.pkl')\n",
    "    for e in embedding_files:\n",
    "        span_and_embedding_pairs += pickle.load(open(e, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4e8b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising and combining computed/existing 17 embeddings from files into single file\n"
     ]
    }
   ],
   "source": [
    "# Create a single file with all embeddings, in the meantime standardising the embeddings to improve the representation\n",
    "print(f\"Normalising and combining computed/existing {len(embedding_files)} embeddings from files into single file\")\n",
    "unique_spans, unique_embeddings = zip(*span_and_embedding_pairs)\n",
    "with open(embedder.embedding_fp + \"unique_spans.pkl\", 'wb') as f:\n",
    "    pickle.dump(unique_spans, f)\n",
    "\n",
    "with open(embedder.embedding_fp + \"unique_embeddings.pkl\", 'wb') as f:\n",
    "    # we average over the token embeddings in a term\n",
    "    unique_clustering_data = np.stack([np.mean(e, axis=0) if len(e.shape) > 1 else e for e in unique_embeddings])\n",
    "\n",
    "    # standardise the unique clustering data, as suggested by https://github.com/wtimkey/rogue-dimensions\n",
    "    embedder.emb_mean = unique_clustering_data.mean(axis=0)\n",
    "    embedder.emb_std = unique_clustering_data.std(axis=0)\n",
    "    pickle.dump(embedder.emb_mean, open(embedder.embedding_fp + \"standardisation_mean.pkl\", 'wb'))\n",
    "    pickle.dump(embedder.emb_std, open(embedder.embedding_fp + \"standardisation_std.pkl\", 'wb'))\n",
    "\n",
    "    standardised_clustering_data = (unique_clustering_data - embedder.emb_mean) / embedder.emb_std\n",
    "\n",
    "    pickle.dump(standardised_clustering_data, f)\n",
    "    \n",
    "# Store the standardised embeddings for reuse; could honeslty remove all the other embedding files but will keep them just in case\n",
    "pickle.dump(standardised_clustering_data, open(embedder.embedding_fp + \"standardised_embeddings.pkl\", 'wb'))\n",
    "spans_and_standardised_embeddings_dict = dict(zip(unique_spans, standardised_clustering_data))\n",
    "# pickle.dump(spans_and_standardised_embeddings_dict, open(embedder.embedding_fp + \"spans_and_standardised_embeddings_dict.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb489c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Fourth, we cluster the embeddings with KMeans.\n",
    "</div>\n",
    "\n",
    "\n",
    "* Note: We try various values for K, the number of clusters. We'll  try to get some insight in a good value for K based on the Elbow score and Silhouette score. However, due to the sparsity of the set of terms found in the Approved Documents and the EU regulations these scores aren't very insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30daa510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute clusters on either CPU or GPU\n",
    "def compute_clusters_sklearn(standardised_clustering_data, cluster_model_fp, num_clusters=10):\n",
    "    \"\"\"\n",
    "    Note that this clustering function relies on the CPU. It won't be able to compute clusters for large \n",
    "    amounts of inputs, e.g., 100.000 spans. When using a large number of clusters (e.g. 5000) it is also\n",
    "    a lot slower than a GPU implementation for. Or it may simply not converge! \n",
    "    For large inputs/num_clusters you'll need to use compute_clusters_kmcuda, and have access to a GPU.\n",
    "    \"\"\"\n",
    "    print(f\"Computing {num_clusters} clusters from scratch, using sklearn on the CPU\")\n",
    "    start_time = time.time()\n",
    "    sklearn_kmeans = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=3, n_init=1, random_state=14,\n",
    "                            tol=0.0001, verbose=0)\n",
    "    assignments = sklearn_kmeans.fit_predict(standardised_clustering_data)\n",
    "    centroids = sklearn_kmeans.cluster_centers_\n",
    "    print(\"Clustering took {}\".format(time.time() - start_time))\n",
    "    with open(cluster_model_fp, 'wb') as f:\n",
    "        pickle.dump((centroids, assignments), f)\n",
    "        \n",
    "# compute clusters on CPU for now\n",
    "def compute_clusters_kmcuda(standardised_clustering_data, cluster_model_fp, num_clusters=10000):\n",
    "    \"\"\"\n",
    "    Won't implement cosine KMeans here, as I want to predict with sklearn in this notebook. \n",
    "    Also not sure if the results are really that much better.\n",
    "    \"\"\"\n",
    "    centroids, assignments = kmeans_cuda(standardised_clustering_data, num_clusters, init=\"k-means++\",\n",
    "                                                 verbosity=1, seed=14) # , device=0)\n",
    "    with open(cluster_model_fp, 'wb') as f:\n",
    "        pickle.dump((centroids, assignments), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b39d48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn cluster file exists for 2000 clusters\n",
      "sklearn cluster file exists for 2500 clusters\n",
      "sklearn cluster file exists for 3000 clusters\n",
      "sklearn cluster file exists for 3500 clusters\n",
      "sklearn cluster file exists for 4000 clusters\n",
      "sklearn cluster file exists for 4500 clusters\n",
      "sklearn cluster file exists for 5000 clusters\n",
      "sklearn cluster file exists for 5500 clusters\n",
      "sklearn cluster file exists for 6000 clusters\n",
      "sklearn cluster file exists for 6500 clusters\n",
      "sklearn cluster file exists for 7000 clusters\n",
      "sklearn cluster file exists for 7500 clusters\n",
      "sklearn cluster file exists for 8000 clusters\n"
     ]
    }
   ],
   "source": [
    "if not kmeans_cuda:\n",
    "    clustering_type = \"sklearn\"\n",
    "    # Computing clusters on the CPU\n",
    "    for num_clusters in range(2000,8001, 500):\n",
    "        cluster_file = f\"output/sklearn_{num_clusters}_clusters.pkl\"\n",
    "        if not os.path.exists(cluster_file):\n",
    "            compute_clusters_sklearn(standardised_clustering_data, cluster_file, num_clusters)\n",
    "        else:\n",
    "            print(f\"sklearn cluster file exists for {num_clusters} clusters\")\n",
    "else:    \n",
    "    \"\"\"\n",
    "    Currently not implemented, would have to provide instructions for kmcuda installation as well probably.\n",
    "    Only needed once inputs (nr of terms in combination with nr of clusters) get very  large.\n",
    "    \"\"\"\n",
    "    clustering_type = \"kmcuda\" \n",
    "    for num_clusters in range(4000,10001, 500):\n",
    "        cluster_file = f\"output/kmcuda_{num_clusters}_clusters.pkl\"\n",
    "        if not os.path.exists(cluster_file):\n",
    "            compute_clusters_kmcuda(standardised_clustering_data, cluster_file, num_clusters) \n",
    "        else:\n",
    "            print(f\"kmcuda cluster file exists for {num_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97b112",
   "metadata": {},
   "source": [
    "* Select the 'best' cluster model using Elbow and Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b6810b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_type = \"sklearn\"\n",
    "clustering_files = glob.glob(f'output/{clustering_type}_*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8d87f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing elbow and silhouette (if not too many num_clusters) scores.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                              | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading values from existing csv file: output/sklearn_4500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_5000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_3500_clusters.pkl\n",
      "Working on: output/sklearn_2000_clusters.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:09<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading values from existing csv file: output/sklearn_2500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_3000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_5500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_4000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_7500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_6000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_6500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_7000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_8000_clusters.pkl\n",
      "Plotting the figure\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This takes a bit of time; 6-10 minutes per cluster size for 2000-6000 clusters \n",
    "# but resulting scores are saved in a csv and reused\n",
    "clustering_data_fp = \"output/\"\n",
    "es = cluster_utils.ElbowAndSilhouette(clustering_data_fp)\n",
    "es.compute_scores_for_models(clustering_type, clustering_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f80fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Fifth, we pick a value for K. This value will be used to determine which clusters are filtered (because a background term occurs in it), as well as for prediction; e.g., predicting which cluster a new term falls into, which neighbours exist in that cluster, etc.\n",
    "</div>\n",
    "\n",
    "* Based on the number of clusters we'd like to use, we create a lookup-dictionary for the embedding and assigned cluster of each span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7db65503",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_num_clusters = 6500\n",
    "cluster_model_to_use = f'output/{clustering_type}_{chosen_num_clusters}_clusters.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "733bd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, assignments = pickle.load(open(cluster_model_to_use, 'rb'))\n",
    "\n",
    "unique_background_terms = [k for k in background_terms_c.keys()]\n",
    "cluster_dict_creator = cluster_utils.ClusterDict(unique_background_terms, \n",
    "                                                 unique_spans, \n",
    "                                                 standardised_clustering_data,  # important to use standardised  embeddings\n",
    "                                                 centroids, \n",
    "                                                 assignments,\n",
    "                                                 embedding_fp=\"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a5692ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cluster dictionary.\n"
     ]
    }
   ],
   "source": [
    "phrase_cluster_dict, clusters_to_filter = cluster_dict_creator.prep_cluster_dict(chosen_num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "63bbc5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: ['repackaging']\n",
      "Filtered: ['developments', 'issues', 'schemes', 'operations', 'treatments']\n",
      "Filtered: ['paragraph 2 11', 'paragraph 2 10', 'paragraph 2 7', 'paragraph 2 8', 'paragraph 1 11']\n",
      "AEC domain: ['Cladding']\n",
      "Filtered: ['competitors']\n",
      "AEC domain: ['the Workplace Health', 'The Workplace Health', 'the Workplace Regulations']\n",
      "Filtered: ['positive result']\n",
      "AEC domain: ['electrical installation condition report']\n",
      "Filtered: ['the European Pharmacopoeia', 'a European Pharmacopoeia']\n",
      "Filtered: ['nucleic acid primers']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/l_mzhpjs6bg95plfkl_n_vsc0000gn/T/ipykernel_6545/378847011.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  for k in random.sample(phrase_cluster_dict.keys(), 10):\n"
     ]
    }
   ],
   "source": [
    "# print some insight in the clusters\n",
    "max_terms_to_show = 5\n",
    "for k in random.sample(phrase_cluster_dict.keys(), 10):\n",
    "    some_terms = [span for score, span in phrase_cluster_dict[k]]\n",
    "    if k in clusters_to_filter:\n",
    "        print(f\"Filtered: {some_terms[:max_terms_to_show]}\")\n",
    "    else:\n",
    "        print(f\"AEC domain: {some_terms[:max_terms_to_show]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a5aa123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_terms = [span for k, v in phrase_cluster_dict.items() for score, span in v if k in clusters_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "824968e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_terms = [t for t in removed_terms if t in foreground_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b97c6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_terms = [span for k, v in phrase_cluster_dict.items() for score, span in v  if k not in clusters_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e89aff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922\n",
      "Terms that were filtered:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the pressure',\n",
       " 'a system',\n",
       " 'wavelengths',\n",
       " 'doorway',\n",
       " 'prepared',\n",
       " 'passengers',\n",
       " 'treatments',\n",
       " 'the Building Act 1984',\n",
       " 'the product standards',\n",
       " 'designed']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(filtered_terms))\n",
    "print(\"Terms that were filtered:\")\n",
    "random.sample(filtered_terms,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "24378f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7615\n",
      "Terms that were kept:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['river silts',\n",
       " 'the Approved',\n",
       " 'mixed use buildings',\n",
       " 'fire hydrant',\n",
       " 'Table B1',\n",
       " 'decay measurements',\n",
       " 'the whole dwelling ventilation supply rate',\n",
       " 'Property protection 0 7 The Building Regulations',\n",
       " 'method 1',\n",
       " 'room air']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(domain_terms))\n",
    "print(\"Terms that were kept:\")\n",
    "random.sample(domain_terms,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "27a2ecd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[141.5850830078125, 'the device'],\n",
       "  [150.78564453125, 'the system'],\n",
       "  [161.78428649902344, 'the building'],\n",
       "  [169.1160125732422, 'the design'],\n",
       "  [176.38735961914062, 'the structure'],\n",
       "  [185.06497192382812, 'the body'],\n",
       "  [186.64706420898438, 'the work'],\n",
       "  [188.46929931640625, 'the product'],\n",
       "  [191.67140197753906, 'the work a'],\n",
       "  [193.30099487304688, 'the plan'],\n",
       "  [193.87547302246094, 'the process'],\n",
       "  [198.57615661621094, 'the Building'],\n",
       "  [200.1083221435547, 'the dwelling'],\n",
       "  [210.5592498779297, 'the unit'],\n",
       "  [211.4690704345703, 'the market'],\n",
       "  [211.84295654296875, 'the spread'],\n",
       "  [213.55813598632812, 'the experience'],\n",
       "  [213.95501708984375, 'the part'],\n",
       "  [214.884521484375, 'the service'],\n",
       "  [217.11228942871094, 'the case'],\n",
       "  [219.58401489257812, 'the action'],\n",
       "  [219.8190155029297, 'the operation'],\n",
       "  [220.64935302734375, 'the point'],\n",
       "  [221.79884338378906, 'the access'],\n",
       "  [223.6614532470703, 'the document'],\n",
       "  [229.41592407226562, 'the label'],\n",
       "  [230.0985107421875, 'the tank'],\n",
       "  [235.38516235351562, 'the room'],\n",
       "  [236.93072509765625, 'the technology'],\n",
       "  [242.42996215820312, 'the notice'],\n",
       "  [244.1175994873047, 'the site'],\n",
       "  [247.5879364013672, 'the business'],\n",
       "  [249.52317810058594, 'the scheme'],\n",
       "  [250.1317138671875, 'the software'],\n",
       "  [250.78439331054688, 'the change'],\n",
       "  [253.79681396484375, 'the patient'],\n",
       "  [257.1473083496094, 'the subject'],\n",
       "  [258.75445556640625, 'the outlet'],\n",
       "  [260.825927734375, 'the user'],\n",
       "  [261.7913818359375, 'the event'],\n",
       "  [264.57623291015625, 'the machine'],\n",
       "  [272.8825378417969, 'the flight'],\n",
       "  [273.8206787109375, 'the laboratory'],\n",
       "  [274.0258483886719, 'the batch'],\n",
       "  [274.373046875, 'the flat'],\n",
       "  [276.66522216796875, 'the display'],\n",
       "  [287.99139404296875, 'the scope'],\n",
       "  [288.247314453125, 'the incident'],\n",
       "  [288.5022888183594, 'the collection'],\n",
       "  [291.133544921875, 'the occupants'],\n",
       "  [293.9956359863281, 'the alarm'],\n",
       "  [300.6129150390625, 'the mechanism'],\n",
       "  [309.05584716796875, 'the character'],\n",
       "  [320.82012939453125, 'the mortar'],\n",
       "  [324.7956237792969, 'the trap'],\n",
       "  [327.00262451171875, 'the vessel'],\n",
       "  [331.6500244140625, 'the agent'],\n",
       "  [338.078125, 'the joint'],\n",
       "  [354.5162048339844, 'the item'],\n",
       "  [375.6573181152344, 'the latest'],\n",
       "  [417.52154541015625, 'the finished device']],\n",
       " [[157.99285888671875, 'adverse'],\n",
       "  [188.81813049316406, 'absorption'],\n",
       "  [190.09494018554688, 'practical'],\n",
       "  [199.1444091796875, 'surgical'],\n",
       "  [207.82833862304688, 'failure'],\n",
       "  [209.42608642578125, 'permanent'],\n",
       "  [213.55735778808594, 'active'],\n",
       "  [214.4614715576172, 'intervention'],\n",
       "  [215.2310028076172, 'invasive'],\n",
       "  [216.89967346191406, 'exempt'],\n",
       "  [218.17523193359375, 'joint'],\n",
       "  [219.93722534179688, 'confidential'],\n",
       "  [220.02223205566406, 'activity'],\n",
       "  [221.40994262695312, 'supplement'],\n",
       "  [221.8401336669922, 'plastic'],\n",
       "  [222.80569458007812, 'validity'],\n",
       "  [227.5101318359375, 'private'],\n",
       "  [231.3321075439453, 'excessive'],\n",
       "  [231.64273071289062, 'floating'],\n",
       "  [234.25064086914062, 'basin'],\n",
       "  [234.74725341796875, 'resistant'],\n",
       "  [234.97122192382812, 'disposal'],\n",
       "  [237.72409057617188, 'adjustment'],\n",
       "  [238.97189331054688, 'reinforced'],\n",
       "  [240.1641845703125, 'bedrooms'],\n",
       "  [243.2595672607422, 'issuing'],\n",
       "  [245.25735473632812, 'occupants'],\n",
       "  [249.1135711669922, 'robust'],\n",
       "  [253.38478088378906, 'falling'],\n",
       "  [253.95021057128906, 'diagram'],\n",
       "  [254.81683349609375, 'pressures'],\n",
       "  [256.98394775390625, 'apparent'],\n",
       "  [257.51904296875, 'rigid'],\n",
       "  [263.9967346191406, 'others'],\n",
       "  [266.00909423828125, 'understanding'],\n",
       "  [266.5075988769531, 'landings'],\n",
       "  [268.06805419921875, 'heated'],\n",
       "  [268.22442626953125, 'therapeutic'],\n",
       "  [270.4246826171875, 'hazardous'],\n",
       "  [272.892578125, 'cold'],\n",
       "  [272.9222717285156, 'sealing'],\n",
       "  [274.6562194824219, 'beds'],\n",
       "  [276.6199645996094, 'surroundings'],\n",
       "  [284.17852783203125, 'bedroom'],\n",
       "  [285.7340087890625, 'critical'],\n",
       "  [286.4862060546875, 'objectives'],\n",
       "  [291.65106201171875, 'laying'],\n",
       "  [299.43353271484375, 'claims'],\n",
       "  [300.00030517578125, 'escaping'],\n",
       "  [306.6166687011719, 'medium'],\n",
       "  [309.75250244140625, 'collapse'],\n",
       "  [311.9997253417969, 'AD'],\n",
       "  [316.34246826171875, 'negative'],\n",
       "  [323.0479431152344, 'penetration'],\n",
       "  [326.2554931640625, 'collision'],\n",
       "  [327.1595153808594, 'wider'],\n",
       "  [327.64434814453125, 'gravity'],\n",
       "  [328.22576904296875, 'drained'],\n",
       "  [335.905517578125, 'component'],\n",
       "  [336.3318786621094, 'TO'],\n",
       "  [420.6259460449219, 'objective']]]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the largest cluster(s)\n",
    "largest_cluster_size = np.max([len(v) for v in phrase_cluster_dict.values()])\n",
    "[v for v in phrase_cluster_dict.values() if len(v) == largest_cluster_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f4d79937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0, 'expansion water']],\n",
       " [[0.0, 'PLY']],\n",
       " [[0.0, 'Electrical safety Dwellings']],\n",
       " [[0.0, 'industrial processes']],\n",
       " [[0.0, 'a temperature relief valve']],\n",
       " [[0.0, 'cistern lids']],\n",
       " [[0.0, 'Unvented']],\n",
       " [[0.0, 'Calorifiers']],\n",
       " [[0.0, 'Open vented copper cylinders']],\n",
       " [[0.0, 'ecification']],\n",
       " [[0.0, 'pressure relief valve']],\n",
       " [[0.0, 'PLY AND']],\n",
       " [[0.0, 'the operating pressure']],\n",
       " [[0.0, 'WARNING']],\n",
       " [[0.0, 'Particular']],\n",
       " [[0.0, 'thermostats']],\n",
       " [[0.0, 'Discharge']],\n",
       " [[0.0, 'a manifold']],\n",
       " [[0.0, 'fixed immersion heaters']],\n",
       " [[0.0, 'tundish']],\n",
       " [[0.0, 'the tundish']],\n",
       " [[0.0, 'a straight length']],\n",
       " [[0.0, 'Symbols']],\n",
       " [[0.0, 'Basic polymers']],\n",
       " [[0.0, 'a wire cage']],\n",
       " [[0.0, 'static completion']],\n",
       " [[0.0, 'working order']],\n",
       " [[0.0, 'Low pressure']],\n",
       " [[0.0, 'thermostatic mixing valves']],\n",
       " [[0.0, 'existing dwellings']],\n",
       " [[0.0, 'blending valves']],\n",
       " [[0.0, 'TMVs']],\n",
       " [[0.0, 'NVENIENCES']],\n",
       " [[0.0, 'Sanitary conveniences']],\n",
       " [[0.0, 'WC suites']],\n",
       " [[0.0, 'BS 6465 - 2 : 1996 Sanitary installations']],\n",
       " [[0.0, 'cold taps']],\n",
       " [[0.0, 'a cubicle']],\n",
       " [[0.0, 'a grating']],\n",
       " [[0.0, 'Lifting plants']],\n",
       " [[0.0, 'greywater recycling']],\n",
       " [[0.0, 'a washbasin']],\n",
       " [[0.0, 'Scale of provision']],\n",
       " [[0.0, 'faecal - free wastewater']],\n",
       " [[0.0, 'a dishwasher']],\n",
       " [[0.0, 'appendix']],\n",
       " [[0.0, 'Taps']],\n",
       " [[0.0, 'water consumption figures']],\n",
       " [[0.0, 'overflow']],\n",
       " [[0.0, 'dishwasher']],\n",
       " [[0.0, 'litres per minute']],\n",
       " [[0.0, 'dry load']],\n",
       " [[0.0, 'ER EFFICIENCY']],\n",
       " [[0.0, 'Shower outlets']],\n",
       " [[0.0, 'Rainfall']],\n",
       " [[0.0, 'Percentage']],\n",
       " [[0.0, 'total capacity']],\n",
       " [[0.0, 'regeneration cycle']],\n",
       " [[0.0, 'Average number']],\n",
       " [[0.0, 'CALCULATOR FOR']],\n",
       " [[0.0, 'fitting type']],\n",
       " [[0.0, 'litres per kilogram']],\n",
       " [[0.0, 'per cent']],\n",
       " [[0.0, 'regeneration cycles per day']],\n",
       " [[0.0, 'Litres per Number Quantity Greywater minute']],\n",
       " [[0.0, 'hydraulic filter efficiency']],\n",
       " [[0.0, 'Daily rainwater per']],\n",
       " [[0.0, 'yield coefficient']],\n",
       " [[0.0, 'mg / l']],\n",
       " [[0.0, 'nitrite']],\n",
       " [[0.0, 'Water Quality']],\n",
       " [[0.0, 'coli parameter']],\n",
       " [[0.0, 'parasite']],\n",
       " [[0.0, 'nitrate']],\n",
       " [[0.0, 'hmso']],\n",
       " [[0.0, 'Sanitary tapware']],\n",
       " [[0.0, 'wras']],\n",
       " [[0.0, 'www wras co uk']],\n",
       " [[0.0, 'Market Transformation Programme']],\n",
       " [[0.0, 'economic feasibility']],\n",
       " [[0.0, 'cibse']],\n",
       " [[0.0, 'page 18']],\n",
       " [[0.0, 'iti ed 15 20']],\n",
       " [[0.0, 'Pumping installations']],\n",
       " [[0.0, 'Drainage fields']],\n",
       " [[0.0, 'Cesspools']],\n",
       " [[0.0, 'Combined systems']],\n",
       " [[0.0, 'rainfall intensities']],\n",
       " [[0.0, 'overflowing']],\n",
       " [[0.0, 'Contaminated']],\n",
       " [[0.0, 'Disused']],\n",
       " [[0.0, 'litres per second per square metre']],\n",
       " [[0.0, 'paved areas']],\n",
       " [[0.0, 'underground rainwater drainage']],\n",
       " [[0.0, 'unventilated']],\n",
       " [[0.0, 'nominal ring stiffness SN4']],\n",
       " [[0.0, 'a shared drain / sewer']],\n",
       " [[0.0, 'Bedding']],\n",
       " [[0.0, 'Code of Practice L24']],\n",
       " [[0.0, 'ISBN 0 7176 0413 6']],\n",
       " [[0.0, 'confined spaces']],\n",
       " [[0.0, 'Relev']],\n",
       " [[0.0, 'clearing blockages']],\n",
       " [[0.0, 'seal depths']],\n",
       " [[0.0, 'Gullies']],\n",
       " [[0.0, 'a stub stack']],\n",
       " [[0.0, 'the tail']],\n",
       " [[0.0, 'water seals']],\n",
       " [[0.0, 'surcharging']],\n",
       " [[0.0, 'Rodding points']],\n",
       " [[0.0, 'lengths']],\n",
       " [[0.0, 'corrosion']],\n",
       " [[0.0, 'rodent control']],\n",
       " [[0.0, 'Polyethylene']],\n",
       " [[0.0, 'positive pressure']],\n",
       " [[0.0, 'low - lying sites']],\n",
       " [[0.0, 'gully']],\n",
       " [[0.0, 'the right']],\n",
       " [[0.0, 'private land']],\n",
       " [[0.0, 'private sewer']],\n",
       " [[0.0, 'cesspool']],\n",
       " [[0.0, 'prefabricated components']],\n",
       " [[0.0, 'surcharge']],\n",
       " [[0.0, 'gullies']],\n",
       " [[0.0, 'Vent']],\n",
       " [[0.0, 'straight lines']],\n",
       " [[0.0, 'granular']],\n",
       " [[0.0, 'Special measures']],\n",
       " [[0.0, 'personnel entry']],\n",
       " [[0.0, 'Pipe gradients']],\n",
       " [[0.0, 'Sewers']],\n",
       " [[0.0, 'watertight']],\n",
       " [[0.0, 'flexible filler']],\n",
       " [[0.0, 'fields Laid']],\n",
       " [[0.0, 'light roads Laid']],\n",
       " [[0.0, 'Alternative designs']],\n",
       " [[0.0, 'Mini depth']],\n",
       " [[0.0, 'BS 5911']],\n",
       " [[0.0, 'mm x mm']],\n",
       " [[0.0, 'Drains']],\n",
       " [[0.0, 'highways']],\n",
       " [[0.0, 'public open space']],\n",
       " [[0.0, 'piling works']],\n",
       " [[0.0, 'the piling']],\n",
       " [[0.0, 'trial holes']],\n",
       " [[0.0, 'Piling']],\n",
       " [[0.0, 'Manholes']],\n",
       " [[0.0, 'test lengths']],\n",
       " [[0.0, 'Pipework']],\n",
       " [[0.0, 'Reclaimed']],\n",
       " [[0.0, 'the Water Regulations Advisory Scheme']],\n",
       " [[0.0, 'leaflet No']],\n",
       " [[0.0, 'Section 48']],\n",
       " [[0.0, 'Repair']],\n",
       " [[0.0, 'a nuisance']],\n",
       " [[0.0, 'grounds']],\n",
       " [[0.0, 'grout filled']],\n",
       " [[0.0, 'Right']],\n",
       " [[0.0, 'Requisition']],\n",
       " [[0.0, 'Adoption']],\n",
       " [[0.0, 'man entry']],\n",
       " [[0.0, 'drainage mounds']],\n",
       " [[0.0, 'waterlogged']],\n",
       " [[0.0, 'watercourse']],\n",
       " [[0.0, 'a watercourse']],\n",
       " [[0.0, 'Septic tanks']],\n",
       " [[0.0, 'Access covers']],\n",
       " [[0.0, 'downslope']],\n",
       " [[0.0, 'a vehicle access']],\n",
       " [[0.0, 'free - flowing']],\n",
       " [[0.0, 'BS EN 12566 - 1']],\n",
       " [[0.0, 'cementsand ratio']],\n",
       " [[0.0, 'BS 5328']],\n",
       " [[0.0, 'soakaways']],\n",
       " [[0.0, 'the 300mm']],\n",
       " [[0.0, 'subsoils']],\n",
       " [[0.0, 'percolation characteristics']],\n",
       " [[0.0, 'a soakaway']],\n",
       " [[0.0, 'shingle']],\n",
       " [[0.0, 'seepage']],\n",
       " [[0.0, 'ammonia']],\n",
       " [[0.0, 'the gravel bed']],\n",
       " [[0.0, 'Horizontal flow systems']],\n",
       " [[0.0, 'reed beds']],\n",
       " [[0.0, 'BRE Good Building Guide No']],\n",
       " [[0.0, 'Marking']],\n",
       " [[0.0, 'a licensed contractor']],\n",
       " [[0.0, 'fortnightly']],\n",
       " [[0.0, 'small sewage treatment works']],\n",
       " [[0.0, 'Offences']],\n",
       " [[0.0, 'polluting']],\n",
       " [[0.0, 'the Water Resources Act']],\n",
       " [[0.0, 'lake']],\n",
       " [[0.0, 'the Public Health Act 1936']],\n",
       " [[0.0, 'settlement tank']],\n",
       " [[0.0, 'the pores']],\n",
       " [[0.0, 'a monthly basis']],\n",
       " [[0.0, 'rainfall intensity']],\n",
       " [[0.0, 'parapet gutters']],\n",
       " [[0.0, 'Information about']],\n",
       " [[0.0, 'rainwater drainage systems']],\n",
       " [[0.0, 'channels']],\n",
       " [[0.0, 'a detention tank']],\n",
       " [[0.0, 'oil separators']],\n",
       " [[0.0, 'Safety Executive']],\n",
       " [[0.0, 'vesting']],\n",
       " [[0.0, 'appendix H1 - C paragraph C 7']],\n",
       " [[0.0, 'the consent']],\n",
       " [[0.0, 'the waste collection authority']],\n",
       " [[0.0, 'amenity']],\n",
       " [[0.0, 'Enclosures']],\n",
       " [[0.0, 'recyclable']],\n",
       " [[0.0, 'a polluted']],\n",
       " [[0.0, 'disuse']],\n",
       " [[0.0, 'Drain and']],\n",
       " [[0.0, 'Vitrified clay pipes']],\n",
       " [[0.0, 'copper tubes']],\n",
       " [[0.0, 'Plumbing fittings']],\n",
       " [[0.0, 'compression ends']],\n",
       " [[0.0, 'cast iron spigot']],\n",
       " [[0.0, 'Generalities']],\n",
       " [[0.0, 'buried pipelines']],\n",
       " [[0.0, 'Plastics piping systems']],\n",
       " [[0.0, 'Unplasticized']],\n",
       " [[0.0, 'PVC - U )']],\n",
       " [[0.0, 'Hydraulic design']],\n",
       " [[0.0, 'Polypropylene']],\n",
       " [[0.0, 'vinyl chloride']],\n",
       " [[0.0, 'poly']],\n",
       " [[0.0, 'unreinforced']],\n",
       " [[0.0, 'BS EN 1917 : 2002 Concrete manholes']],\n",
       " [[0.0, 'jacking pipes']],\n",
       " [[0.0, 'Gravity drainage systems']],\n",
       " [[0.0, 'Layout']],\n",
       " [[0.0, 'Lifting']],\n",
       " [[0.0, 'Other publications']],\n",
       " [[0.0, 'WRAS']],\n",
       " [[0.0, 'www netregs gov uk']],\n",
       " [[0.0, 'carbon monoxide alarms']],\n",
       " [[0.0, 'solid fuel appliances']],\n",
       " [[0.0, 'older houses']],\n",
       " [[0.0, 'secondary containment']],\n",
       " [[0.0, 'informative']],\n",
       " [[0.0, 'relining']],\n",
       " [[0.0, 'relining flues']],\n",
       " [[0.0, 'Fireplace recesses']],\n",
       " [[0.0, 'Connect']],\n",
       " [[0.0, 'LPG storage installations']],\n",
       " [[0.0, 'Flueblock chimneys']],\n",
       " [[0.0, 'Tank location']],\n",
       " [[0.0, 'footnotes']],\n",
       " [[0.0, 'Paragraphs']],\n",
       " [[0.0, 'the conservation officer']],\n",
       " [[0.0, 'Body']],\n",
       " [[0.0, 'the Clean Air Act']],\n",
       " [[0.0, 'incinerators']],\n",
       " [[0.0, 'overheating']],\n",
       " [[1.1641532182693481e-10, 'hearth fireplace']],\n",
       " [[0.0, 'fixed oil storage tanks']],\n",
       " [[0.0, 'connecting pipes']],\n",
       " [[0.0, 'kW net']],\n",
       " [[0.0, 'ratings']],\n",
       " [[0.0, 'solid fuel use']],\n",
       " [[0.0, 'oil - fired']],\n",
       " [[0.0, 'Equivalent area']],\n",
       " [[0.0, 'LPG tanks']],\n",
       " [[0.0, 'natural draught']],\n",
       " [[0.0, 'rated input']],\n",
       " [[0.0, 'heat input rate']],\n",
       " [[0.0, 'flueless appliances']],\n",
       " [[0.0, 'proprietary assembly']],\n",
       " [[0.0, 'COMBUSTION INSTALLATIONS']],\n",
       " [[0.0, 'open - flued']],\n",
       " [[0.0, 'OFTEC']],\n",
       " [[0.0, 'Bends']],\n",
       " [[0.0, 'Liners']],\n",
       " [[0.0, 'condensing appliances']],\n",
       " [[0.0, 'flueblocks']],\n",
       " [[0.0, 'the designation T400 N2 D 3 G']],\n",
       " [[0.0, 'combust']],\n",
       " [[0.0, 'Flexible']],\n",
       " [[0.0, 'xxmm']],\n",
       " [[0.0, 'straight']],\n",
       " [[0.0, 'a specialist firm']],\n",
       " [[0.0, 'a sub - contractor']],\n",
       " [[0.0, 'Open appliance']],\n",
       " [[0.0, 'a flue draught stabiliser']],\n",
       " [[0.0, 'appliance rated output']],\n",
       " [[0.0, 'rectangular /']],\n",
       " [[0.0, 'square flues']],\n",
       " [[0.0, 'FUEL WITH A RATED OUTPUT UP TO']],\n",
       " [[0.0, 'Chim']],\n",
       " [[0.0, 'D At']],\n",
       " [[0.0, 'FUEL WITH']],\n",
       " [[0.0, 'combustible material']],\n",
       " [[0.0, 'Diagram appliances']],\n",
       " [[0.0, 'an d']],\n",
       " [[0.0, 'RATED']],\n",
       " [[0.0, 'UT UP TO']],\n",
       " [[0.0, 'Some ways']],\n",
       " [[0.0, 'a DFE fire']],\n",
       " [[0.0, 'mm x']],\n",
       " [[3.725290298461914e-09, 'The plume']],\n",
       " [[0.0, 'nuisance']],\n",
       " [[0.0, 'frequent wetting']],\n",
       " [[0.0, 'terminal']],\n",
       " [[0.0, 'an openable element window']],\n",
       " [[0.0, 'a window frame']],\n",
       " [[0.0, 'nests']],\n",
       " [[0.0, 'veranda']],\n",
       " [[0.0, 'ILFE']],\n",
       " [[0.0, 'default designations']],\n",
       " [[0.0, 'flue designation']],\n",
       " [[0.0, 'flueblock']],\n",
       " [[0.0, 'straight blocks']],\n",
       " [[0.0, 'recess units']],\n",
       " [[0.0, 'Relining']],\n",
       " [[0.0, 'Flueblocks']],\n",
       " [[0.0, 'flexible stainless steel liners']],\n",
       " [[0.0, 'Double - skin flexible flue liners']],\n",
       " [[0.0, 'back boilers']],\n",
       " [[0.0, 'debris']],\n",
       " [[0.0, 'convector heaters']],\n",
       " [[0.0, 'fire / back boilers']],\n",
       " [[0.0, 'st 2nd']],\n",
       " [[0.0, 'rd family gases']],\n",
       " [[0.0, 'rd family']],\n",
       " [[0.0, 'dispersal']],\n",
       " [[0.0, 'Dwellings']],\n",
       " [[0.0, 'Suitable']],\n",
       " [[0.0, 'Condensing boiler']],\n",
       " [[0.0, 'with pressure - jet burners']],\n",
       " [[0.0, 'boiler range cooker']],\n",
       " [[0.0, 'Install']],\n",
       " [[0.0, 'oil firing']],\n",
       " [[0.0, 'Pollution']],\n",
       " [[0.0, 'paving slabs']],\n",
       " [[0.0, 'flue terminals']],\n",
       " [[0.0, 'chimneys The checklist']],\n",
       " [[0.0, 'Firing capability']],\n",
       " [[0.0, 'solid fuel / gas / oil / all']],\n",
       " [[0.0, 'Intended type']],\n",
       " [[0.0, 'State type area']],\n",
       " [[0.0, 'natural draught gas appliances']],\n",
       " [[0.0, 'flue outlet terminal']],\n",
       " [[0.0, 'diagram reference']],\n",
       " [[0.0, 'AD J']],\n",
       " [[0.0, 'Sweep']],\n",
       " [[0.0, 'Inspection']],\n",
       " [[0.0, 'Smith']],\n",
       " [[0.0, 'Print name']],\n",
       " [[0.0, 'Profession Capacity']],\n",
       " [[0.0, 'Proprietor']],\n",
       " [[0.0, 'Smith  s Flues']],\n",
       " [[0.0, 'Authorising Engineer']],\n",
       " [[0.0, 'Brown plc ) Tel no']],\n",
       " [[0.0, 'Address Postcode']],\n",
       " [[0.0, 'Signed']],\n",
       " [[0.0, 'GasSafe']],\n",
       " [[0.0, 'HETAS']],\n",
       " [[0.0, 'NACE']],\n",
       " [[0.0, 'NACS )']],\n",
       " [[0.0, 'the full length']],\n",
       " [[0.0, 'the pellets']],\n",
       " [[0.0, 'TV aerial']],\n",
       " [[0.0, 'open fire places Wood']],\n",
       " [[0.0, 'National Association']],\n",
       " [[0.0, 'Chimneys']],\n",
       " [[0.0, 'Factory - Made Chimneys']],\n",
       " [[0.0, 'Fire / Back Boilers']],\n",
       " [[0.0, 'Domestic Heating']],\n",
       " [[0.0, 'rd Family Gases )']],\n",
       " [[0.0, 'Stainless Steels']],\n",
       " [[0.0, 'OFTEC Oil Fired Appliance Standard']],\n",
       " [[0.0, 'green c']],\n",
       " [[0.0, 'falling Siting']],\n",
       " [[0.0, 'Permanent methods']],\n",
       " [[0.0, 'vehicle barriers']],\n",
       " [[0.0, 'the workplace premises']],\n",
       " [[0.0, 'loading bays']],\n",
       " [[0.0, 'windows skylights']],\n",
       " [[0.0, 'headroom']],\n",
       " [[0.0, 'Steepness']],\n",
       " [[0.0, 'tapered treads']],\n",
       " [[0.0, 'dimensional constraints']],\n",
       " [[0.0, 'the gangways']],\n",
       " [[0.0, 'a seating layout']],\n",
       " [[0.0, 'transverse gangways']],\n",
       " [[0.0, 'radial gangways']],\n",
       " [[0.0, 'tiered seating']],\n",
       " [[0.0, 'a stepped gangway']],\n",
       " [[0.0, 'Make step nosings']],\n",
       " [[0.0, 'low level cane detection']],\n",
       " [[0.0, 'sloping plots']],\n",
       " [[0.0, 'consecutive']],\n",
       " [[0.0, 'tread']],\n",
       " [[0.0, 'Stair width']],\n",
       " [[0.0, 'vandalism']],\n",
       " [[0.0, 'low maintenance']],\n",
       " [[0.0, 'key factors']],\n",
       " [[0.0, 'thermal conductivity']],\n",
       " [[0.0, 'clothing']],\n",
       " [[0.0, 'rounded edges']],\n",
       " [[0.0, 'mm sphere']],\n",
       " [[0.0, 'per month']],\n",
       " [[0.0, 'slip resistant']],\n",
       " [[0.0, 'landing surfaces']],\n",
       " [[0.0, 'upstands']],\n",
       " [[0.0, 'passing places']],\n",
       " [[0.0, 'sunken area']],\n",
       " [[0.0, 'parapet']],\n",
       " [[0.0, 'critical locations']],\n",
       " [[0.0, 'small panes']],\n",
       " [[0.0, 'annealed']],\n",
       " [[0.0, 'Manifestation']],\n",
       " [[0.0, 'a high - contrast strip']],\n",
       " [[0.0, 'stable surface']],\n",
       " [[0.0, 'safety harnesses']],\n",
       " [[0.0, 'the track']],\n",
       " [[0.0, 'power - operated']],\n",
       " [[0.0, 'Light reflectance value']],\n",
       " [[0.0, 'visible light']],\n",
       " [[0.0, 'a day - to - day basis']],\n",
       " [[0.0, 'Page 35']],\n",
       " [[0.0, 'Page 41']],\n",
       " [[0.0, 'statutory undertakers']],\n",
       " [[0.0, 'power 3 Demons']],\n",
       " [[0.0, 'Section 2 Design standards']],\n",
       " [[0.0, 'DER']],\n",
       " [[0.0, 'information Criterion 5 Provisions']],\n",
       " [[0.0, 'power L1B : Conservation']],\n",
       " [[0.0, 'an overview']],\n",
       " [[0.0, 'a pointer']],\n",
       " [[0.0, 'Nearly zero - energy requirements']],\n",
       " [[0.0, 'Statutory']],\n",
       " [[0.0, 'Schedule 1 : Conservation']],\n",
       " [[0.0, 'power L1']],\n",
       " [[0.0, 'losses i )']],\n",
       " [[0.0, 'construction stages']],\n",
       " [[0.0, 'regulation 26A']],\n",
       " [[0.0, 'Criteria 2']],\n",
       " [[0.0, 'statutory guidance']],\n",
       " [[0.0, 'trade - offs']],\n",
       " [[0.0, 'uncertain service lives']],\n",
       " [[0.0, 'air - conditioned']],\n",
       " [[0.0, 'One way']],\n",
       " [[0.0, 'inter alia']],\n",
       " [[0.0, 'Methodology of']],\n",
       " [[0.0, 'an energy performance indicator']],\n",
       " [[0.0, 'standardised use']],\n",
       " [[0.0, 'Target Fabric Energy Efficiency']],\n",
       " [[0.0, 'SAP 2012']],\n",
       " [[0.0, 'fabric energy efficiency targets']],\n",
       " [[0.0, 'Developers']],\n",
       " [[0.0, 'the community scheme']],\n",
       " [[0.0, 'multi - fuel']],\n",
       " [[0.0, 'an apartment block']],\n",
       " [[0.0, 'the floor - area - weighted average']],\n",
       " [[0.0, 'an interim recommendations report']],\n",
       " [[0.0, 'an accredited source']],\n",
       " [[0.0, 'the average TER']],\n",
       " [[0.0, 'the National Planning Policy Framework']],\n",
       " [[0.0, 'a community energy system']],\n",
       " [[0.0, 'The predicted effect']],\n",
       " [[0.0, 'gas boilers']],\n",
       " [[0.0, 'system efficiencies']],\n",
       " [[0.0, 'distribution temperatures']],\n",
       " [[0.0, 'carbon - intensive option']],\n",
       " [[0.0, 'enhancements']],\n",
       " [[0.0, 'cheaper']],\n",
       " [[0.0, 'capped off connections']],\n",
       " [[0.0, 'a planned community heating scheme']],\n",
       " [[0.0, 'decentralised energy supply systems']],\n",
       " [[0.0, 'reasonable times']],\n",
       " [[0.0, 'officer']],\n",
       " [[0.0, 'common typologies']],\n",
       " [[0.0, 'cogeneration']],\n",
       " [[0.0, 'a central source of production']],\n",
       " [[0.0, 'renewable sources']],\n",
       " [[0.0, 'fossil sources']],\n",
       " [[0.0, 'aerothermal']],\n",
       " [[0.0, 'geothermal']],\n",
       " [[0.0, 'hydrothermal']],\n",
       " [[0.0, 'ocean energy']],\n",
       " [[0.0, 'hydropower']],\n",
       " [[0.0, 'biomass']],\n",
       " [[0.0, 'reversible']],\n",
       " [[0.0, 'technology neutral']],\n",
       " [[0.0, 'the feasibility']],\n",
       " [[0.0, 'calculation software output reporting']],\n",
       " [[0.0, 'special areas']],\n",
       " [[0.0, 'Criterion 2 Limits']],\n",
       " [[0.0, 'design flexibility a ) i )']],\n",
       " [[0.0, 'energy - efficient fixed building services']],\n",
       " [[0.0, 'limiting values']],\n",
       " [[0.0, 'BR 443 Conventions']],\n",
       " [[0.0, 'BR 443']],\n",
       " [[0.0, 'domestic - type construction']],\n",
       " [[0.0, 'SAP 2012 Table 6e']],\n",
       " [[0.0, 'Air permeability 10 0 m3 /']],\n",
       " [[0.0, 'Pa Notes :']],\n",
       " [[0.0, 'BS EN ISO 13370']],\n",
       " [[0.0, 'NARM Technical Document NTD 2']],\n",
       " [[0.0, 'quality - assured data']],\n",
       " [[0.0, 'Reasonable provision']],\n",
       " [[0.0, 'daylighting']],\n",
       " [[0.0, 'levels daylight']],\n",
       " [[0.0, 'electric lighting']],\n",
       " [[0.0, 'the key features']],\n",
       " [[0.0, 'thermal bridges']],\n",
       " [[0.0, 'exposed edges line']],\n",
       " [[0.0, 'BRE Report BR 497 Conventions']],\n",
       " [[0.0, 'BR 497']],\n",
       " [[0.0, 'results tolerances']],\n",
       " [[0.0, 'linear transmittance values']],\n",
       " [[0.0, ': Pressure testing 43']],\n",
       " [[0.0, 'the Independent Air Tightness Testing Scheme Limited']],\n",
       " [[0.0, 'the Air Tightness Testing']],\n",
       " [[0.0, 'Measuring Association']],\n",
       " [[0.0, 'the Air Tightness Testing Measurement Association']],\n",
       " [[0.0, 'ATTMA']],\n",
       " [[0.0, 'publication Meas']],\n",
       " [[0.0, 'the previous 12 months']],\n",
       " [[0.0, 'www iats - uk org / iats - member - list /']],\n",
       " [[0.0, 'satisfactory performance']],\n",
       " [[0.0, 'the templates']],\n",
       " [[0.0, 'the Model Commissioning Plan']],\n",
       " [[0.0, 'BSRIA BG 8 / 2009']],\n",
       " [[0.0, 'controls  off']],\n",
       " [[0.0, 'Fixed building services']],\n",
       " [[0.0, 'a local authority BCB']],\n",
       " [[0.0, 'power 40']],\n",
       " [[0.0, 'an electronic copy']],\n",
       " [[0.0, 'the concurrent notional building specifications']],\n",
       " [[0.0, 'model design packages']],\n",
       " [[0.0, 'Such model packages']],\n",
       " [[0.0, 'boiler seasonal efficiencies']],\n",
       " [[0.0, 'The construction industry']],\n",
       " [[0.0, 'model designs']],\n",
       " [[0.0, 'www modeldesigns info 5 4']],\n",
       " [[0.0, 'TFA']],\n",
       " [[0.0, 'air leakage rate per hour per square metre of']],\n",
       " [[0.0, 'the test reference pressure differential']],\n",
       " [[0.0, 'pascals']],\n",
       " [[0.0, 'Overall internal dimensions']],\n",
       " [[0.0, 'subtractions']],\n",
       " [[0.0, 'exterior walls floors']],\n",
       " [[0.0, 'the advancement']],\n",
       " [[0.0, 'setting - to - work']],\n",
       " [[0.0, 'repetitively']],\n",
       " [[0.0, 'fitting sanitation']],\n",
       " [[0.0, 'kWh /']],\n",
       " [[0.0, 'Dwelling']],\n",
       " [[0.0, 'nursing homes']],\n",
       " [[0.0, 'emergency escape lighting process lighting']],\n",
       " [[0.0, 'kgCO2 /']],\n",
       " [[0.0, 'Abbreviations']],\n",
       " [[0.0, 'DL1 DL2']],\n",
       " [[0.0, 'reception point']],\n",
       " [[0.0, 'reception desk']],\n",
       " [[0.0, 'M2 OTHER THAN DWELLINGS']],\n",
       " [[0.0, 'Wheelchair users']],\n",
       " [[0.0, 'ent M1']],\n",
       " [[0.0, 'stairlift']],\n",
       " [[0.0, 'glare']],\n",
       " [[0.0, 'acoustically']],\n",
       " [[0.0, 'Machinery Safety']],\n",
       " [[0.0, 'continuous pressure controls']],\n",
       " [[0.0, 'wide deep']],\n",
       " [[0.0, 'mobility - impaired']],\n",
       " [[0.0, 'Facilities']],\n",
       " [[0.0, 'lip reading']],\n",
       " [[0.0, 'lecture / conference facilities']],\n",
       " [[0.0, 'learning difficulties']],\n",
       " [[0.0, 'spectator facilities']],\n",
       " [[0.0, 'conferences']],\n",
       " [[0.0, 'Accessible stadia']],\n",
       " [[0.0, 'a hearing enhancement system']],\n",
       " [[0.0, 'an advantage']],\n",
       " [[0.0, 'en - suite']],\n",
       " [[0.0, 'hinged']],\n",
       " [[0.0, 'visually impaired']],\n",
       " [[0.0, 'push pads']],\n",
       " [[0.0, 'induction loop']],\n",
       " [[0.0, 'changing seat']],\n",
       " [[0.0, 'separate - sex toilet washrooms']],\n",
       " [[0.0, 'a drop - down rail']],\n",
       " [[0.0, 'sports buildings']],\n",
       " [[0.0, 'left - hand']],\n",
       " [[0.0, 'right - hand transfer']],\n",
       " [[0.0, 'the horizontal support rail']],\n",
       " [[0.0, 'an emergency assistance alarm system']],\n",
       " [[0.0, 'www sportengland org /']],\n",
       " [[0.0, 'Amendment No 1 : 2011']],\n",
       " [[0.0, 'consumer units']],\n",
       " [[0.0, 'the consumer unit']],\n",
       " [[0.0, 'current standards']],\n",
       " [[0.0, 'domestic greenhouses']],\n",
       " [[0.0, 'business premises']],\n",
       " [[0.0, 'shower tray']],\n",
       " [[0.0, 'third - party certifier']],\n",
       " [[3.637978807091713e-12, 'Certification']],\n",
       " [[0.0, 'electrical installation condition report']],\n",
       " [[0.0, 'Part Q']],\n",
       " [[0.0, 'physical attack']],\n",
       " [[0.0, 'PAS 24 : 2012']],\n",
       " [[0.0, 'Secured']],\n",
       " [[0.0, 'Design  s New Homes 2014']],\n",
       " [[0.0, 'Letter plates']],\n",
       " [[0.0, 'technical specification TS 008 : 2012']],\n",
       " [[0.0, 'clear glass']],\n",
       " [[0.0, 'a door chain door limiter']],\n",
       " [[0.0, 'a warden']],\n",
       " [[0.0, 'Alternative caller - identification measures']],\n",
       " [[0.0, 'a multipoint locking system']],\n",
       " [[0.0, 'non - key locking']],\n",
       " [[0.0, 'an external locking override facility']],\n",
       " [[0.0, 'a mortice lock']],\n",
       " [[0.0, 'rim lock']],\n",
       " [[0.0, 'BS 3621']],\n",
       " [[0.0, 'BS 10621']],\n",
       " [[0.0, 'key locking']],\n",
       " [[0.0, 'major renovation works']],\n",
       " [[0.0, 'high - speed electronic communications networks']],\n",
       " [[0.0, 'fibre - optic cables']],\n",
       " [[0.0, 'Mbps']],\n",
       " [[0.0, 'Listed Buildings Conservation Areas']],\n",
       " [[0.0, 'the Electronic Communications Universal Service']],\n",
       " [[0.0, 'PAS 2016']],\n",
       " [[0.0, 'Next generation access']],\n",
       " [[0.0, 'new build homes Guide']],\n",
       " [[0.0, 'BT']],\n",
       " [[0.0, 'Avis juridique']],\n",
       " [[0.0, 'COUNCIL DIRECTIVE 93 / 42 / EEC of 14 June 1993']],\n",
       " [[0.0, 'THE EUROPEAN COMMUNITIES']],\n",
       " [[0.0, 'the European Economic Community']],\n",
       " [[0.0, 'the opinion Social Committee']],\n",
       " [[0.0, 'internal frontiers']],\n",
       " [[0.0, 'capital']],\n",
       " [[0.0, 'disparities']],\n",
       " [[0.0, 'harmonized']],\n",
       " [[0.0, 'sickness insurance schemes']],\n",
       " [[0.0, 'third parties']],\n",
       " [[0.0, 'January 1965']],\n",
       " [[0.0, 'administrative action']],\n",
       " [[0.0, 'a single integral unit']],\n",
       " [[0.0, 'single - unit product']],\n",
       " [[0.0, 'pharmaco - toxicological standards']],\n",
       " [[0.0, 'the Council resolution']],\n",
       " [[0.0, 'uniform Community rules']],\n",
       " [[0.0, 'the electromagnetic compatibility aspects part']],\n",
       " [[0.0, 'ionizing']],\n",
       " [[0.0, 'workers']],\n",
       " [[0.0, 'private - law bodies']],\n",
       " [[0.0, 'mandatory texts']],\n",
       " [[0.0, 'Cenelec']],\n",
       " [[0.0, 'a mandate']],\n",
       " [[0.0, 'European Pharmacopoeia monographs']],\n",
       " [[0.0, 'emergencies']],\n",
       " [[0.0, 'AIDS prevention']],\n",
       " [[0.0, 'Community level']],\n",
       " [[0.0, 'the HIV virus']],\n",
       " [[0.0, 'reclassification']],\n",
       " [[0.0, 'veterinary medicine']],\n",
       " [[0.0, 'HAS ADOPTED']],\n",
       " [[0.0, 'DIRECTIVE']],\n",
       " [[0.0, 'apparatusliance']],\n",
       " [[0.0, 'prevention disease']],\n",
       " [[0.0, 'injuryp']],\n",
       " [[0.0, 'pharmacological']],\n",
       " [[0.0, 'immunological']],\n",
       " [[0.0, 'information state']],\n",
       " [[0.0, 'human clinical environment']],\n",
       " [[0.0, 'labelling']],\n",
       " [[0.0, 'refurb']],\n",
       " [[0.0, 'free of charge']],\n",
       " [[0.0, 'single integral product']],\n",
       " [[0.0, 'an integral part']],\n",
       " [[0.0, 'cosmetic products']],\n",
       " [[0.0, 'human plasma']],\n",
       " [[0.0, 'blood cells']],\n",
       " [[0.0, 'animal tissue']],\n",
       " [[0.0, 'personal protective equipment']],\n",
       " [[0.0, 'Essential requirements']],\n",
       " [[0.0, 'Article 4 Free movement']],\n",
       " [[0.0, 'At trade fairs']],\n",
       " [[0.0, 'Community language']],\n",
       " [[0.0, 'a transitional period']],\n",
       " [[0.0, 'Article 5 Reference']],\n",
       " [[0.0, 'the monographs']],\n",
       " [[0.0, 'surgical sutures']],\n",
       " [[0.0, 'Article 148']],\n",
       " [[0.0, 'The votes']],\n",
       " [[0.0, 'a qualified']],\n",
       " [[0.0, 'Article 8 Safeguard clause 1']],\n",
       " [[0.0, 'shortcomings']],\n",
       " [[0.0, 'Class I Class IIa']],\n",
       " [[0.0, 'Section 4 3 second third subparagraphs']],\n",
       " [[0.0, 'IV']],\n",
       " [[0.0, 'By way']],\n",
       " [[0.0, 'derogation']],\n",
       " [[0.0, 'the mutual compatibility']],\n",
       " [[0.0, 'derogation clause 1']],\n",
       " [[0.0, 'place of business']],\n",
       " [[0.0, 'the relevant clinical investigation']],\n",
       " [[0.0, 'fication']],\n",
       " [[0.0, 'public policy']],\n",
       " [[0.0, 'up to date']],\n",
       " [[0.0, 'Bodies']],\n",
       " [[0.0, 'common accord']],\n",
       " [[0.0, 'time limits']],\n",
       " [[0.0, 'mutual information']],\n",
       " [[0.0, 'the dissemination']],\n",
       " [[0.0, 'criminal law']],\n",
       " [[0.0, 'the 60 - day period']],\n",
       " [[0.0, 'the Ethical Committee']],\n",
       " [[0.0, 'Article 22 Implementation']],\n",
       " [[0.0, 'transitional provisions 1']],\n",
       " [[0.0, 'EEC pattern approval']],\n",
       " [[0.0, 'Luxembourg']],\n",
       " [[0.0, 'Accession']],\n",
       " [[0.0, 'Spain']],\n",
       " [[0.0, 'Portugal']],\n",
       " [[0.0, 'side - effect']],\n",
       " [[0.0, 'body fluids']],\n",
       " [[0.0, 'Infection']],\n",
       " [[0.0, 'Tissues']],\n",
       " [[0.0, 'veterinary controls']],\n",
       " [[0.0, 'Notified']],\n",
       " [[0.0, 'the geographical origin']],\n",
       " [[0.0, 'Processing']],\n",
       " [[0.0, 'transferable agents']],\n",
       " [[0.0, 'validated methods']],\n",
       " [[0.0, 'viral inactivation']],\n",
       " [[0.0, 'sterile']],\n",
       " [[0.0, 'ster']],\n",
       " [[0.0, 'Packaging systems']],\n",
       " [[0.0, 'cleanliness']],\n",
       " [[0.0, 'dimensional features']],\n",
       " [[0.0, 'magnetic fields influences']],\n",
       " [[0.0, 'electrostatic discharge']],\n",
       " [[0.0, 'pressure acceleration']],\n",
       " [[0.0, 'implants']],\n",
       " [[0.0, 'flam']],\n",
       " [[0.0, 'Protection against']],\n",
       " [[0.0, 'variable parameters']],\n",
       " [[0.0, 'Unintended']],\n",
       " [[0.0, 'The operating instructions']],\n",
       " [[0.0, 'image quality']],\n",
       " [[0.0, 'therapeutic radiology way']],\n",
       " [[0.0, 'the beam type energy']],\n",
       " [[0.0, 'the repeatability reliability']],\n",
       " [[0.0, 'electromagnetic fields']],\n",
       " [[0.0, 'electric shocks']],\n",
       " [[0.0, 'moving parts']],\n",
       " [[0.0, 'technical progress']],\n",
       " [[0.0, 'pneumatic energy supplies']],\n",
       " [[0.0, 'Instructions']],\n",
       " [[0.0, 'Any symbol']],\n",
       " [[0.0, 'identification colour standards']],\n",
       " [[0.0, 'STERILE']],\n",
       " [[0.0, 'LOT']],\n",
       " [[0.0, 'costum - made']],\n",
       " [[0.0, 'special operating instructions']],\n",
       " [[0.0, 'resterilization']],\n",
       " [[0.0, 'disinfection']],\n",
       " [[0.0, 'reuses']],\n",
       " [[0.0, 'final assembly']],\n",
       " [[0.0, 'type intensity']],\n",
       " [[0.0, 'contra - indications']],\n",
       " [[0.0, 'magnetic fields']],\n",
       " [[0.0, 'variations pressure']],\n",
       " [[0.0, 'thermal ignition sources']],\n",
       " [[0.0, 'CONFORMITY']],\n",
       " [[0.0, 'efficacious']],\n",
       " [[0.0, 'sloping floor tier']],\n",
       " [[0.0, 'Lighting']],\n",
       " [[0.0, 'battery room']],\n",
       " [[0.0, 'BS ISO 3864 - 1']],\n",
       " [[0.0, 'Advice']],\n",
       " [[0.0, 'the HSE publication Safety Signs']],\n",
       " [[0.0, 'Signals :']],\n",
       " [[0.0, 'Cable routes']],\n",
       " [[0.0, 'PH 30 classification']],\n",
       " [[0.0, 'lobbies']],\n",
       " [[0.0, 'head']],\n",
       " [[0.0, 'Vents']],\n",
       " [[0.0, 'Refuse chutes']],\n",
       " [[0.0, 'refuse hoppers']],\n",
       " [[0.0, 'the open air']],\n",
       " [[0.0, 'refuse storage chambers']],\n",
       " [[0.0, 'Width']],\n",
       " [[0.0, 'external wall Accommodation']],\n",
       " [[0.0, 'Acco']],\n",
       " [[0.0, 'mm min']],\n",
       " [[0.0, 'protected stairway Stair min']],\n",
       " [[0.0,\n",
       "   'Non - fire resisting construction Accommodation Accommodation Configuration A Configuration B protection']],\n",
       " [[0.0, 'mm zone above']],\n",
       " [[0.0, 'mm zone m fire resisting side of stair 6m maximum']],\n",
       " [[0.0, 'Fire doorset height of stair']],\n",
       " [[0.0, 'an independent stairway SECTION AA SECTION BB A B B 1 8m']],\n",
       " [[0.0, 'a podium']],\n",
       " [[0.0, 'protected stairways']],\n",
       " [[0.0, 'protected lobbies']],\n",
       " [[0.0, 'meters stairway']],\n",
       " [[0.0, 'Dimensional']],\n",
       " [[0.0, 'Fixed ladders']],\n",
       " [[0.0, 'Helical stairs']],\n",
       " [[0.0, 'type E stairs']],\n",
       " [[0.0, 'latch']],\n",
       " [[0.0, 'bolt fastenings']],\n",
       " [[0.0, 'fastenings']],\n",
       " [[0.0, 'the fastening']],\n",
       " [[0.0, 'Operable']],\n",
       " [[0.0, 'combination keypad swipe']],\n",
       " [[0.0, 'proximity card']],\n",
       " [[0.0, 'biometric data']],\n",
       " [[0.0, 'Electrically powered locks']],\n",
       " [[0.0, 'the unlocked position']],\n",
       " [[0.0, 'Security mechanism overrides']],\n",
       " [[0.0, 'Amount']],\n",
       " [[0.0, 'Vision panels']],\n",
       " [[0.0, 'revolving doors']],\n",
       " [[0.0, 'turnstiles']],\n",
       " [[0.0, 'outward opening']],\n",
       " [[0.0, 'They failsafe']],\n",
       " [[0.0, 'turnstile']],\n",
       " [[0.0, 'horizontal evacuation']],\n",
       " [[0.0, 'disabled people']],\n",
       " [[0.0, 'a level threshold']],\n",
       " [[0.0, 'transformer chambers']],\n",
       " [[0.0, 'fire spreads']],\n",
       " [[0.0, 'rapid spread']],\n",
       " [[0.0, 'fumes']],\n",
       " [[0.0, 'Furniture']],\n",
       " [[0.0, 'linings Location Classification Small rooms']],\n",
       " [[0.0, 'Wallcoverings']],\n",
       " [[0.0, 'Window frames']],\n",
       " [[0.0, 'Architraves']],\n",
       " [[0.0, 'cover moulds']],\n",
       " [[0.0, 'picture rails']],\n",
       " [[0.0, 'narrow members']],\n",
       " [[0.0, 'Fireplace surrounds']],\n",
       " [[0.0, 'mantle shelves']],\n",
       " [[0.0, 'Glazed surfaces']],\n",
       " [[0.0, 'exposed beams']],\n",
       " [[0.0, 'Special applications']],\n",
       " [[0.0, 'an air - supported structure']],\n",
       " [[0.0, 'PTFE - based materials']],\n",
       " [[0.0, 'tension - membrane roofs']],\n",
       " [[0.0, 'Fire behaviour']],\n",
       " [[0.0, 'insulating core panels']],\n",
       " [[0.0, 'internally']],\n",
       " [[0.0, 'class A1 cored panels']],\n",
       " [[0.0, 'Fixing systems']],\n",
       " [[0.0, 'delaminate']],\n",
       " [[0.0, 'fire - protecting suspended ceilings']],\n",
       " [[0.0, 'PART OF']],\n",
       " [[0.0, 'DIFFUSER IN']],\n",
       " [[0.0, 'FITTING BELOW']],\n",
       " [[0.0, 'FORMING']],\n",
       " [[0.0, 'wall ceiling surfaces']],\n",
       " [[0.0, 'Suspended']],\n",
       " [[0.0, 'm dimension']],\n",
       " [[0.0, 'group 5m dimension']],\n",
       " [[0.0, 'group Rooflight']],\n",
       " [[0.0, 'diffuser NOTES :']],\n",
       " [[0.0, 'plastic panels']],\n",
       " [[0.0, 'No restriction D - s3']],\n",
       " [[0.0, 'lighting diffusers ceilings']],\n",
       " [[0.0, 'The overall size']],\n",
       " [[0.0, 'the maximum percentage quoted']],\n",
       " [[0.0, 'dimension x']],\n",
       " [[0.0, 'dimension y Ceiling plan Materials']],\n",
       " [[0.0, 'concealed spaces']],\n",
       " [[0.0, 'stabilis']],\n",
       " [[0.0, 'forms of cladding']],\n",
       " [[0.0, 'semi - detached']],\n",
       " [[0.0, 'rafters']],\n",
       " [[0.0, 'trussed']],\n",
       " [[0.0, 'the truss']],\n",
       " [[0.0, 'Junction compartment wall']],\n",
       " [[0.0, 'timber tiling battens']],\n",
       " [[0.0, 'ANY']],\n",
       " [[0.0, 'Roof covering']],\n",
       " [[0.0, 'profiled steel cladding']],\n",
       " [[0.0, 'mm Double - skinned insulated']],\n",
       " [[0.0, 'roof sheeting']],\n",
       " [[0.0, 'a band material']],\n",
       " [[0.0, 'roof support members']],\n",
       " [[0.0, 'mm side']],\n",
       " [[0.0, 'RESIDENTIAL']],\n",
       " [[0.0, 'OTHER']],\n",
       " [[0.0, 'M HIGH Roof covering']],\n",
       " [[0.0, 'Boarding']],\n",
       " [[0.0, 'bedded']],\n",
       " [[0.0, 'Sarking felt']],\n",
       " [[0.0, 'boarding slab']],\n",
       " [[0.0, 'Section XX Roof covering']],\n",
       " [[0.0, 'Roofing battens']],\n",
       " [[0.0, 'the upstand / parapet wall']],\n",
       " [[0.0, 'Wall 200mm']],\n",
       " [[0.0, 'exit / entry points']],\n",
       " [[0.0, 'this arrangement performance']],\n",
       " [[0.0, 'Domestic meter cupboards']],\n",
       " [[0.0, 'two cupboards dwelling b']],\n",
       " [[0.0, 'cupboard Close cavity']],\n",
       " [[0.0, 'Two leaves']],\n",
       " [[0.0, 'Timber']],\n",
       " [[0.0, 'Polythene']],\n",
       " [[0.0, 'sleeved mineral wool']],\n",
       " [[0.0, 'compression']],\n",
       " [[0.0, 'Calcium silicate']],\n",
       " [[0.0, 'cement - based']],\n",
       " [[0.0, 'slates']],\n",
       " [[0.0, 'corrugated sheeting']],\n",
       " [[0.0, 'a fire resisting wall partition collapses']],\n",
       " [[0.0, 'Ducts']],\n",
       " [[0.0, 'parking vehicles']],\n",
       " [[0.0, 'Tables B3 B4']],\n",
       " [[0.0, 'deform']],\n",
       " [[0.0, 'vertical load']],\n",
       " [[0.0, 'the middle half of']],\n",
       " [[0.0, 'the deflection']],\n",
       " [[0.0, 'compartmentation Openings']],\n",
       " [[0.0, 'Pipes']],\n",
       " [[0.0, 'chutes']],\n",
       " [[0.0, 'Atria']],\n",
       " [[0.0, 'Annexes B C']],\n",
       " [[0.0, 'service shafts']],\n",
       " [[0.0, 'Escalators']],\n",
       " [[0.0, 'uninsulated']],\n",
       " [[0.0, 'three common examples']],\n",
       " [[0.0, 'Compartment wall Fd Fd External shaft A Protected shaft C']],\n",
       " [[0.0, 'compartment bounded']],\n",
       " [[0.0, 'sides walls fourth']],\n",
       " [[0.0, 'compartment walls Fd Fire doorset']],\n",
       " [[0.0, 'CORRIDOR b']],\n",
       " [[0.0,\n",
       "   'WITH LOBBY Protected Protected shaft shaft Corridor Lobby Glazed Glazed screen screen Fire resistance']],\n",
       " [[0.0, 'Sa Fire resistance']],\n",
       " [[0.0, 'protected shaft lobby']],\n",
       " [[0.0, 'corridor Pipes']],\n",
       " [[0.0, 'LPG']],\n",
       " [[0.0, 'Of screwed steel']],\n",
       " [[0.0, 'welded steel construction']],\n",
       " [[0.0, 'Situations']],\n",
       " [[0.0, 'Other parts']],\n",
       " [[0.0, 'Inlets']],\n",
       " [[0.0, 'cavity closures']],\n",
       " [[0.0, 'profiled insulated']],\n",
       " [[0.0, 'Both surfaces']],\n",
       " [[0.0, 'Roof floor cavity The ceiling']],\n",
       " [[0.0, 'Ceiling surface /']],\n",
       " [[0.0, 'product exposed']],\n",
       " [[0.0, 'demountable']],\n",
       " [[0.0, 'Soffit']],\n",
       " [[0.0, 'Cavity barrier Insulation']],\n",
       " [[0.0, 'Every joint fit']],\n",
       " [[0.0, 'Alternative B : Pipes']],\n",
       " [[0.0, 'a proprietary sealing system']],\n",
       " [[0.0, 'an above - ground drainage system']],\n",
       " [[0.0, 'melting point metal']],\n",
       " [[0.0, 'Aluminium']],\n",
       " [[0.0, 'Aluminium alloy']],\n",
       " [[0.0, 'Fibre - cement']],\n",
       " [[0.0, 'uPVC']],\n",
       " [[0.0, 'BS 4514']],\n",
       " [[0.0, 'BS 5255']],\n",
       " [[0.0, 'hot gas']],\n",
       " [[0.0, 'flaming droplets']],\n",
       " [[0.0, 'the casing']],\n",
       " [[0.0, 'Pipe specification']],\n",
       " [[0.0, 'Sleeve']],\n",
       " [[0.0, 'The sleeve']],\n",
       " [[0.0, 'aluminium alloy']],\n",
       " [[0.0, 'uPVC pipes']],\n",
       " [[0.0, 'exhaust points']],\n",
       " [[0.0, 'thermally activated fire dampers']],\n",
       " [[0.0, 'fire resisting ductwork']],\n",
       " [[0.0, 'Smoke detector - controlled automatic release mechanisms']],\n",
       " [[0.0, 'Thermally actuated']],\n",
       " [[0.0, 'grease']],\n",
       " [[0.0, 'fire resisting ductwork Ductwork']],\n",
       " [[0.0, 'EIS X']],\n",
       " [[0.0,\n",
       "   'BS EN 1366 - 2 Protected stairway Fd Protected lobby Fd Smoke detection system']],\n",
       " [[0.0, 'actuating mechanism']],\n",
       " [[0.0, 'BS EN 15650 b']],\n",
       " [[0.0, 'Smoke detectors']],\n",
       " [[0.0, 'the ASFP Grey Book']],\n",
       " [[0.0,\n",
       "   'compartment wall Compartment wall floor Flue Compartment Compartment wall wall']],\n",
       " [[0.0, 'Flue wall Flue walls']],\n",
       " [[0.0, 'cable']],\n",
       " [[0.0, 'span']],\n",
       " [[0.0, 'suitability']],\n",
       " [[0.0, 'Different materials']],\n",
       " [[0.0, 'Cement mortar']],\n",
       " [[0.0, 'Cement - based']],\n",
       " [[0.0, 'vermiculite']],\n",
       " [[0.0, 'perlite mixes']],\n",
       " [[0.0, 'crushed rock']],\n",
       " ...]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the smallest clusters\n",
    "[v for v in phrase_cluster_dict.values() if len(v) == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0194b",
   "metadata": {},
   "source": [
    "### 4 Suggesting similar terms for Uniclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67baa7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Here we predict (1) expansion candidates and (2) potential inflections (based on Levenshtein distance) for a given term. \n",
    "</div>\n",
    "\n",
    "\n",
    "* We run our algorithm on all Uniclass terms to get a feel for the output we generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "93a16c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterAssignment:\n",
    "    def __init__(self, pkl_model, embedder, unique_spans, standardised_clustering_data, phrase_cluster_dict, clusters_to_filter):\n",
    "        \"\"\"\n",
    "        It's important to use the standardised clustering data here!\n",
    "        \"\"\"\n",
    "        self.centroids, self.assignments = pickle.load(open(pkl_model, 'rb'))\n",
    "        self.num_clusters = int(max(self.assignments) + 1)\n",
    "        \n",
    "        # set up sklearn for prediction\n",
    "        cpu_centroids = np.nan_to_num(self.centroids, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "        self.cpu_clusterer = KMeans(self.num_clusters, init=cpu_centroids, n_init=1, max_iter=1, tol=0)\n",
    "        print(\"[Clustering] Initialising sklearn kMeans with 1 iteration on KMcuda outputs. This takes some time!\")\n",
    "        self.cpu_clusterer.fit(standardised_clustering_data)\n",
    "        \n",
    "        self.embedder = embedder\n",
    "        self.unique_span_dict = dict(zip(unique_spans, standardised_clustering_data))\n",
    "        self.cluster_dict = phrase_cluster_dict\n",
    "        self.clusters_to_filter = clusters_to_filter\n",
    "    \n",
    "\n",
    "    def sklearn_assign(self, to_be_clustered: List[cluster_utils.ToBeClustered]) -> List[cluster_utils.ToBeClustered]:\n",
    "        \"\"\"\n",
    "        Using SciKit Learn's CPU implementation of KMeans to assign cluster IDs to a span or list of spans.\n",
    "\n",
    "        :param to_be_predicted: A `str` or `list` of strings for which a cluster ID will be computed.\n",
    "        :return :   List of cluster IDs.\n",
    "        \"\"\"\n",
    "        # Note: we try to avoid iteratively assigning clusters for each item in a list - don't think we parallelize more\n",
    "        embeddings = [s.embedding for s in to_be_clustered]\n",
    "        arrays = [np.ones([1, 768]).astype(np.float32) for _ in to_be_clustered]\n",
    "\n",
    "        for i, e in enumerate(embeddings):\n",
    "            arrays[i][0] = np.stack(e.squeeze())  # .astype(np.float16)\n",
    "\n",
    "        assignments = []\n",
    "        for arr in arrays:\n",
    "            assignments.append(self.cpu_clusterer.predict(arr))\n",
    "\n",
    "        for idx, assignment in enumerate(assignments):\n",
    "            to_be_clustered[idx].cluster_id = str(int(assignment))\n",
    "#             print(f\"assigned ID: {str(int(assignment))}\")\n",
    "            to_be_clustered[idx].distance_to_centroid = np.sum(np.absolute(embeddings[idx]-self.centroids[assignment]))\n",
    "            to_be_clustered[idx].all_neighbours = self.cluster_dict[str(int(assignment))]\n",
    "\n",
    "        return to_be_clustered\n",
    "    \n",
    "    def get_top_neighbours(self, \n",
    "                           text_inputs : Union[List[str], str], \n",
    "                           cosine_sim_threshold: float = 0.7, \n",
    "                           top_k: int = 3,\n",
    "                           return_non_aec=False):\n",
    "        if type(text_inputs) == str:\n",
    "            NON_AEC = False\n",
    "            tbc = cluster_utils.ToBeClustered(text_inputs, embedder)\n",
    "            [tbc] = self.sklearn_assign([tbc])\n",
    "            if tbc.cluster_id in self.clusters_to_filter:\n",
    "#                 print(f\"Potentially non-AEC domain: {tbc.text}\")\n",
    "                NON_AEC = True\n",
    "                \n",
    "            if not return_non_aec and NON_AEC:\n",
    "                return [], []\n",
    "            else:\n",
    "                neighbours, inflections = tbc.get_top_k_neighbours(self.unique_span_dict, cosine_sim_threshold, top_k)\n",
    "                return neighbours, inflections\n",
    "        else:\n",
    "            tbcs = [cluster_utils.ToBeClustered(t, embedder) for t in text_inputs]\n",
    "            tbcs = self.sklearn_assign(tbcs)\n",
    "            neighbours = []\n",
    "            inflections = []\n",
    "            for tbc in tbcs:\n",
    "                NON_AEC = False\n",
    "                if tbc.cluster_id in self.clusters_to_filter:\n",
    "#                     print(f\"Potentially non-AEC domain: {tbc.text}\")\n",
    "                    NON_AEC = True\n",
    "                if not return_non_aec and NON_AEC:\n",
    "                    neighbours.append([])\n",
    "                    inflections.append([])\n",
    "                else:\n",
    "                    n, i = tbc.get_top_k_neighbours(self.unique_span_dict, cosine_sim_threshold, top_k)\n",
    "                    neighbours.append(n)\n",
    "                    inflections.append(i)\n",
    "            return neighbours, inflections\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f95dfe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clustering] Initialising sklearn kMeans with 1 iteration on KMcuda outputs. This takes some time!\n"
     ]
    }
   ],
   "source": [
    "cluster_assigner = ClusterAssignment(cluster_model_to_use, embedder, unique_spans, standardised_clustering_data, phrase_cluster_dict, clusters_to_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116ca64",
   "metadata": {},
   "source": [
    "* some examples of assigning clusters and identifying neighbours for spans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a30eab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], ['party walls', 'Party walls'])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example str input\n",
    "cluster_assigner.get_top_neighbours(\"party wall\", cosine_sim_threshold=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "00101129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[], ['test equipment', 'electrical equipment']], [[], ['control equipment']])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example list of str input\n",
    "cluster_assigner.get_top_neighbours([\"hollow structural member\", \"control equipment\"], cosine_sim_threshold=.7, return_non_aec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "58dd9968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example str input\n",
    "cluster_assigner.get_top_neighbours(\"Activities\", cosine_sim_threshold=.7, return_non_aec=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d106a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We read Uniclass terms from a .ttl file that we have previoulsy prepared.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2fc2c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ttl_lines(text):\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    for idx, line in enumerate(text.split(\"\\n\")):\n",
    "        if line == '':\n",
    "            if current_group:\n",
    "                groups.append(current_group)\n",
    "            current_group = []\n",
    "        else:\n",
    "            current_group.append(line)\n",
    "            if idx+1 == len(text.split(\"\\n\")):\n",
    "                groups.append(current_group)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a399aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_uids_and_labels_with_definition(groups):\n",
    "    uid_dict = {}\n",
    "    for g in groups:\n",
    "        if any([line.startswith('  skos:prefLabel') for line in g]):\n",
    "            # only use group if a prefLabel exists\n",
    "            pref_label = ''\n",
    "            alt_labels = []\n",
    "            definition = ''\n",
    "            for line in g:\n",
    "                if line.startswith('  skos:prefLabel'):\n",
    "                    pref_label = line.split('\"')[1]\n",
    "                elif line.startswith('  skos:altLabel'):\n",
    "                    labels = line.split('\"')[1::2]\n",
    "                    alt_labels += labels\n",
    "                elif line.startswith('  skos:definition'):\n",
    "                    definition = line.split('\"')[1]\n",
    "\n",
    "            if pref_label:\n",
    "                uid = g[0].split()[0].split(\":\")[1]\n",
    "                uid_dict[uid] = {'pref_label': pref_label, \n",
    "                                 'alt_labels': alt_labels,\n",
    "                                 'definition': definition\n",
    "                                }\n",
    "    return uid_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a3b8ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_nodes(vocab_name):\n",
    "    processed_file = f\"{vocab_name}.json\"\n",
    "    \n",
    "    # check if file as processed before \n",
    "    NODES_LOADED = False\n",
    "    if os.path.exists(processed_file):\n",
    "        with open(processed_file) as f:\n",
    "            graph_dict = json.load(f)\n",
    "            \n",
    "        NODES_LOADED = True\n",
    "        print(f\"Loaded nodes and neighbours for: {vocab_name}\") \n",
    "    else: \n",
    "        print(f\"Will have to grab nodes for: {vocab_name}\")\n",
    "    \n",
    "        # compute the neighbours for each node\n",
    "        graph_dict = {}\n",
    "        \n",
    "        print(f\"Working on file: {vocab_name}\")\n",
    "        with open(vocab_name, 'r') as f:\n",
    "            text =  f.read()\n",
    "            \n",
    "        groups = group_ttl_lines(text)\n",
    "        print(\"Collecting nodes with definitions from dict\")\n",
    "        graph_dict = grab_uids_and_labels_with_definition(groups)\n",
    "        \n",
    "        # save the dictionary somewhere for reloading\n",
    "        with open(processed_file, 'w') as f:\n",
    "            json.dump(graph_dict, f)\n",
    "    return graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4fa0845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nodes and neighbours for: data/input/uniclass_2015.ttl\n"
     ]
    }
   ],
   "source": [
    "uniclass_dict = grab_nodes(\"data/input/uniclass_2015.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a31dd1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15020"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniclass_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b18c51",
   "metadata": {},
   "source": [
    "* Feed the Uniclass labels to our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2615e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                               | 140/15020 [00:09<18:07, 13.69it/s]"
     ]
    }
   ],
   "source": [
    "expansion_candidates =  {}\n",
    "for k, v in tqdm(uniclass_dict.items()):\n",
    "    uniclass_label = v['pref_label']\n",
    "    if uniclass_label:\n",
    "        expansion_terms, inflections = cluster_assigner.get_top_neighbours(uniclass_label, \n",
    "                                                                           cosine_sim_threshold=.7,\n",
    "                                                                           top_k=5,\n",
    "                                                                           return_non_aec=False)\n",
    "        expansion_candidates[uniclass_label] = {\"expansions\": expansion_terms,\n",
    "                                                \"inflections\": inflections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093dac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expansion_candidates(expansion_candidates: Dict[str, str]):\n",
    "    number_of_terms_with_expansion_candidates = 0\n",
    "    for k, v in expansion_candidates.items():\n",
    "        if v['expansions'] or v['inflections']:\n",
    "            print(f\"==========================\\nTerm: {k}\")\n",
    "            print(f\"Related: {v['expansions']}\")\n",
    "            print(f\"Inflections: {v['inflections']}\")\n",
    "            number_of_terms_with_expansion_candidates += 1\n",
    "\n",
    "    print(\"\\n\\n\\nAmount of terms with candidates:\\n{} ({:.2f}%)\".format(\n",
    "        number_of_terms_with_expansion_candidates,\n",
    "        number_of_terms_with_expansion_candidates/len(expansion_candidates)*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b9516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_expansion_candidates(expansion_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f15bb5",
   "metadata": {},
   "source": [
    "* Our own list of terms of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b803486",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_of_interest = ['Timber frame floors and roofs',  'EPS',  'Water services',  'Subsystems',  'External thermal insulation composite system with rendering ',  'Smoke and fire-stopping',  'Timber baseboards',  'PV panels',  'Ceramic slates',  'Vertical smoke strip curtains',  'Hardwood deck boards',  'Roof type',  'Flat roof ',  'Aluminium external panels',  'Material',  'Ethylene propylene (EP) damp-proof courses and cavity trays',  'Vertical smoke curtains',  'Light-gauge steel floors and roofs',  'Fibre-cement',  'Fibre-reinforced cement boards',  'Services',  'Fire alarm systems',  'HVAC equipment',  'Covering',  'Mineral wool insulation',  'Components',  'Roof structure - flat',  'CLT',  'Aluminium cassette panels',  'Fibre-reinforced cement sheets',  'Weathering steel cassette panels',  'Clay roofing tiles',  'Batteries',  'Natural stone',  'Bitumen-based damp-proof courses and cavity trays',  'Board suspended ceiling systems',  'Green roofs/gardens',  'Maintenance access',  'Softwood baseboards',  'Polyurethane (PUR) foam boards',  'Sheet panels',  'Glulam',  'Flexible sheet for waterproofing',  'Panelled and framed modular systems',  'Vertical active fire curtain barriers',  'Gypsum core boards',  'Barriers',  'Light steel roof framing systems',  'Natural stone panels',  'Timber sheet panels',  'Mineral wool wire-reinforced mattress cavity barriers',  'Structural frame',  'Aluminium internal panels',  'Roof diaphragm',  'Structural connectors',  'Timber',  'Roof windows',  'Reinforced concrete',  'Ceramic tiles',  'LWSF - Light weight steel-frame',  'Panel of steel-wires with incorporated thermal insulation',  'Water tightness',  'Structural',  'Structural insulated panel systems',  'Cold-applied roofing membrane adhesive damp-proof course joint sealers',  'Mineral fibre slab insulation',  'Cross-laminated timber (CLT) panelled modules',  'Membranes',  'Ceiling and soffit systems',  'Green roof',  'Skylights',  'Extruded polyethylene (PE) foam boards',  'Plain tile roofing systems',  'Wood-based panels',  'Blue roof',  'Insulated damp-proof courses',  'Interfacial',  'Light-gauge steel frame panels',  'Aluminium structures',  'Timber board panels',  'Bitumen membrane shingles',  'Mastic asphalt (MA) damp-proof courses',  'Deck frame',  'ICT',  'Gypsum baseboards',  'Flexible stone wool mat insulation',  'Pitched roof ',  'Fire insulating caps',  'Active smoke barriers',  'Fibre cement slate roofing systems',  'Steel structures',  'Photovoltaic devices',  'Structural insulated panel (SIP) modules',  'Mineral wool slab insulation',  'XPS',  'Sound proofing',  'Ceiling cassettes',  'Highlighted relevant item',  'Hardboards',  'Intumescent sleeved mineral wool cavity fire barriers',  'Thermal insulation',  'Solar photovoltaic modules',  'Wood structures',  'Aluminium-faced aluminium core panels',  'Steel deck',  'P-DfMA Standards Database',  'Rain drainage',  'Polymeric damp-proof courses',  'Active Roof',  'Flexible intumescent gap seals',  'Bonded sheets',  'Underlays for discontinuous roofing',  'Bitumen sheets',  'Prefabricated framed and panelled structures',  'Panels',  'Composite',  'Active roof',  'Sealants',  'Building elements',  'Hardwood baseboards',  'Light gauge steel frame',  'Mineral wool flexible insulation',  'Energy storage',  'Air tightness',  'Passive roof',  'Ceramic panels',  'Vapour control layer',  'Mineral wool',  'Energy generation and storage',  'Softwood deck boards',  'Ceramic fibre fire-stopping',  'Intumescent linear gap seals',  'Gypsum plasterboards',  'Oriented strand boards',  'Non-loadbearing',  'Wood-based boards',  'Roof-mounted photovoltaic',  'Tapered insulation',  'Solar thermal systems',  'Carbon steel insulating sandwich panels',  'Fire detection',  'LVL',  'Fibre-cement slates',  'Insulation',  'Cold roof ',  'Self-supporting double skin metal faced insulating panels',  'Composite panels',  'Carbon steel framed vertical bar and rail panels',  'Mineral wool fire-stopping',  'Warm roof ',  'Damp-proof courses and cavity trays',  'Flexible plasterboards',  'Superstructure',  'Prefabricated building units ',  'Aluminium composite material (ACM) panels',  'Natural slates',  'Fire-fighting systems',  'Mechanical services',  'Bitumen membrane shingle roofing systems',  'Wood laminate strips and boards',  'Ceramic',  'PIR',  'Plastics membranes',  'Extruded polystyrene (XPS) boards',  'Composite lightweight panels',  'Bitumen membrane',  'Rainwater harvesting',  'Coated woven glass fibre cloth flexible cavity barriers',  'Wood fibre boards',  'Polyisocyanurate (PIR) foam boards',  'Timber lining boards',  'Pre-fabricated wood-based loadbearing stressed skin panels',  'External wall',  'Fully bonded pre applied flexible sheet for water proofing ',  'Plywood desk',  'Load bearing',  'Concrete roofing tiles',  'Expanded polystyrene (EPS) boards',  'Timber structures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_expansion_candidates =  {}\n",
    "for term in tqdm(terms_of_interest):\n",
    "#     term = term if term.isupper() else term.lower() # remove capitalisation if not an abbreviation\n",
    "    expansion_terms, inflections = cluster_assigner.get_top_neighbours(term, \n",
    "                                                                       cosine_sim_threshold=.7,\n",
    "                                                                       top_k=5,\n",
    "                                                                       return_non_aec=False)\n",
    "    term_expansion_candidates[term] = {\"expansions\": expansion_terms,\n",
    "                                       \"inflections\": inflections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_expansion_candidates(term_expansion_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f35250",
   "metadata": {},
   "source": [
    "* Identify potential mappings based on overlap in expansion candidates and inflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1, v1 in expansion_candidates.items():\n",
    "    for k2, v2 in term_expansion_candidates.items(): \n",
    "        if any([candidate for candidate in v1['expansions'] + v1['inflections'] if (candidate in v2['expansions'] or candidate in v2['inflections'])]):\n",
    "            print(f\"Match?===============\\nUniclass: {k1}\\nBRE: {k2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b0d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c732b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0fdd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
