{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788a8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM cuda not found, defaulting to sklearn CPU version of kmeans\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Any, Optional, Dict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import urllib\n",
    "import requests\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from threading import current_thread\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "try:\n",
    "    from libKMCUDA import kmeans_cuda\n",
    "except:\n",
    "    print(\"KM cuda not found, defaulting to sklearn CPU version of kmeans\")\n",
    "    kmeans_cuda = None\n",
    "\n",
    "import utils\n",
    "import embedding\n",
    "import cluster_utils\n",
    "import IDF_computation\n",
    "from customdocument import CustomDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081bf43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "We will run our term extraction on the Merged Approved Documents, the .pdf file can be found in the `data/` directory. For filtering of out-of-domain terms we will also process a set of EU regulations for medical device design, the .html files for these can be found in the same directory.\n",
    "</div>\n",
    "\n",
    "1. Preprocessing will consist only of removing headers/footers from PDF files. \n",
    "\n",
    "2. Candidate terms are identified using SPaR.txt (Kruiper et al., 2021), sentence splitting is done with the PunkSentTokenizer (Strunk, 2006).\n",
    "\n",
    "3. Filtering of term candidates consists of:\n",
    "  * a set of regular expressions found in utils.py\n",
    "  * clustering of terms found in (1) the Approved Documents, and (2) a set of EU regulations for medical device design; any clusters containing terms from (2) will be designated as terms that are irrelevant to the AEC domain.\n",
    "  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a98d0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1 Preprocessing: get text from PDF and HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f74d6fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved Documents: data/input/The Merged Approved Documents.pdf\n",
      "Reference corpus: ['data/input/EUR-Lex - 31993L0042 - EN.html', 'data/input/CELEX 32017R0746 EN TXT.html', 'data/input/CELEX 32017R0745 EN TXT.html', 'data/input/EUR-Lex - 31998L0079 - EN.html', 'data/input/EUR-Lex - 31990L0385 - EN.html']\n"
     ]
    }
   ],
   "source": [
    "merged_approved_pdf_file = glob.glob(\"data/input/*.pdf\")[0]\n",
    "eu_html_files = glob.glob(\"data/input/*.html\")\n",
    "print(f\"Approved Documents: {merged_approved_pdf_file}\")\n",
    "print(f\"Reference corpus: {eu_html_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bdc02",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "First we grab the text from the Merged Approved Documents pdf file. Our implementation is based on the pdf conversion pipeline in Haystack.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0d20e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path: Path, layout: bool = True, encoding: Optional[str] = \"Latin1\") -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract pages from the pdf file at file_path; based on Haystack.\n",
    "\n",
    "        :param file_path: path of the pdf file\n",
    "        :param layout: whether to retain the original physical layout for a page. If disabled, PDF pages are read in\n",
    "                       the content stream order.\n",
    "        \"\"\"\n",
    "        if layout:\n",
    "            command = [\"pdftotext\", \"-enc\", encoding, \"-layout\", str(file_path), \"-\"]\n",
    "        else:\n",
    "            command = [\"pdftotext\", \"-enc\", encoding, str(file_path), \"-\"]\n",
    "        output = subprocess.run(command, stdout=subprocess.PIPE, shell=False)  # type: ignore\n",
    "        document = output.stdout.decode(errors=\"ignore\")\n",
    "        pages = document.split(\"\\f\")\n",
    "        pages = pages[:-1]  # the last page in the split is always empty.\n",
    "        return pages\n",
    "\n",
    "def convert_pdf_to_mydoc(source_file_path: Path, \n",
    "                         output_file_path: Path, \n",
    "                         meta: Optional[Dict[str, str]] = None,\n",
    "                         remove_header_and_footer: Optional[bool] = True,\n",
    "                         clean_whitespace: Optional[bool] = True,\n",
    "                         clean_empty_lines: Optional[bool] = True,\n",
    "                         encoding: Optional[str] = \"Latin1\") -> CustomDocument:\n",
    "        \"\"\"\n",
    "        Extract pages from the pdf file at file_path; based on Haystack.\n",
    "\n",
    "        :param output_file_path:    Path to the .json file to store the converted file.\n",
    "        :param source_file_path:    Path to the .pdf file you want to convert\n",
    "        :param meta: Optional dictionary with metadata that shall be attached to all resulting documents.\n",
    "                     Can be any custom keys and values.\n",
    "        :param encoding: Encoding that will be passed as -enc parameter to pdftotext. \"Latin 1\" is the default encoding\n",
    "                         of pdftotext. While this works well on many PDFs, it might be needed to switch to \"UTF-8\" or\n",
    "                         others if your doc contains special characters (e.g. German Umlauts, Cyrillic characters ...).\n",
    "                         Note: With \"UTF-8\" we experienced cases, where a simple \"fi\" gets wrongly parsed as\n",
    "                         \"xef\\xac\\x81c\" (see test cases). That's why we keep \"Latin 1\" as default here.\n",
    "                         (See list of available encodings by running `pdftotext -listenc` in the terminal)\n",
    "        \"\"\"\n",
    "        pages = read_pdf(source_file_path, layout=True, encoding=encoding)\n",
    "\n",
    "        if not pages:\n",
    "            # empty input file\n",
    "            return None\n",
    "        \n",
    "        pages = [\"\\n\".join(p.splitlines()) for p in pages]\n",
    "\n",
    "        # splitting text happens during preprocessing, so no split_size passed here;\n",
    "        # split_size will be set to -1 during conversion.\n",
    "        document = CustomDocument(output_file_path, source_file_path, split_size=-1)\n",
    "        \n",
    "        print(\"Converted PDF file to pages of text, combining to a single CustomDocument to keep track of page nrs.\")\n",
    "        for page_idx, page in tqdm(enumerate(pages)):\n",
    "            \n",
    "            # some simple cleaning -- roughly based on haystack.\n",
    "            lines = page.splitlines()\n",
    "            if remove_header_and_footer:\n",
    "                # simplest way for removing header and footer\n",
    "                lines = lines[1:-2]\n",
    "\n",
    "            if clean_whitespace:\n",
    "                cleaned_lines = []\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    cleaned_lines.append(line)\n",
    "                text = \" \".join(cleaned_lines)\n",
    "\n",
    "            if clean_empty_lines:\n",
    "                text = re.sub(r\"\\n\\n+\", \"\\n\\n\", text)\n",
    "                text = re.sub(r\"[\\s]+\", \" \", text)\n",
    "            \n",
    "            # no splitting here yet, so simply using page_nr as a place holder and split_id is left blank\n",
    "            page_nr = str(page_idx + 1)\n",
    "            document.add_content(text=text, \n",
    "                                 page_nr=page_nr, \n",
    "                                 doc_title=source_file_path.rsplit('/',1)[1])   # we're using the pdf file name for simplicity\n",
    "\n",
    "        return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71184fcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted PDF file to pages of text, combining to a single CustomDocument to keep track of page nrs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1274it [00:00, 7429.52it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_approved_document = convert_pdf_to_mydoc(merged_approved_pdf_file, \"data/converted_documents/merged_approved.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1473ee8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum character length for a single block of text: 5537\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum character length for a single block of text: {max([len(c.text) for c in merged_approved_document.all_contents])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203400ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84117041",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Second, we grab the text from the EU regulation HTML files. Because the text in HTML files isn't split into pages, the blocks of text are much longer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bb53f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def grab_HTML_text_simple(file):\n",
    "    \"\"\"\n",
    "    All text in the EU htmls seems to be captured neatly in <p> tags, we don't care about structure currently.\n",
    "    We do remove all unicode characters, see `utils.remove_unicode_chars()`.\n",
    "    \"\"\" \n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return [utils.remove_unicode_chars(x.text) for x in soup.body.find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6630e6ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_html_to_mydoc(source_file_path: Path, \n",
    "                          output_file_path: Path) -> CustomDocument:\n",
    "    \n",
    "    document = CustomDocument(output_file_path, source_file_path, split_size=-1)\n",
    "    document_paragraphs = []\n",
    "    list_of_paragraphs = grab_HTML_text_simple(html_file)\n",
    "    for paragraph in list_of_paragraphs:\n",
    "        if paragraph.strip() != '':\n",
    "            document_paragraphs.append(paragraph)\n",
    "    \n",
    "    for paragraph_idx, paragraph in tqdm(enumerate(document_paragraphs)):\n",
    "            # no splitting here yet, so simply using page_nr as a place holder and split_id is left blank\n",
    "            paragraph_nr = str(paragraph_idx + 1)\n",
    "            document.add_content(text=paragraph, \n",
    "                                 page_nr=paragraph_nr, \n",
    "                                 doc_title=source_file_path) # we're using the html file name for simplicity\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b68b58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/5 [00:00<?, ?it/s]\n",
      "826it [00:00, 338825.93it/s]\n",
      "\n",
      "4344it [00:00, 351602.79it/s]\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 2/5 [00:00<00:01,  2.26it/s]\n",
      "4799it [00:00, 368531.71it/s]\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3/5 [00:01<00:01,  1.67it/s]\n",
      "623it [00:00, 233079.24it/s]\n",
      "\n",
      "511it [00:00, 227718.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "eu_regulation_documents = []\n",
    "for html_file in tqdm(eu_html_files):\n",
    "    outfile = f\"data/converted_documents/{html_file.rsplit('/',1)[1]}.json\"\n",
    "    eu_regulation_documents.append(convert_html_to_mydoc(html_file, outfile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033634ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum character length for a single paragraph: 143428\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum character length for a single paragraph: {max([len(c.text) for d in eu_regulation_documents for c in d.all_contents])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77347abc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Third, if the output document doesn't exist (yet), we save the ConvertedDocument.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24237e3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "foreground_corpus = [merged_approved_document]\n",
    "background_corpus = eu_regulation_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a00ed81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in foreground_corpus + background_corpus:\n",
    "    if not os.path.exists(d.output_fp):\n",
    "        d.write_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6e56a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2 Term extraction: identify object spans with SPaR.txt\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "For each of the contents in a document, run SPaR.txt for object identification. To this end, we split the text into sentences and pass a sentence to a running instance fo a SPaR.txt predictor.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf22a14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# download SPaR.txt if required\n",
    "if not os.path.exists(\"SPaR.txt/README.md\"):\n",
    "    !git clone https://github.com/rubenkruiper/SPaR.txt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19aa4ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "with open('SPaR.txt/spar_predictor.py', 'rb') as fp:\n",
    "    spar_predictor = imp.load_module(\n",
    "        'spar_predictor', fp, 'SPaR.txt.spar_predictor.py',\n",
    "        ('.py', 'rb', imp.PY_SOURCE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9daef1de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# trains a model if needed, otherwise loads from archive; \n",
    "# - best F1 on dev/validation in the paper is 80,96 trained on a GPU, CPU will be a bit lower ~77.x I think\n",
    "sp = spar_predictor.SparPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0206ea8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obj': ['An example sentence', 'ACC terminology', 'the British Standards']}\n",
      "Parsing took 0.12084102630615234\n"
     ]
    }
   ],
   "source": [
    "example = \"An example sentence to show how ACC terminology will be extracted from the British Standards.\"\n",
    "start_time = time.time()\n",
    "# prepare instance and run model on single instance\n",
    "docid = ''                  # ToDo - add doc_id during pre_processing?\n",
    "token_list = sp.predictor._dataset_reader.tokenizer.tokenize(example)\n",
    "instance = sp.predictor._dataset_reader.text_to_instance(docid,\n",
    "                                                      example,\n",
    "                                                      token_list,\n",
    "                                                      sp.predictor._dataset_reader._token_indexer)\n",
    "result = sp.predictor.predict_instance(instance)\n",
    "printable_result = sp.parse_output(result, ['obj'])\n",
    "print(printable_result)\n",
    "print(\"Parsing took {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f7c27f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# These should automatically run on your Nvidia GPU if available\n",
    "class SparInstance:\n",
    "    def __init__(self):\n",
    "        self.sp = spar_predictor.SparPredictor()\n",
    "    \n",
    "    def call(self, input_str:str=''):\n",
    "        if input_str:\n",
    "            # prepare instance and run model on single instance\n",
    "            docid = ''  # ToDo - add doc_id during pre_processing?\n",
    "            token_list = self.sp.predictor._dataset_reader.tokenizer.tokenize(input_str)\n",
    "\n",
    "            # truncating the input to SPaR.txt to maximum 512 tokens\n",
    "            token_length = len(token_list)\n",
    "            if token_length > 512:\n",
    "                token_list = token_list[:511] + [token_list[-1]]\n",
    "                token_length = 512\n",
    "\n",
    "            instance = self.sp.predictor._dataset_reader.text_to_instance(docid, input_str, token_list,\n",
    "                                                              self.sp.predictor._dataset_reader._token_indexer)\n",
    "            result = self.sp.predictor.predict_instance(instance)\n",
    "            printable_result = self.sp.parse_output(result, ['obj'])\n",
    "            return {\n",
    "                    \"prediction\": printable_result,\n",
    "                    \"num_input_tokens\": token_length,\n",
    "            }\n",
    "            \n",
    "        # If the input is None, or too long, return an empty list of objects\n",
    "        return {\n",
    "                \"prediction\": {'obj': []},\n",
    "                \"num_input_tokens\": 0\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb733c61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TermExtractor:\n",
    "    \n",
    "    def __init__(self, split_length=300, max_num_cpu_threads=4):\n",
    "        \"\"\"\n",
    "        Initialise SPaR.txt predictors `max_num_cpu_threads` \n",
    "        \"\"\"\n",
    "        self.split_length = split_length   # in number of tokens\n",
    "        self.max_num_cpu_threads = max_num_cpu_threads\n",
    "        self.PREDICTORS = []\n",
    "        for i in range(max_num_cpu_threads + 1):\n",
    "            self.PREDICTORS.append(SparInstance())\n",
    "    \n",
    "    \n",
    "    def process_sentence(self, sentence: str = ''):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        predictor_to_use = int(current_thread().name.rsplit('_', 1)[1])\n",
    "        spartxt = self.PREDICTORS[predictor_to_use]\n",
    "\n",
    "        # SPaR doesn't handle ALL uppercase sentences well, which the OCR system sometimes outputs    \n",
    "        sentence = sentence.lower() if sentence.isupper() else sentence\n",
    "        prediction_dict =  spartxt.call(sentence)\n",
    "        if not prediction_dict:\n",
    "            return []\n",
    "\n",
    "        pred_labels = prediction_dict[\"prediction\"]\n",
    "        return pred_labels['obj']\n",
    "        \n",
    "\n",
    "    def split_into_sentences_and_run_spar(self, input_document):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        print(f\"Working on: {input_document.source_fp}\")\n",
    "        content_as_list_of_dicts = input_document.to_list_of_dicts()\n",
    "        total_number_of_sentences_found = 0\n",
    "        content_idx = 0\n",
    "        for content_dict in tqdm(content_as_list_of_dicts):\n",
    "\n",
    "            text = ' '.join([x for x in content_dict[\"content\"].split(' ') if x != ''])\n",
    "            # some really long paragraphs in the EU regulations are summations that should be split at ';'\n",
    "            if len(text) > 3000:\n",
    "                text = text.replace(\";\", \".\\n\")\n",
    "\n",
    "            # We'll split into sentences even if this has been done before, it doesn't take long\n",
    "            sentences = []\n",
    "            for part in text.split('\\n'):\n",
    "                # split into sentences using PunktSentTokenizer (TextBlob implements NLTK's version under the hood) \n",
    "                sentences += [str(s) for s in TextBlob(part).sentences if len(str(s)) > 10]\n",
    "\n",
    "            content_dict[\"meta\"][\"sentences\"] = '###'.join(sentences)\n",
    "                \n",
    "            total_number_of_sentences_found += len(sentences)\n",
    "\n",
    "            # process sentences in the content and add SPaR.txt object tags to the content dict.        \n",
    "            if not content_dict[\"meta\"][\"SPaR_labels\"]:\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_num_cpu_threads) as executor:\n",
    "                    futures = [executor.submit(self.process_sentence, sentences[idx]) for idx in range(len(sentences))]\n",
    "\n",
    "                content_spar_objects = [f.result() for f in futures]\n",
    "                content_dict[\"meta\"][\"SPaR_labels\"] = ', '.join([tag for tags in content_spar_objects for tag in tags])\n",
    "                \n",
    "            # immediately update the list of content_dicts and every X iterations we save the file \n",
    "            content_as_list_of_dicts[content_idx] = content_dict\n",
    "            if content_idx // 5 == 0:\n",
    "                converted_document.replace_contents(content_as_list_of_dicts)\n",
    "                converted_document.write_document()\n",
    "            \n",
    "            content_idx += 1\n",
    "\n",
    "        print(f\"Number of sentences found: {total_number_of_sentences_found}\")\n",
    "        converted_document.replace_contents(content_as_list_of_dicts)\n",
    "        converted_document.write_document()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7dc2f46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te = TermExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d086b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: data/input/The Merged Approved Documents.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1274/1274 [00:01<00:00, 767.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 17745\n",
      "Working on: data/input/EUR-Lex - 31993L0042 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 826/826 [00:00<00:00, 3979.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 1679\n",
      "Working on: data/input/CELEX 32017R0746 EN TXT.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4344/4344 [00:01<00:00, 2564.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 3405\n",
      "Working on: data/input/CELEX 32017R0745 EN TXT.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4799/4799 [00:01<00:00, 3244.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 3838\n",
      "Working on: data/input/EUR-Lex - 31998L0079 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 623/623 [00:00<00:00, 2601.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 1255\n",
      "Working on: data/input/EUR-Lex - 31990L0385 - EN.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [00:00<00:00, 4581.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences found: 771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run SPaR.txt on all documents and write to file\n",
    "for converted_document in foreground_corpus + background_corpus:\n",
    "    # re-load the document from file, to make sure we don't overwrite existing SPaR.txt labels\n",
    "    converted_document = converted_document.load_document(converted_document.output_fp)\n",
    "    te.split_into_sentences_and_run_spar(converted_document)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835185f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Number of sentences (longer than 10 characters) found in: <ul>\n",
    "    <li>Merged Approved documents: 17745</li>\n",
    "    <li>Background corpus (1679+3405+3838+1255+771): 10948</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b15878",
   "metadata": {},
   "source": [
    "### 3 Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511762d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "First, load all terms from the processed files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fb5373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of foreground terms: 114361\n",
      "Total number of UNIQUE foreground terms: 42658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 2130),\n",
       " ('a', 930),\n",
       " ('the building', 864),\n",
       " ('buildings', 839),\n",
       " ('guidance', 522),\n",
       " ('a building', 455),\n",
       " ('the Building Regulations', 434),\n",
       " ('document', 303),\n",
       " ('people', 301),\n",
       " ('the requirements', 297)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreground_terms_lists = [c.NER_labels for d in foreground_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "foreground_terms = [t for t_list in foreground_terms_lists for t in t_list]\n",
    "foreground_terms_c = Counter(foreground_terms)\n",
    "print(f\"Total number of foreground terms: {len(foreground_terms)}\")\n",
    "print(f\"Total number of UNIQUE foreground terms: {len(foreground_terms_c)}\")\n",
    "foreground_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8006f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of background terms: 76570\n",
      "Total number of UNIQUE background terms: 10246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('', 3446),\n",
       " ('the', 2651),\n",
       " ('devices', 1641),\n",
       " ('the manufacturer', 1243),\n",
       " ('the device', 1187),\n",
       " ('Regulation', 624),\n",
       " ('the notified body', 595),\n",
       " ('information', 550),\n",
       " ('Member States', 489),\n",
       " ('a', 451)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_terms_lists = [c.NER_labels for d in background_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "background_terms = [t for t_list in background_terms_lists for t in t_list]\n",
    "background_terms_c = Counter(background_terms)\n",
    "print(f\"Total number of background terms: {len(background_terms)}\")\n",
    "print(f\"Total number of UNIQUE background terms: {len(background_terms_c)}\")\n",
    "background_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464451e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Second, clean the terms with the regular expressions we've defined in utils.py\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2503708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_filter = utils.RegexFilter()\n",
    "def run_filters(input_counter):\n",
    "    cleaned_counter = Counter()\n",
    "    for k, v in input_counter.items():\n",
    "        # terms should occur twice at least\n",
    "        if v < 2:\n",
    "            continue\n",
    "\n",
    "        # todo; clean up these util functions and how to call them|\n",
    "        _, k = regex_filter.run_filter(k)\n",
    "        if k:\n",
    "            cleaned_k = utils.custom_cleaning_rules(k)\n",
    "            if cleaned_k:\n",
    "                cleaned_counter[cleaned_k[0]] = v\n",
    "    return cleaned_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e42c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('guidance', 522),\n",
       " ('a building', 455),\n",
       " ('document', 303),\n",
       " ('the requirements', 297),\n",
       " ('requirements', 266),\n",
       " ('work', 242),\n",
       " ('the guidance', 240),\n",
       " ('the work', 232),\n",
       " ('Schedule 1', 226),\n",
       " ('the dwelling', 215)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_foreground_terms_c = run_filters(foreground_terms_c)\n",
    "print(len(cleaned_foreground_terms_c))\n",
    "cleaned_foreground_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899b1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('devices', 1641),\n",
       " ('the manufacturer', 1243),\n",
       " ('the device', 1187),\n",
       " ('the notified body', 595),\n",
       " ('Member States', 489),\n",
       " ('the market', 447),\n",
       " ('the Commission', 446),\n",
       " ('accordance', 429),\n",
       " ('a device', 405),\n",
       " ('conformity', 357)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_background_terms_c = run_filters(background_terms_c)\n",
    "print(len(cleaned_background_terms_c))\n",
    "cleaned_background_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d6ca8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Third, we cluster the embeddings for both foreground and background terms with KMeans.\n",
    "</div>\n",
    "\n",
    "\n",
    "* Note: embeddings will be IDF weighted (IDF weights over both foreground and background corpora)\n",
    "  * Could add more sentences to the computation of IDF weights, e.g., definitions from vocabularies/WikiData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b177bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which tokenizer to use for IDF computation and Embedding;\n",
    "bert_model_name = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10278f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms_c = cleaned_foreground_terms_c + cleaned_background_terms_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1000a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('devices', 1665),\n",
       " ('the manufacturer', 1286),\n",
       " ('the device', 1195),\n",
       " ('the requirements', 647),\n",
       " ('accordance', 631),\n",
       " ('the notified body', 595),\n",
       " ('guidance', 539),\n",
       " ('Member States', 491),\n",
       " ('the market', 458),\n",
       " ('requirements', 457)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_terms_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8d0d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF weights\n",
    "sentence_lists = [c.sentences for d in foreground_corpus + background_corpus for c in d.load_document(d.output_fp).all_contents]\n",
    "all_sentences = [s for sent_list in sentence_lists for s in sent_list if s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bf4a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Merged Approved Documents',\n",
       " 'How to use the Merged Approved Documents This document combines the approved documents into a single PDF.',\n",
       " 'Each approved document is self-contained and has its own introduction.',\n",
       " 'Each introduction relates only to the corresponding approved document.',\n",
       " \"Each introduction also contains information on when the document's guidance came into effect (or will come into effect).\",\n",
       " 'It is important to check that the version of each approved document you are using remains current and is the correct version for your project.',\n",
       " 'Please refer to the Ministry of Housing, Communities and Local Government website to check, and confirm with your building control body if in doubt.',\n",
       " 'Key features The Merged Approved Documents enable the user to: undertake a word search across all of the approved documents cut and paste text and diagrams into other documents add notes to a saved copy use an index to access individual sections of the guidance Correction to Approved Document K The heading in section 1.18 of the online version of Approved Document K have been corrected to match the print version.',\n",
       " \"Forthcoming changes Please check the Ministry of Housing, Communities and Local Government's website to ensure that each approved document you are using is current for your project.\",\n",
       " 'This is particularly important in relation to Approved Document B as this has been subject to frequent update.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_sentences))\n",
    "all_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c09c984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing IDF weights.\n",
      "Printing some IDF values, should be subword units!\n",
      "['cluster']\n",
      "['##of']\n",
      "['deposits']\n",
      "['ultimate']\n",
      "['horizontal']\n",
      "['proximity']\n",
      "['estates']\n",
      "['exploration']\n",
      "['##most']\n",
      "['rendered']\n"
     ]
    }
   ],
   "source": [
    "IDF_c = IDF_computation.IdfComputer(\"data/IDF_weights.json\", bert_model_name=bert_model_name)\n",
    "IDF_path = IDF_c.compute_or_load_IDF_weights(all_sentences, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "411b8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each of the terms identified by SPaR.txt, applies IDF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b1959bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique terms: 16577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the Merged Approved Documents',\n",
       " 'document',\n",
       " 'documents',\n",
       " 'Each introduction',\n",
       " 'approved',\n",
       " 'information',\n",
       " 'guidance',\n",
       " 'the version',\n",
       " 'project',\n",
       " 'the Ministry']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_terms = [k for k in all_terms_c.keys()] # counter keys, so already unique\n",
    "print(f\"Number of unique terms: {len(all_terms)}\")\n",
    "all_terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26f20d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a669a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedding.Embedder(tokenizer, bert_model, \n",
    "                              IDF_dict=json.load(open(IDF_path)), \n",
    "                              embedding_fp=\"output/\",\n",
    "                              layers_to_use = [12],         # we'll use the output of the last layer\n",
    "                              layer_combination = \"avg\",    # how to combine layers if multiple are used\n",
    "                              idf_threshold = 1.5,          # minimum IDF value for a token to contribute\n",
    "                              idf_weight_factor = 1.0,      # modify how strong the influence of IDF weighting is\n",
    "                              not_found_idf_value = 0.5)    # IDF value for tokens that weren't seen during IDF computation (doesn't apply here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce59ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embeddings, this is split into subsets so we don't overload your memory (adjust these values if needed)\n",
    "max_num_cpu_threads = 4\n",
    "subset_size = 1000\n",
    "\n",
    "# Checks which of the embeddings for the clustering cluster_data already exist, so they can be re-used\n",
    "term_subsets = utils.split_list(all_terms, subset_size)\n",
    "embedding_files = glob.glob(embedder.embedding_fp + 'embeddings*.pkl')\n",
    "span_and_embedding_pairs = []\n",
    "if len(embedding_files) == len(term_subsets):\n",
    "    for e in embedding_files:\n",
    "        span_and_embedding_pairs += pickle.load(open(e, 'rb'))\n",
    "else:\n",
    "    print(f\"Preparing embeddings for {len(all_terms)} spans, in groups of: {subset_size}\")\n",
    "    subset_idx = 0            # iterator index outside of tqdm \n",
    "    for subset in tqdm(term_subsets):\n",
    "        subset_embeddings = []\n",
    "        subset_file_name = embedder.embedding_fp + \"embeddings_part_\" + '{}.pkl'.format(subset_idx)\n",
    "        subset_idx += 1\n",
    "        if os.path.exists(subset_file_name):\n",
    "            # already computed previously\n",
    "            continue\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_num_cpu_threads) as executor:\n",
    "            futures = [executor.submit(embedder.embed_a_span, subset[idx]) for idx in range(len(subset))]\n",
    "\n",
    "        subset_embeddings += [f.result() for f in futures if f.result()]\n",
    "\n",
    "        with open(subset_file_name, 'wb') as f:\n",
    "            pickle.dump(subset_embeddings, f)\n",
    "\n",
    "    # Once all embeddings are created; combine them in span_and_embedding_pairs\n",
    "    embedding_files = glob.glob(embedder.embedding_fp + \"embeddings_part_\" + '*.pkl')\n",
    "    for e in embedding_files:\n",
    "        span_and_embedding_pairs += pickle.load(open(e, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4e8b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising and combining computed/existing 17 embeddings from files into single file\n"
     ]
    }
   ],
   "source": [
    "# Create a single file with all embeddings, in the meantime standardising the embeddings to improve the representation\n",
    "print(f\"Normalising and combining computed/existing {len(embedding_files)} embeddings from files into single file\")\n",
    "unique_spans, unique_embeddings = zip(*span_and_embedding_pairs)\n",
    "with open(embedder.embedding_fp + \"unique_spans.pkl\", 'wb') as f:\n",
    "    pickle.dump(unique_spans, f)\n",
    "\n",
    "with open(embedder.embedding_fp + \"unique_embeddings.pkl\", 'wb') as f:\n",
    "    # we average over the token embeddings in a term\n",
    "    unique_clustering_data = np.stack([np.mean(e, axis=0) if len(e.shape) > 1 else e for e in unique_embeddings])\n",
    "\n",
    "    # standardise the unique clustering data, as suggested by https://github.com/wtimkey/rogue-dimensions\n",
    "    embedder.emb_mean = unique_clustering_data.mean(axis=0)\n",
    "    embedder.emb_std = unique_clustering_data.std(axis=0)\n",
    "    pickle.dump(embedder.emb_mean, open(embedder.embedding_fp + \"standardisation_mean.pkl\", 'wb'))\n",
    "    pickle.dump(embedder.emb_std, open(embedder.embedding_fp + \"standardisation_std.pkl\", 'wb'))\n",
    "\n",
    "    standardised_clustering_data = (unique_clustering_data - embedder.emb_mean) / embedder.emb_std\n",
    "\n",
    "    pickle.dump(standardised_clustering_data, f)\n",
    "    \n",
    "# COULD/SHOULD remove the embedding files now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30daa510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute clusters on either CPU or GPU\n",
    "def compute_clusters_sklearn(unique_clustering_data, cluster_model_fp, num_clusters=10):\n",
    "    \"\"\"\n",
    "    Note that this clustering function relies on the CPU. It won't be able to compute clusters for large \n",
    "    amounts of inputs, e.g., 100.000 spans. When using a large number of clusters (e.g. 5000) it is also\n",
    "    a lot slower than a GPU implementation for. Or it may simply not converge! \n",
    "    For large inputs/num_clusters you'll need to use compute_clusters_kmcuda, and have access to a GPU.\n",
    "    \"\"\"\n",
    "    print(f\"Computing {num_clusters} clusters from scratch, using sklearn on the CPU\")\n",
    "    start_time = time.time()\n",
    "    sklearn_kmeans = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=3, n_init=1, random_state=14,\n",
    "                            tol=0.0001, verbose=0)\n",
    "    assignments = sklearn_kmeans.fit_predict(unique_clustering_data)\n",
    "    centroids = sklearn_kmeans.cluster_centers_\n",
    "    print(\"Clustering took {}\".format(time.time() - start_time))\n",
    "    with open(cluster_model_fp, 'wb') as f:\n",
    "        pickle.dump((centroids, assignments), f)\n",
    "        \n",
    "# compute clusters on CPU for now\n",
    "def compute_clusters_kmcuda(unique_clustering_data, cluster_model_fp, num_clusters=10000):\n",
    "    \"\"\"\n",
    "    Won't implement cosine KMeans here, as I want to predict with sklearn in this notebook. \n",
    "    Also not sure if the results are really that much better.\n",
    "    \"\"\"\n",
    "    centroids, assignments = kmeans_cuda(unique_clustering_data, num_clusters, init=\"k-means++\",\n",
    "                                                 verbosity=1, seed=14) # , device=0)\n",
    "    with open(cluster_model_fp, 'wb') as f:\n",
    "        pickle.dump((centroids, assignments), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b39d48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn cluster file exists for 2000 clusters\n",
      "sklearn cluster file exists for 2500 clusters\n",
      "sklearn cluster file exists for 3000 clusters\n",
      "sklearn cluster file exists for 3500 clusters\n",
      "sklearn cluster file exists for 4000 clusters\n",
      "sklearn cluster file exists for 4500 clusters\n",
      "sklearn cluster file exists for 5000 clusters\n",
      "sklearn cluster file exists for 5500 clusters\n",
      "sklearn cluster file exists for 6000 clusters\n",
      "sklearn cluster file exists for 6500 clusters\n"
     ]
    }
   ],
   "source": [
    "if not kmeans_cuda:\n",
    "    # Computing clusters on the CPU\n",
    "    for num_clusters in range(2000,6501, 500):\n",
    "        cluster_file = f\"output/sklearn_{num_clusters}_clusters.pkl\"\n",
    "        if not os.path.exists(cluster_file):\n",
    "            compute_clusters_sklearn(standardised_clustering_data, cluster_file, num_clusters)\n",
    "        else:\n",
    "            print(f\"sklearn cluster file exists for {num_clusters} clusters\")\n",
    "else:     \n",
    "    for num_clusters in range(4000,10001, 500):\n",
    "        cluster_file = f\"output/kmcuda_{num_clusters}_clusters.pkl\"\n",
    "        if not os.path.exists(cluster_file):\n",
    "            compute_clusters_kmcuda(standardised_clustering_data, cluster_file, num_clusters) \n",
    "        else:\n",
    "            print(f\"kmcuda cluster file exists for {num_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97b112",
   "metadata": {},
   "source": [
    "* Select the 'best' cluster model using Elbow and Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b6810b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_type = \"sklearn\"\n",
    "clustering_files = glob.glob(f'output/{clustering_type}_*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d87f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing elbow and silhouette (if not too many num_clusters) scores.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 1965.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading values from existing csv file: output/sklearn_4500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_5000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_3500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_2000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_2500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_3000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_5500_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_4000_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_6000_clusters.pkl\n",
      "File may not have the right naming format: output/sklearn_clusters.pkl\n",
      "Loading values from existing csv file: output/sklearn_6500_clusters.pkl\n",
      "Plotting the figure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This takes a bit of time; 6-10 minutes per cluster size for 2000-6000 clusters \n",
    "# but resulting scores are saved in a csv and reused\n",
    "clustering_data_fp = \"output/\"\n",
    "es = cluster_utils.ElbowAndSilhouette(clustering_data_fp)\n",
    "es.compute_scores_for_models(clustering_type, clustering_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f80fc",
   "metadata": {},
   "source": [
    "* Based on the number of clusters we'd like to use, we create a lookup-dictionary for the embedding and assigned cluster of each span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7db65503",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_num_clusters = 6000\n",
    "cluster_model_to_use = f'output/{clustering_type}_{chosen_num_clusters}_clusters.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "733bd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, assignments = pickle.load(open(cluster_model_to_use, 'rb'))\n",
    "\n",
    "unique_background_terms = [k for k in background_terms_c.keys()]\n",
    "cluster_dict_creator = cluster_utils.ClusterDict(unique_background_terms, unique_spans, unique_embeddings, \n",
    "                 centroids, \n",
    "                 assignments,\n",
    "                 embedding_fp=\"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5692ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cluster dictionary.\n"
     ]
    }
   ],
   "source": [
    "phrase_cluster_dict, clusters_to_filter = cluster_dict_creator.prep_cluster_dict(chosen_num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63bbc5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEC domain: ['Class B', 'Class S', 'Class F']\n",
      "Filtered: ['the presence', 'The presence']\n",
      "Filtered: ['cytomegalovirus']\n",
      "Filtered: ['the objective methodology']\n",
      "AEC domain: ['Cause the system']\n",
      "Filtered: ['Accession']\n",
      "Filtered: ['accreditation']\n",
      "Filtered: ['wires']\n",
      "Filtered: ['the views']\n",
      "AEC domain: ['Soffit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/l_mzhpjs6bg95plfkl_n_vsc0000gn/T/ipykernel_19204/378847011.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  for k in random.sample(phrase_cluster_dict.keys(), 10):\n"
     ]
    }
   ],
   "source": [
    "# print some insight in the clusters\n",
    "max_terms_to_show = 5\n",
    "for k in random.sample(phrase_cluster_dict.keys(), 10):\n",
    "    some_terms = [span for score, span in phrase_cluster_dict[k]]\n",
    "    if k in clusters_to_filter:\n",
    "        print(f\"Filtered: {some_terms[:max_terms_to_show]}\")\n",
    "    else:\n",
    "        print(f\"AEC domain: {some_terms[:max_terms_to_show]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5aa123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_terms = [span for k, v in phrase_cluster_dict.items() for score, span in v if k in clusters_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b97c6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_terms = [span for k, v in phrase_cluster_dict.items() for score, span in v  if k not in clusters_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e89aff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8794\n",
      "Terms that were filtered:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the latest scientific evidence',\n",
       " 'a fire wall',\n",
       " 'Monitoring',\n",
       " 'newel post',\n",
       " 'the direction',\n",
       " 'insulation criterion',\n",
       " 'grey',\n",
       " 'authorized',\n",
       " 'a rationale',\n",
       " 'accessory']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(filtered_terms))\n",
    "print(\"Terms that were filtered:\")\n",
    "random.sample(filtered_terms,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24378f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7782\n",
      "Terms that were kept:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['humidities',\n",
       " 'criterion',\n",
       " 'trial holes',\n",
       " 'person per day',\n",
       " 'the flue',\n",
       " 'WC /',\n",
       " 'the pipework',\n",
       " 'licensed',\n",
       " 'BRE report BR 135',\n",
       " 'the pipe floor']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(domain_terms))\n",
    "print(\"Terms that were kept:\")\n",
    "random.sample(domain_terms,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d79937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
